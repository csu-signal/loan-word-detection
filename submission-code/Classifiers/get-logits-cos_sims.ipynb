{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d900aa",
   "metadata": {},
   "source": [
    "Assumes you have run `Train_Testset.ipynb` first to make the `alldata`, `realdist`, and `balanced` train/test splits for the chosen language pair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a3a5e",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "091671b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import panphon\n",
    "import panphon.distance\n",
    "import editdistance # levenshtein\n",
    "import epitran\n",
    "import eng_to_ipa as eng\n",
    "from epitran.backoff import Backoff\n",
    "from googletrans import Translator\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "epitran.download.cedict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4977c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import nn, optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed2ae9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import io\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "726f5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer specific imports \n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup,\\\n",
    "    BertForSequenceClassification, BertForPreTraining, AutoModel\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel, XLMModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, mean_squared_error\n",
    "import time\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78b4fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    \n",
    "#device = torch.device(\"cuda:0:3\" if torch.cuda.is_available() else \"cpu\") ## specify the GPU id's, GPU id's start from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80da282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e42f7",
   "metadata": {},
   "source": [
    "# DNN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e92610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(n_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            \n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        logits_new = self.linear_relu_stack(x)\n",
    "        logits  = self.dropout(logits_new)\n",
    "        \n",
    "        return torch.sigmoid(logits), logits_new\n",
    "    \n",
    "    def fit(self, X_train, Y_train, X_val, Y_val, criterion, optimizer, n_epochs=5000):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accur = []\n",
    "        val_accur = []\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            y_pred, logits = self(X_train.float())\n",
    "\n",
    "            train_loss = criterion(y_pred, Y_train.float())\n",
    "\n",
    "            if epoch % (n_epochs // 50) == 0:\n",
    "                train_acc,_ = self.calculate_accuracy(Y_train, y_pred)\n",
    "\n",
    "                y_val_pred = self(X_val.float())[0]\n",
    "\n",
    "                val_loss = criterion(y_val_pred, Y_val.float())\n",
    "\n",
    "                val_acc, total_corr = self.calculate_accuracy(Y_val, y_val_pred)\n",
    "\n",
    "                print(f'''epoch {epoch}\n",
    "                    Train set - loss: {self.round_tensor(train_loss)}, accuracy: {self.round_tensor(train_acc)} \n",
    "                    Val set - loss: {self.round_tensor(val_loss)}, accuracy: {self.round_tensor(val_acc)}''')\n",
    "                \n",
    "                train_losses.append(train_loss.detach().cpu().numpy())\n",
    "                val_losses.append(val_loss.detach().cpu().numpy())\n",
    "\n",
    "                val_accur.append(val_acc.detach().cpu().numpy())\n",
    "                train_accur.append(train_acc.detach().cpu().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "        return train_losses,val_losses,train_accur,val_accur\n",
    "    \n",
    "    def calculate_accuracy(self, y_true, y_pred):\n",
    "        predicted = y_pred.ge(.5) \n",
    "        return ((y_true == predicted).sum().float() / len(y_true), (y_true == predicted).sum())\n",
    "    \n",
    "    def round_tensor(self, t, decimal_places=3):\n",
    "        return round(t.item(), decimal_places)\n",
    "    \n",
    "    def plot_losses(self, train_losses, val_losses, train_accur, val_accur):\n",
    "        epochs = range(1, len(train_accur) + 1)\n",
    "\n",
    "        plt.plot(epochs, train_accur, 'bo', label='Training acc')\n",
    "        plt.plot(epochs, val_accur, 'b', label='Vaidation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
    "        plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36154569",
   "metadata": {},
   "source": [
    "# MyDataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8b14ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overriding the Dataset class required for the use of PyTorch's data loader classes.\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, l1_encodings, l2_encodings):\n",
    "        self.l1_encodings = l1_encodings\n",
    "        self.l2_encodings = l2_encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {('l1_' + key): torch.tensor(val[idx]) for key, val in self.l1_encodings.items()}\n",
    "        item2 = {('l2_' + key): torch.tensor(val[idx]) for key, val in self.l2_encodings.items()}\n",
    "        item.update(item2)\n",
    "        # item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l1_encodings['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a47bf8",
   "metadata": {},
   "source": [
    "# Download LMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b243a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "xlm_tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "xlm_model = XLMModel.from_pretrained(\"xlm-mlm-100-1280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "947738c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMModel(\n",
       "  (position_embeddings): Embedding(512, 1280)\n",
       "  (embeddings): Embedding(200000, 1280, padding_idx=2)\n",
       "  (layer_norm_emb): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "  (attentions): ModuleList(\n",
       "    (0): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (1): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (2): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (3): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (4): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (5): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (6): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (7): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (8): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (9): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (10): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (11): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (12): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (13): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (14): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (15): MultiHeadAttention(\n",
       "      (q_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (k_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (v_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (out_lin): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm1): ModuleList(\n",
       "    (0): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (1): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (2): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (3): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (4): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (5): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (6): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (7): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (8): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (9): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (10): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (11): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (12): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (13): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (14): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (15): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (ffns): ModuleList(\n",
       "    (0): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (1): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (2): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (3): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (4): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (5): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (6): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (7): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (8): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (9): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (10): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (11): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (12): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (13): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (14): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "    (15): TransformerFFN(\n",
       "      (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (act): GELUActivation()\n",
       "    )\n",
       "  )\n",
       "  (layer_norm2): ModuleList(\n",
       "    (0): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (1): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (2): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (3): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (4): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (5): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (6): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (7): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (8): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (9): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (10): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (11): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (12): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (13): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (14): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "    (15): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55834b9",
   "metadata": {},
   "source": [
    "# Pipeline function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4051b",
   "metadata": {},
   "source": [
    "## Get Panphon phonetic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4354d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_panphon_features(train_set, test_set):\n",
    "    #get phonetic features using PanPhon\n",
    "    ft = panphon.FeatureTable()   \n",
    "    \n",
    "    train_set['features_loan'] = train_set.apply(lambda x:ft.word_to_vector_list(x[\"loan_word_epitran\"],numeric=True ), axis=1)\n",
    "    train_set['features_orig'] = train_set.apply(lambda x:ft.word_to_vector_list(x[\"original_word_epitran\"],numeric=True ), axis=1)\n",
    "    test_set['features_loan'] = test_set.apply(lambda x:ft.word_to_vector_list(x[\"loan_word_epitran\"],numeric=True ), axis=1)\n",
    "    test_set['features_orig'] = test_set.apply(lambda x:ft.word_to_vector_list(x[\"original_word_epitran\"],numeric=True ), axis=1)\n",
    "\n",
    "    train_set['features_loan'] = train_set['features_loan'].apply(lambda x:sum(x, []))\n",
    "    train_set['features_orig'] = train_set['features_orig'].apply(lambda x:sum(x, []))\n",
    "    test_set['features_orig'] = test_set['features_orig'].apply(lambda x:sum(x, []))\n",
    "    test_set['features_loan'] = test_set['features_loan'].apply(lambda x:sum(x, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "413d0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_panphon_features(train_set, test_set, maxlen, verbose=False):\n",
    "    # Pad the phonetic features of the loan word and original word out to the maxlen \n",
    "    # of the features appearing in the training set (format: `<loan><pad 0s><orig><pad 0s>`).\n",
    "    train_set['features_loan'] = train_set['features_loan'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[0]-len(x)), 'constant'))\n",
    "    train_set['features_orig'] = train_set['features_orig'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[1]-len(x)), 'constant'))\n",
    "    test_set['features_loan'] = test_set['features_loan'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[0]-len(x)), 'constant'))\n",
    "    test_set['features_orig'] = test_set['features_orig'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[1]-len(x)), 'constant'))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Sample train features:\\n\",\\\n",
    "                train_set['features_loan'][np.random.randint(len(train_set['features_loan']))],\\\n",
    "                train_set['features_orig'][np.random.randint(len(train_set['features_loan']))])\n",
    "\n",
    "        print(\"Sample test features:\\n\",\\\n",
    "                test_set['features_loan'][np.random.randint(len(test_set['features_loan']))],\\\n",
    "                test_set['features_orig'][np.random.randint(len(test_set['features_orig']))])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a031511",
   "metadata": {},
   "source": [
    "## Add target labels and make train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "900f4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target_labels(train_set, test_set):\n",
    "    Y_train = np.array([y for y in train_set['label_bin']])\n",
    "    Y_test = np.array([y for y in test_set['label_bin']])\n",
    "    return Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e93f3aa",
   "metadata": {},
   "source": [
    "Make a validation split for training the DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16fd11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_val_set(train_set, test_set, Y_train):\n",
    "    X_train = np.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                np.array([x for x in train_alldata['features_orig']])])\n",
    "    X_test = np.hstack([np.array([x for x in test_alldata['features_loan']]),\\\n",
    "                np.array([x for x in test_alldata['features_orig']])])\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2,\\\n",
    "                                                      random_state=1, stratify=Y_train)\n",
    "    return X_train, X_val, X_test, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee312b",
   "metadata": {},
   "source": [
    "Make tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44851fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "    X_train = torch.tensor(X_train).to(device)\n",
    "    Y_train = torch.tensor(Y_train).to(device).reshape((-1,1))\n",
    "\n",
    "    X_val = torch.tensor(X_val).to(device)\n",
    "    Y_val = torch.tensor(Y_val).to(device).reshape((-1,1))\n",
    "    \n",
    "    X_test = torch.tensor(X_test).to(device)\n",
    "    Y_test = torch.tensor(Y_test).to(device).reshape((-1,1))\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40b267",
   "metadata": {},
   "source": [
    "## Get cosine similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683ed59",
   "metadata": {},
   "source": [
    "MBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48e84130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mbert_cos_sims(l1_data,l2_data):\n",
    "    with torch.no_grad():\n",
    "        tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_bert_MODEL)\n",
    "        tokenizer.model_max_length = MAXTOKENS\n",
    "        l1_encodings = tokenizer(l1_data, truncation=False, padding=True, max_length=MAXTOKENS)\n",
    "        l2_encodings = tokenizer(l2_data, truncation=False, padding=True, max_length=MAXTOKENS)\n",
    "        \n",
    "        dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "        \n",
    "        data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "        \n",
    "        base_model = BertModel.from_pretrained(PRE_TRAINED_bert_MODEL).to(device)\n",
    "        base_model.eval()\n",
    "        cos_s = torch.nn.CosineSimilarity()\n",
    "        \n",
    "        sim_lst = []\n",
    "        \n",
    "        #loop through dataset \n",
    "        for step, batch in enumerate(data_loader):\n",
    "            l1_vector = base_model(batch['l1_input_ids'].to(device),\n",
    "                                          attention_mask=batch['l1_attention_mask'].to(device),\n",
    "                                          return_dict=True).last_hidden_state[:, 0, :]\n",
    "            l2_vector = base_model(batch['l2_input_ids'].to(device),\n",
    "                                          attention_mask=batch['l2_attention_mask'].to(device),\n",
    "                                          return_dict=True).last_hidden_state[:, 0, :]\n",
    "            sims = cos_s(l1_vector, l2_vector).data.cpu().numpy()\n",
    "            sim_lst.extend(list(sims))\n",
    "            if (step * BS) % 100 < BS:\n",
    "                print(\"Got {}\".format(len(sim_lst)))\n",
    "        print()\n",
    "                \n",
    "    return sim_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643675a",
   "metadata": {},
   "source": [
    "XLM-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6ecafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xlm_cos_sims(l1_data,l2_data):\n",
    "    with torch.no_grad():\n",
    "        tokenizer = XLMTokenizer.from_pretrained(PRE_TRAINED_xlm_MODEL)\n",
    "        tokenizer.model_max_length = MAXTOKENS \n",
    "        l1_encodings = tokenizer(l1_data, truncation=False, padding=True, max_length=MAXTOKENS, return_tensors=\"pt\", return_special_tokens_mask=True)\n",
    "        l2_encodings = tokenizer(l2_data, truncation=False, padding=True, max_length=MAXTOKENS, return_tensors=\"pt\", return_special_tokens_mask=True)\n",
    "\n",
    "        dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "\n",
    "        data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "\n",
    "        \n",
    "        base_model = XLMModel.from_pretrained(PRE_TRAINED_xlm_MODEL).to(device)\n",
    "        \n",
    "        base_model.eval()\n",
    "        cos_s = torch.nn.CosineSimilarity()\n",
    "        \n",
    "        sim_lst = []\n",
    "\n",
    "        #loop through dataset \n",
    "        for step, batch in enumerate(data_loader):\n",
    "            \n",
    "            l1_vector = base_model(batch['l1_input_ids'].to(device), output_hidden_states=False).last_hidden_state\n",
    "            l2_vector = base_model(batch['l2_input_ids'].to(device), output_hidden_states=False).last_hidden_state \n",
    "            \n",
    "            sims = cos_s(l1_vector[:,0,:],l2_vector[:,0,:]).data.cpu().numpy()\n",
    "            sim_lst.extend(list(sims))\n",
    "            if (step * BS) % 100 < BS:\n",
    "                print(\"Got {}\".format(len(sim_lst)))\n",
    "        print()\n",
    "                \n",
    "    return sim_lst "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcffe48",
   "metadata": {},
   "source": [
    "# Load `language-pairs.json` list and run pipeline for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "189eca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English-French\n",
      "\n",
      "Using cpu device\n",
      "\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=1080, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") \n",
      "\n",
      "epoch 0\n",
      "                    Train set - loss: 0.678, accuracy: 0.751 \n",
      "                    Val set - loss: 0.679, accuracy: 0.735\n",
      "epoch 100\n",
      "                    Train set - loss: 0.487, accuracy: 0.781 \n",
      "                    Val set - loss: 0.484, accuracy: 0.788\n",
      "epoch 200\n",
      "                    Train set - loss: 0.448, accuracy: 0.782 \n",
      "                    Val set - loss: 0.448, accuracy: 0.784\n",
      "epoch 300\n",
      "                    Train set - loss: 0.439, accuracy: 0.782 \n",
      "                    Val set - loss: 0.447, accuracy: 0.774\n",
      "epoch 400\n",
      "                    Train set - loss: 0.434, accuracy: 0.78 \n",
      "                    Val set - loss: 0.434, accuracy: 0.785\n",
      "epoch 500\n",
      "                    Train set - loss: 0.426, accuracy: 0.781 \n",
      "                    Val set - loss: 0.429, accuracy: 0.785\n",
      "epoch 600\n",
      "                    Train set - loss: 0.42, accuracy: 0.777 \n",
      "                    Val set - loss: 0.423, accuracy: 0.787\n",
      "epoch 700\n",
      "                    Train set - loss: 0.41, accuracy: 0.781 \n",
      "                    Val set - loss: 0.42, accuracy: 0.781\n",
      "epoch 800\n",
      "                    Train set - loss: 0.401, accuracy: 0.781 \n",
      "                    Val set - loss: 0.414, accuracy: 0.781\n",
      "epoch 900\n",
      "                    Train set - loss: 0.389, accuracy: 0.783 \n",
      "                    Val set - loss: 0.412, accuracy: 0.775\n",
      "epoch 1000\n",
      "                    Train set - loss: 0.379, accuracy: 0.782 \n",
      "                    Val set - loss: 0.397, accuracy: 0.787\n",
      "epoch 1100\n",
      "                    Train set - loss: 0.364, accuracy: 0.786 \n",
      "                    Val set - loss: 0.387, accuracy: 0.784\n",
      "epoch 1200\n",
      "                    Train set - loss: 0.353, accuracy: 0.787 \n",
      "                    Val set - loss: 0.381, accuracy: 0.781\n",
      "epoch 1300\n",
      "                    Train set - loss: 0.337, accuracy: 0.798 \n",
      "                    Val set - loss: 0.373, accuracy: 0.783\n",
      "epoch 1400\n",
      "                    Train set - loss: 0.322, accuracy: 0.809 \n",
      "                    Val set - loss: 0.36, accuracy: 0.795\n",
      "epoch 1500\n",
      "                    Train set - loss: 0.307, accuracy: 0.822 \n",
      "                    Val set - loss: 0.354, accuracy: 0.798\n",
      "epoch 1600\n",
      "                    Train set - loss: 0.291, accuracy: 0.834 \n",
      "                    Val set - loss: 0.348, accuracy: 0.801\n",
      "epoch 1700\n",
      "                    Train set - loss: 0.277, accuracy: 0.841 \n",
      "                    Val set - loss: 0.339, accuracy: 0.804\n",
      "epoch 1800\n",
      "                    Train set - loss: 0.261, accuracy: 0.849 \n",
      "                    Val set - loss: 0.324, accuracy: 0.815\n",
      "epoch 1900\n",
      "                    Train set - loss: 0.249, accuracy: 0.852 \n",
      "                    Val set - loss: 0.319, accuracy: 0.818\n",
      "epoch 2000\n",
      "                    Train set - loss: 0.232, accuracy: 0.862 \n",
      "                    Val set - loss: 0.31, accuracy: 0.821\n",
      "epoch 2100\n",
      "                    Train set - loss: 0.221, accuracy: 0.865 \n",
      "                    Val set - loss: 0.315, accuracy: 0.812\n",
      "epoch 2200\n",
      "                    Train set - loss: 0.206, accuracy: 0.875 \n",
      "                    Val set - loss: 0.303, accuracy: 0.823\n",
      "epoch 2300\n",
      "                    Train set - loss: 0.196, accuracy: 0.877 \n",
      "                    Val set - loss: 0.296, accuracy: 0.826\n",
      "epoch 2400\n",
      "                    Train set - loss: 0.185, accuracy: 0.881 \n",
      "                    Val set - loss: 0.288, accuracy: 0.831\n",
      "epoch 2500\n",
      "                    Train set - loss: 0.174, accuracy: 0.886 \n",
      "                    Val set - loss: 0.286, accuracy: 0.83\n",
      "epoch 2600\n",
      "                    Train set - loss: 0.166, accuracy: 0.891 \n",
      "                    Val set - loss: 0.285, accuracy: 0.832\n",
      "epoch 2700\n",
      "                    Train set - loss: 0.157, accuracy: 0.891 \n",
      "                    Val set - loss: 0.278, accuracy: 0.837\n",
      "epoch 2800\n",
      "                    Train set - loss: 0.147, accuracy: 0.9 \n",
      "                    Val set - loss: 0.287, accuracy: 0.829\n",
      "epoch 2900\n",
      "                    Train set - loss: 0.141, accuracy: 0.9 \n",
      "                    Val set - loss: 0.275, accuracy: 0.845\n",
      "epoch 3000\n",
      "                    Train set - loss: 0.136, accuracy: 0.902 \n",
      "                    Val set - loss: 0.286, accuracy: 0.829\n",
      "epoch 3100\n",
      "                    Train set - loss: 0.13, accuracy: 0.904 \n",
      "                    Val set - loss: 0.28, accuracy: 0.834\n",
      "epoch 3200\n",
      "                    Train set - loss: 0.124, accuracy: 0.905 \n",
      "                    Val set - loss: 0.286, accuracy: 0.833\n",
      "epoch 3300\n",
      "                    Train set - loss: 0.12, accuracy: 0.907 \n",
      "                    Val set - loss: 0.284, accuracy: 0.831\n",
      "epoch 3400\n",
      "                    Train set - loss: 0.115, accuracy: 0.908 \n",
      "                    Val set - loss: 0.278, accuracy: 0.839\n",
      "epoch 3500\n",
      "                    Train set - loss: 0.109, accuracy: 0.91 \n",
      "                    Val set - loss: 0.287, accuracy: 0.837\n",
      "epoch 3600\n",
      "                    Train set - loss: 0.106, accuracy: 0.911 \n",
      "                    Val set - loss: 0.289, accuracy: 0.833\n",
      "epoch 3700\n",
      "                    Train set - loss: 0.101, accuracy: 0.914 \n",
      "                    Val set - loss: 0.283, accuracy: 0.844\n",
      "epoch 3800\n",
      "                    Train set - loss: 0.102, accuracy: 0.909 \n",
      "                    Val set - loss: 0.289, accuracy: 0.838\n",
      "epoch 3900\n",
      "                    Train set - loss: 0.099, accuracy: 0.911 \n",
      "                    Val set - loss: 0.295, accuracy: 0.838\n",
      "epoch 4000\n",
      "                    Train set - loss: 0.097, accuracy: 0.91 \n",
      "                    Val set - loss: 0.292, accuracy: 0.838\n",
      "epoch 4100\n",
      "                    Train set - loss: 0.095, accuracy: 0.912 \n",
      "                    Val set - loss: 0.29, accuracy: 0.843\n",
      "epoch 4200\n",
      "                    Train set - loss: 0.091, accuracy: 0.913 \n",
      "                    Val set - loss: 0.304, accuracy: 0.835\n",
      "epoch 4300\n",
      "                    Train set - loss: 0.089, accuracy: 0.915 \n",
      "                    Val set - loss: 0.304, accuracy: 0.839\n",
      "epoch 4400\n",
      "                    Train set - loss: 0.088, accuracy: 0.914 \n",
      "                    Val set - loss: 0.311, accuracy: 0.839\n",
      "epoch 4500\n",
      "                    Train set - loss: 0.084, accuracy: 0.916 \n",
      "                    Val set - loss: 0.306, accuracy: 0.837\n",
      "epoch 4600\n",
      "                    Train set - loss: 0.086, accuracy: 0.912 \n",
      "                    Val set - loss: 0.314, accuracy: 0.834\n",
      "epoch 4700\n",
      "                    Train set - loss: 0.086, accuracy: 0.911 \n",
      "                    Val set - loss: 0.309, accuracy: 0.839\n",
      "epoch 4800\n",
      "                    Train set - loss: 0.082, accuracy: 0.915 \n",
      "                    Val set - loss: 0.31, accuracy: 0.842\n",
      "epoch 4900\n",
      "                    Train set - loss: 0.082, accuracy: 0.913 \n",
      "                    Val set - loss: 0.322, accuracy: 0.837\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAu9ElEQVR4nO3deXhU5dn48e9NCMYIsoSwSIAEy1IVCBBAxX2pbAUXsCBVeVEQ6oq2iqJCsVhr/bXIVbFFVFxoAa0vRcUXRUFRqxKWqihWwESDCxhl38P9++M5A5MwM5lJZjKZmftzXXNlzpkz5zxnZnLPM/ezHFFVjDHGJL468S6AMcaY6LCAbowxScICujHGJAkL6MYYkyQsoBtjTJKwgG6MMUnCAroJSEReEZGro71tPIlIkYhcEIP9qoj8xLv/VxG5J5xtq3CcESLyalXLGWK/54hISbT3a2pe3XgXwESPiOz0W8wE9gFl3vJ1qjon3H2par9YbJvsVHVsNPYjIrnAF0C6qh709j0HCPs9NKnHAnoSUdX6vvsiUgRcq6pLKm4nInV9QcIYkzws5ZICfD+pReQOEfkWeFJEGovISyKyRUR+9O7n+D1nmYhc690fKSJvi8hD3rZfiEi/Km6bJyJvicgOEVkiIo+IyLNByh1OGe8TkXe8/b0qIk39Hr9SRIpFpFREJoZ4fXqLyLcikua37hIR+dC730tE/i0iW0XkGxH5i4jUC7Kv2SLyO7/l33jP+VpERlXYdoCIrBaR7SLylYhM9nv4Le/vVhHZKSKn+V5bv+efLiIrRGSb9/f0cF+bUETkp97zt4rIWhEZ5PdYfxH5xNvnJhH5tbe+qff+bBWRH0RkuYhYfKlh9oKnjhZAE6AtMAb33j/pLbcB9gB/CfH83sBnQFPgQeBxEZEqbPt34AMgC5gMXBnimOGU8Qrgf4BmQD3AF2BOAh719n+Cd7wcAlDV94FdwHkV9vt3734ZMN47n9OA84FfhSg3Xhn6euW5EGgPVMzf7wKuAhoBA4BxInKx99hZ3t9GqlpfVf9dYd9NgJeB6d65/Ql4WUSyKpzDUa9NJWVOB14EXvWedyMwR0Q6eps8jkvfNQBOAd7w1t8GlADZQHPgLsDmFalhFtBTxyFgkqruU9U9qlqqqv9U1d2qugOYCpwd4vnFqvqYqpYBTwEtcf+4YW8rIm2AnsC9qrpfVd8GFgY7YJhlfFJV/6uqe4D5QL63fgjwkqq+par7gHu81yCYfwDDAUSkAdDfW4eqrlTV91T1oKoWAX8LUI5ALvfK97Gq7sJ9gfmf3zJV/UhVD6nqh97xwtkvuC+Az1X1Ga9c/wDWAT/32ybYaxPKqUB94AHvPXoDeAnvtQEOACeJyPGq+qOqrvJb3xJoq6oHVHW52kRRNc4CeurYoqp7fQsikikif/NSEttxP/Eb+acdKvjWd0dVd3t360e47QnAD37rAL4KVuAwy/it3/3dfmU6wX/fXkAtDXYsXG38UhE5BrgUWKWqxV45OnjphG+9ctyPq61XplwZgOIK59dbRJZ6KaVtwNgw9+vbd3GFdcVAK7/lYK9NpWVWVf8vP//9Xob7sisWkTdF5DRv/R+B9cCrIrJRRCaEdxommiygp46KtaXbgI5Ab1U9niM/8YOlUaLhG6CJiGT6rWsdYvvqlPEb/317x8wKtrGqfoILXP0on24Bl7pZB7T3ynFXVcqASxv5+zvuF0prVW0I/NVvv5XVbr/GpaL8tQE2hVGuyvbbukL++/B+VXWFqg7GpWMW4Gr+qOoOVb1NVdsBg4BbReT8apbFRMgCeupqgMtJb/XysZNifUCvxlsITBaRel7t7uchnlKdMj4PDBSRM7wGzClU/nn/O3Az7ovjuQrl2A7sFJFOwLgwyzAfGCkiJ3lfKBXL3wD3i2WviPTCfZH4bMGliNoF2fcioIOIXCEidUXkF8BJuPRIdbyPq83fLiLpInIO7j2a671nI0SkoaoewL0mhwBEZKCI/MRrK9mGa3cIleIyMWABPXVNA44FvgfeA/6vho47AtewWAr8DpiH6y8fyDSqWEZVXQtcjwvS3wA/4hrtQvHlsN9Q1e/91v8aF2x3AI95ZQ6nDK945/AGLh3xRoVNfgVMEZEdwL14tV3vubtxbQbveD1HTq2w71JgIO5XTClwOzCwQrkjpqr7cQG8H+51nwFcparrvE2uBIq81NNY3PsJrtF3CbAT+DcwQ1WXVqcsJnJi7RYmnkRkHrBOVWP+C8GYZGc1dFOjRKSniJwoInW8bn2DcblYY0w12UhRU9NaAC/gGihLgHGqujq+RTImOVjKxRhjkoSlXIwxJkmElXLxcp0PA2nALFV9oMLjfwbO9RYzgWaq2ijUPps2baq5ubmRltcYY1LaypUrv1fV7ECPVRrQvVF5j+DmoygBVojIQm8gBgCqOt5v+xuBbpXtNzc3l8LCwjCKb4wxxkdEKo4QPiyclEsvYL2qbvT6qM7F9UwIZjjeHBjGGGNqTjgBvRXl56Moofx8EYeJSFsgj6MHUPgeHyMihSJSuGXLlkjLaowxJoRoN4oOA573Ztk7iqrOVNUCVS3Izg6YAjLGGFNF4TSKbqL8BEM5BJ8AaBhuuLUxphY6cOAAJSUl7N27t/KNTVxlZGSQk5NDenp62M8JJ6CvANqLSB4ukA+j/CRCAHiTFjXGzeNgjKmFSkpKaNCgAbm5uQS/PomJN1WltLSUkpIS8vLywn5epSkX79qTNwCLgU+B+aq6VkSm+F+aChfo58ZyUvs5cyA3F+rUcX/n2OVyjYnI3r17ycrKsmBey4kIWVlZEf+SCqsfuqouwk3X6b/u3grLkyM6coTmzIExY2C3d2mE4mK3DDBiRPDnGWPKs2CeGKryPiXMSNGJE48Ec5/du916Y4wxCRTQv/wysvXGmNqntLSU/Px88vPzadGiBa1atTq8vH///pDPLSws5Kabbqr0GKeffnpUyrps2TIGDhwYlX3VlIQJ6G0qXryrkvXGmOqLdrtVVlYWa9asYc2aNYwdO5bx48cfXq5Xrx4HDx4M+tyCggKmT59e6THefffd6hUygSVMQJ86FTIzy6/LzHTrjTHR52u3Ki4G1SPtVtHujDBy5EjGjh1L7969uf322/nggw847bTT6NatG6effjqfffYZUL7GPHnyZEaNGsU555xDu3btygX6+vXrH97+nHPOYciQIXTq1IkRI0bg67OxaNEiOnXqRI8ePbjpppsqrYn/8MMPXHzxxXTp0oVTTz2VDz/8EIA333zz8C+Mbt26sWPHDr755hvOOuss8vPzOeWUU1i+fHl0X7AQEmY+dF/D5+23w9dfQ1YWPPywNYgaEyuh2q2i/X9XUlLCu+++S1paGtu3b2f58uXUrVuXJUuWcNddd/HPf/7zqOesW7eOpUuXsmPHDjp27Mi4ceOO6rO9evVq1q5dywknnECfPn145513KCgo4LrrruOtt94iLy+P4cOHV1q+SZMm0a1bNxYsWMAbb7zBVVddxZo1a3jooYd45JFH6NOnDzt37iQjI4OZM2dy0UUXMXHiRMrKythd8UWMoYQJ6OA+RD//OTRsCHfcYcHcmFiqyXaroUOHkpaWBsC2bdu4+uqr+fzzzxERDhw4EPA5AwYM4JhjjuGYY46hWbNmfPfdd+Tk5JTbplevXofX5efnU1RURP369WnXrt3h/t3Dhw9n5syZIcv39ttvH/5SOe+88ygtLWX79u306dOHW2+9lREjRnDppZeSk5NDz549GTVqFAcOHODiiy8mPz+/Oi9NRBIm5eLToIFLtXzzTbxLYkxyq8l2q+OOO+7w/XvuuYdzzz2Xjz/+mBdffDFoX+xjjjnm8P20tLSA+fdwtqmOCRMmMGvWLPbs2UOfPn1Yt24dZ511Fm+99RatWrVi5MiRPP3001E9ZigJF9BFoGVLC+jGxFq82q22bdtGq1Zu/r/Zs2dHff8dO3Zk48aNFBUVATBv3rxKn3PmmWcyx2s8WLZsGU2bNuX4449nw4YNdO7cmTvuuIOePXuybt06iouLad68OaNHj+baa69l1apVUT+HYBIuoAO0aAHffhvvUhiT3EaMgJkzoW1bV5Fq29YtxzrVefvtt3PnnXfSrVu3qNeoAY499lhmzJhB37596dGjBw0aNKBhw4YhnzN58mRWrlxJly5dmDBhAk899RQA06ZN45RTTqFLly6kp6fTr18/li1bRteuXenWrRvz5s3j5ptvjvo5BBO3a4oWFBRoVS9wMXQofPQRrFsX5UIZk+Q+/fRTfvrTn8a7GHG3c+dO6tevj6py/fXX0759e8aPH1/5E2tYoPdLRFaqakGg7ROyhm4pF2NMdTz22GPk5+dz8skns23bNq677rp4FykqEqqXi0+LFrB9u+tCVTHHZ4wxlRk/fnytrJFXV8LW0MHy6MYY4y+hA7qlXYwx5ggL6MYYkyQSMqC3aOH+WkA3xpgjEjKgZ2dDWprl0I1JNOeeey6LFy8ut27atGmMGzcu6HPOOeccfF2c+/fvz9atW4/aZvLkyTz00EMhj71gwQI++eSTw8v33nsvS5YsiaD0gdWmaXYTMqDXqQPNm1sN3ZhEM3z4cObOnVtu3dy5c8OaIAvcLImNGjWq0rErBvQpU6ZwwQUXVGlftVVCBnSwvujGJKIhQ4bw8ssvH76YRVFREV9//TVnnnkm48aNo6CggJNPPplJkyYFfH5ubi7ff/89AFOnTqVDhw6cccYZh6fYBdfHvGfPnnTt2pXLLruM3bt38+6777Jw4UJ+85vfkJ+fz4YNGxg5ciTPP/88AK+//jrdunWjc+fOjBo1in379h0+3qRJk+jevTudO3dmXSWjGeM9zW5C9kMHl0fftCnepTAmcd1yC6xZE9195ufDtGnBH2/SpAm9evXilVdeYfDgwcydO5fLL78cEWHq1Kk0adKEsrIyzj//fD788EO6dOkScD8rV65k7ty5rFmzhoMHD9K9e3d69OgBwKWXXsro0aMBuPvuu3n88ce58cYbGTRoEAMHDmTIkCHl9rV3715GjhzJ66+/TocOHbjqqqt49NFHueWWWwBo2rQpq1atYsaMGTz00EPMmjUr6PnFe5pdq6EbY2qUf9rFP90yf/58unfvTrdu3Vi7dm259EhFy5cv55JLLiEzM5Pjjz+eQYMGHX7s448/5swzz6Rz587MmTOHtWvXhizPZ599Rl5eHh06dADg6quv5q233jr8+KWXXgpAjx49Dk/oFczbb7/NlVdeCQSeZnf69Ols3bqVunXr0rNnT5588kkmT57MRx99RIMGDULuOxwJW0Nv2RI2b4aDB6Fuwp6FMfETqiYdS4MHD2b8+PGsWrWK3bt306NHD7744gseeughVqxYQePGjRk5cmTQaXMrM3LkSBYsWEDXrl2ZPXs2y5Ytq1Z5fVPwVmf63QkTJjBgwAAWLVpEnz59WLx48eFpdl9++WVGjhzJrbfeylVXXVWtsiZsDb1FC3dZrM2b410SY0wk6tevz7nnnsuoUaMO1863b9/OcccdR8OGDfnuu+945ZVXQu7jrLPOYsGCBezZs4cdO3bw4osvHn5sx44dtGzZkgMHDhye8hagQYMG7Nix46h9dezYkaKiItavXw/AM888w9lnn12lc4v3NLsJW7f1H/5/wgnxLYsxJjLDhw/nkksuOZx68U0326lTJ1q3bk2fPn1CPr979+784he/oGvXrjRr1oyePXsefuy+++6jd+/eZGdn07t378NBfNiwYYwePZrp06cfbgwFyMjI4Mknn2To0KEcPHiQnj17Mnbs2Cqdl+9ap126dCEzM7PcNLtLly6lTp06nHzyyfTr14+5c+fyxz/+kfT0dOrXrx+VC2GENX2uiPQFHgbSgFmq+kCAbS4HJgMK/EdVrwi1z+pMnwvw3ntw2mnw0kswYECVd2NMSrHpcxNLpNPnVlpDF5E04BHgQqAEWCEiC1X1E79t2gN3An1U9UcRaVaNcwiLDf83xpjywsmh9wLWq+pGVd0PzAUGV9hmNPCIqv4IoKoxz2w3b+7+WkA3xhgnnIDeCvjKb7nEW+evA9BBRN4Rkfe8FM1RRGSMiBSKSOGWLVuqVmJPRgY0bmzD/42JVLyuUmYiU5X3KVq9XOoC7YFzgOHAYyLSqOJGqjpTVQtUtSA7O7vaB7W+6MZEJiMjg9LSUgvqtZyqUlpaSkZGRkTPC6eXyyagtd9yjrfOXwnwvqoeAL4Qkf/iAvyKiEoTIQvoxkQmJyeHkpISqvsL2cReRkYGOTk5ET0nnIC+AmgvInm4QD4MqNiDZQGuZv6kiDTFpWA2RlSSKmjRAt55J9ZHMSZ5pKenk5eXF+9imBipNOWiqgeBG4DFwKfAfFVdKyJTRMQ33nYxUCoinwBLgd+oammsCu3jq6Hbr0djjAlzYJGqLgIWVVh3r999BW71bjWmZUvYtw+2bnUNpMYYk8oSdug/WF90Y4zxl9AB3XcpOuu6aIwxCR7QrYZujDFHWEA3xpgkkdAB/fjj3YhRC+jGGJPgAV3E1dIth26MMQke0MFGixpjjI8FdGOMSRIJH9BbtLCUizHGQBIE9JYt3UjRPXviXRJjjImvpAjoYLV0Y4xJmoBueXRjTKpL+IBuw/+NMcZJ+IBuNXRjjHESPqBnZ0OdOhbQjTEm4QN6Who0b24pF2OMSfiADi6PbjV0Y0yqS4qAbqNFjTHGAroxxiSNpAjoLVrA5s1QVhbvkhhjTPwkRUBv2RIOHYItW+JdEmOMiZ+kCehgaRdjTGqzgG6MMUkiKQK6Df83xpgwA7qI9BWRz0RkvYhMCPD4SBHZIiJrvNu10S9qcFZDN8YYqFvZBiKSBjwCXAiUACtEZKGqflJh03mqekMMylipjAxo1MgCujEmtYVTQ+8FrFfVjaq6H5gLDI5tsSJnF4s2xqS6cAJ6K+Arv+USb11Fl4nIhyLyvIi0DrQjERkjIoUiUrglyn0Mbfi/MSbVRatR9EUgV1W7AK8BTwXaSFVnqmqBqhZkZ2dH6dCOjRY1xqS6cAL6JsC/xp3jrTtMVUtVdZ+3OAvoEZ3ihW/rVigqAhHIzYU5c2q6BMYYE1/hBPQVQHsRyROResAwYKH/BiLS0m9xEPBp9IpYuTlz4LXXQNUtFxfDmDEW1I0xqaXSgK6qB4EbgMW4QD1fVdeKyBQRGeRtdpOIrBWR/wA3ASNjVeBAJk6EAwfKr9u92603xphUIeqr1tawgoICLSwsjMq+6tQ5Ujv3J+LmeDHGmGQhIitVtSDQY0kxUrRNm8jWG2NMMkqKgD51KmRmll+XmenWG2NMqkiKgD5iBMyceaRGXrcuzJjh1htjTKpIioAOLngXF8OLL8LBg7B/f7xLZIwxNStpArrPgAFw6qkwZQrs3Rvv0hhjTM1JuoAuAr/7HZSUwN/+Fu/SGGNMzUm6gA5w/vlw7rlw//2wa1e8S2OMMTUjKQM6uB4umzfD9OnxLokxxtSMpA3op53m8ukPPujmeTHGmGSXtAEd4L77XDDPzXWjSW3SLmNMMkvqgP7JJ5CWBtu2uakBioth9Gh4/HGbEsAYk3ySOqBPnAhlZeXX7dkD117rAn39+jB0KJSWxqd8xhgTTUkd0L/8Mvhjl1ziujg+/zw0bw53311z5TLGmFhI6oAebHKurCxYvBh27nTLZWWuV8wll8DTT1vO3RiTmJI6oAebtAvcfOkVLVgA//M/Ltfuy7nbhTKMMYkiqQO6b9Kutm1deqVtW7f8ww/Bn1OxsdQulGGMSRRJHdDBBfWiIheoi4rccqTzpBcXw3XXQatWds1SY0ztlfQBPZBgqZisrMDbi7ia/ddfu+XiYrjmGnjmmdiW0xhjIpGSAT1YKubhhwMH+saNj97Hvn0u337LLTBpktuHNaQaY+IpKa4pGk1z5ric+ZdfutTM1Klw5ZWBr1kKkJ5+9AWq09Ph+uth1Cho1w6OOy725TbGpIZQ1xS1gB6G3FyXZqmobVuXm//qq9DP79EDLr/cDWLKy4tJEY0xKSLpLxIda6GuWVpSEvx5N9wADRvCypVwxx2utt6zp5sw7IsvYltmY0zqsRp6mAKlYkaMCF57z8py0wz493dPT4fWrWHjRrecm+tq+W3bun22aePud+4MLVvWxFkZYxJNqBp63ZouTKIaMSLwRaenTnWDj/wDd7DBSwcOuFGpGzfCP/8Jq1e7L4hly2DTpiPzzmRkwBNPwPDhMTkVY0ySCivlIiJ9ReQzEVkvIhNCbHeZiKiIBPz2SEaRDl768kt49134y1/gH/9w+ff773fXPy0uhjffdGmZK66ACROOnlzMGGOCqTTlIiJpwH+BC4ESYAUwXFU/qbBdA+BloB5wg6qGzKckWsolUpGkYjIz3ZeA7xfA/v1w883w179Cv37w979Do0Y1UWpjTG1X3UbRXsB6Vd2oqvuBucDgANvdB/wB2FvlkiaRSOaRqTi9QL168Oij7vbaa9C7N6xbF9vyGmMSXzgBvRXg3zGvxFt3mIh0B1qr6stRLFtCq0oqpqKxY+GNN+DHH11Qf9leXWNMCNXutigidYA/AbeFse0YESkUkcItW7ZU99C1XiTzyLRp43rSVJy698wzobAQTjwRBg6Eiy923SCNMaaicAL6JqC133KOt86nAXAKsExEioBTgYWBGkZVdaaqFqhqQXZ2dtVLncCCpWL693e9ZQJN3dumDbz9Nvz2t67RtKAAfv5zWLEiPudgjKmdwgnoK4D2IpInIvWAYcBC34Oquk1Vm6pqrqrmAu8BgyprFE1VwVIxixaFzq1nZsK997pA/7vfuZ4yvXq5L4L33qv58zDG1D6VBnRVPQjcACwGPgXmq+paEZkiIoNiXcBkFCgVE+xyeV9+WT4V06WLu19UBL//PXzwAZx2GnTrBn/4Q+CeNcaY1GAjRWuJqnZz3LkTZs92Qd9XUz/9dDcoaehQd71UY0zysLlcEkBVuznWr+/mjPn3v90I1Pvvhx074MYb4YQTXEPqyy/bACVjUoEF9FoiGt0c8/Lgzjvhww/h44/dhGArV7qg/pOfwAMPwObNsT0PY0z8WMqllgs1dW9RUeXPP3DAXfx6xgw3Z0x6OgwZAr/+NXTvHt2yGmNiz1IuCSzU1L3hSE93ufSlS+GTT2DcOJeC6dXLpWcsFWNM8rCAXssFS8X45n0JNBgpmJ/+1F1m78svXZCfOBEuvNDN9GiMSXyWcklgc+YEnrrXP+AHo+p6x9xwAxx7rLs/cGAsS2uMiQZLuSSpiRMrn+grGBF3keuVKyEnx408vflmd/FrY0xisoCewMIdjBQqFdOpk+u/fvPNMH06dO3qRqKuXRv8wtjGmNrJAnoCCzbRV5MmweeFCSQjA6ZNg5degsaN4Z574JRToGNHuP1218f90KGYnYYxJkosoCew6sy5HsiAAS54b9rk5mLPy4M//9mNPG3VyqVo5s6F0tLonYMxJnosoCewaAxGCuSEE9xc7IsXw5YtrmZ/1lnwr3+5KQWys9387PfeC++8Y7V3Y2oL6+WShKo7GCmYsjI3N/v//Z8L9u+/74L5SSe52v/ll0Ndu+y4MTFlvVxSTKjBSJH0W68oLc3VzCdNctP3fv89PPWU+3UwYoTr5/7EE250qjGm5llAT0LBUjEQWWNpZRo3hquucnPHvPACHH88XHONmzfm0Udhr11d1pgaZSmXFBKrVIyPqkvH3Hefa1zt3NnNI9OuXfX3bYxxLOVigND91qNBBPr1cw2lL74IJSXucnmLF0dn/8aY0Cygp5BQF6iOJhE3jUBhIbRu7YL8739vA5WMiTUL6CkkVo2lwbRr5xpPhw2Du+5yE4Lt2FH9/RpjArOAnkJqqrHU33HHuf386U8un37qqW4aX2NM9FmjqIl5Y6nPG2/AL37hujvm57sJwQYOdHn2Ola1MCng0CGYNQsuu8xdL7gqrFHUhBTrxlKf886D//wH/vAHdy3UqVNdv/ZWreDaa92FN2zUqUlWH38MZ5wB110HTz4Zm2NYQDc11lgKblqB22+H5cvd9U2fftpNK/Dcc662ftJJbnDS/v3RP7Yx8bB3L9x9N3TrBv/9r/vM33ZbbI5lAd3UeGOpT1YWXHklzJvn5oyZO9cd95prXIPqn/8MO3ce2b6sDFatgv/3/1zwb9bMDWz6/vvolcmYioqLYcoUF4RfeCGyC60vXQpdurj/pSuugHXr3GdeJDZltRy6AVygnjjRpVnatDlyzdKqXhGpqlThtdfggQfcP4NvNOoXX8Bbb8HWrW67Dh3cP8q//gUNG7pL6w0fHrt/FJMcDh6E1193A+Byc91Movn57tq7/vbvd2MpHnsMXn3VratX78gFYDp0gDPPdLdTTnG18F27XAVk1y53e/ddeOYZVzn529/ggguicw6hcuioaqU3oC/wGbAemBDg8bHAR8Aa4G3gpMr22aNHDzW1W9u2qi7Elr+1bVszx3/vPdVLLlEVUT3xRNVrrlF99lnVkpIj23z0kWrv3q5c/furFhfXTNlM4igrU337bdXrr1fNznaflfT0I5/nY49VPfts1TvvVH3hBdXf/Ea1WTP3WE6O6r33qn7xherevarvvKP6wAOqAweqNmoU+P/Dd6tbV3XCBNVdu6J7PkChBomrldbQRSQN+C9wIVACrACGq+onftscr6rbvfuDgF+pat9Q+7Uaeu1Xp07gwUAiNdt4uW8fHHNM8MfLyuAvf3F93evUcYOYfvUr6zmTKjZudDXuQ4fczT+sfvMNzJ/v0iYZGa5n1RVXuMFuW7a4WrTvtnq1q8Gnpbntrr0W+vZ1y4EcOuSu7LVhg/vletxx5W+NGh2dyoyGUDX0cAL6acBkVb3IW74TQFV/H2T74cBVqtov1H4toNd+NdWdMVqKilwPgldfhfbtXQpm2DA3C6RJTvPmucDr39biLy0NfvYz91m4+GJo0CD4vnbvhjVr3IVdWraMRWmjo7rdFlsBX/ktl3jrKh7kehHZADwI3FSVgpraJVRjaW2Um+tqanPnugtf33ef6zXTtaurtW/cGO8SmmjZtw+uv959YXfuDJ9+6horv//eXVHrhx/gxx/dyORFi1xDZKhgDu6zffrptTuYVyZqP0pV9RFVPRG4A7g70DYiMkZECkWkcMuWLdE6tImRYCNLfQ2isewBU1UibvDSG2+4S+lNn+76vN91F5x4ovuHnTPnSOOWqXllZbBsmbvi1axZrudSJO/Hxo3Qpw/MmAG//jW8+aa72Hl2tus51aSJa0xv1AiOPTZWZ1E7xSLlUgf4UVUbhtqvpVwS25w5Nd8DpjqKi93P88cfd32BmzVz5b/uOlebN7GlCu+9596D+fNdbttf3bpw8smur3a3bu7Lt1Urd2va9EjvpQULYORItzx7NgweXMMnUgtUN4deF9coej6wCdcoeoWqrvXbpr2qfu7d/zkwKdgBfSygJ7ZEy6/7HDoES5a4RtSXXnK/Li69FEaPdqmZ7Gzr+uhP1aUyPv/c3TZscF+AQ4dWPnRd1dW+fUG8uNg1bvfv735FDRgA333ntlm92t1WrTq6n3e9em5AWtOmbgbPggK3v7y82J13bVatgO7toD8wDUgDnlDVqSIyBdd9ZqGIPAxcABwAfgRu8A/4gVhAT2y1pQdMdXzxhbuy0qxZLt8KLj1z4olHbnl5rsdCerq71a3r/tar52qSTZtWfpzPPoMHH4Svv3btD927V/6c7dvdr6COHeHss4P3tPDZu9c1Bn/1lStTdnb5vxX7WQej6i5OMmuWm6Zh/XpXFp86ddz7m57uAvIvf+n+ZmQcef6HHx4J4hs2uNfsootcEB882F3ZKtTxv/3WBf9Nm8rfvv4aevZ0g3xC9XpKdtXuhx6Lm/VDT2yh+qg/+6z7K3JkuTbbtUt10SLV6dNVb7pJdcAA1U6dVOvVC93POD3d9ZP/179U9+8/er8rVqhedpl7HTIyXB/otDTVO+5Q3b07cFnKylRnz1Zt3vzIcZo3V73hBtXly93jPnv2qC5YoHrFFaoNGoQua6tWqmPGqL7yiuq+fUcfd+9e1aefVi0ocNs3bKh60UXuuA8/7F6fzz9357lqleqtt6q2aOG2bdRIdfRo1XvuUe3Y0a1LS1P92c9UZ81SLS2NyttkPIToh24B3VTJs8+qZmaWDxqZmarjxgVeX9uDeiAHD7pBTOvXq376qRvEtGqV6vvvqy5dqnrbbUcCb3a26i23qK5erbpkier55x8JjBMnqn73neoPP7jBUaDavr3qm2+WP15hoeqpp7rHe/d2g2Gee859KWRk6OGBLuPHlw/iTZq4/S5erPrNN6off+zK99xzqjNmqP72t6pDh6rWr++2P/541WHDVOfNc+c2efKR8+jUyT1nx47wXp/Fi1WvvFL1uONU69RRPfdc1b/+VXXz5ui/H8axgG5iIlBNPN6jS2va/v2qL76oOmRI+Rp9ixaqDz6oum3b0c9ZskS1XTu33dixqhs2uBquiBuh+OST5Wviqqrbt7vXd+BA98ugSRPVa691ATXQr4NA9uxRfekl9zzfiEnfrX9/t69Dh6r2OuzaZTXxmhIqoNtcLiaqkiG3XlWlpW7WyGOOcQNZfHnlQHbtct32pk1zr0vdunDjjTBpkpubJpRdu1wOP9y8eCBlZW505IoVblRk+/ZV35epWdVuFI0FC+jJKVF7v8TLBx+46VR/9Ss3CMqYytgFLkyNSbTRpfHWq5frQmnB3ESDBXQTVaFGl9bGkaXGJJO68S6AST4jRhw9WrTiyFLfhah92xtjqs9q6KZGTJxYfpoAcMsTJ8anPMYkIwvopkbU1IWojUllFtBNjQh1IWrLrRsTHRbQTY0I1vulf3+XSy8udv3Xfbl1C+rGRM4CuqkRwXq/LFpkuXVjosUGFpm4SuWRpcZUhQ0sMrVWqNy6MSYyFtBNXFU2stQaTI0JnwV0E1eVjSy1BlNjwmc5dFNr2URfxhzNcugmIdlgJGMiYwHd1Fo2GMmYyFhAN7WWDUYyJjIW0E2tZYORjImMNYqahGODkUwqs0ZRk1RsMJIxgVlANwkn1GAkayw1qcwCukk4wXLrYI2lJrWFlUMXkb7Aw0AaMEtVH6jw+K3AtcBBYAswSlUDDAk5wnLoJtpsIJJJBdXKoYtIGvAI0A84CRguIhWvUb4aKFDVLsDzwIPVK7IxkQs1EMlSMSYVhJNy6QWsV9WNqrofmAsM9t9AVZeqqq8j2XtATnSLaUzlgjWKNmliqRiTGsIJ6K2Ar/yWS7x1wVwDvBLoAREZIyKFIlK4ZcuW8EtpTBiCNZaC9Vs3qSGqjaIi8kugAPhjoMdVdaaqFqhqQXZ2djQPbUzQxtIffgi8vc0JY5JNOAF9E9DabznHW1eOiFwATAQGqeq+6BTPmMiMGOEaQA8dcn9HjLA5YUzqCCegrwDai0ieiNQDhgEL/TcQkW7A33DBfHP0i2lM1dmcMCZVVBrQVfUgcAOwGPgUmK+qa0VkiogM8jb7I1AfeE5E1ojIwiC7M6bG2ZwwJlXYXC4mZVU2J8ycOS64f/mlS89Mneq+HIyJJ5vLxZgAKsutWzrGJBoL6CZlhZoTZuJES8eYxGMB3aSsUBeotlGnJhFZDt2YAILNC5OVBXv2lK+9Z2Ye+SIwJtYsh25MhGzUqUlEFtCNCaAqo04tFWPizVIuxkTAUjEm3izlYkyUWCrG1GYW0I2JgKViTG1mKRdjosBSMaamWMrFmBirSirGau4m2iygGxMFkaZifFMJ2NQCJposoBsTJZHMxZ6WFroR1WrvpiosoBsTQ8FSMWVlgbf3NaJa7d1UhQV0Y2IoWCqmbdvA27dpE3piMKu5m1Csl4sxceCrhQfq/XLllYHnafdtYz1mUpv1cjGmlgk102NV8u5WczdgNXRjap1gtfeKwdxfsJo72FWXko3V0I1JIJHm3YPV3G++2RpXU40FdGNqoUBdICPtMVNaaimaVGMB3ZgEEWnNPRgb1JS8LKAbk0AiqblnZQXehw1qSl4W0I1JcMFq7g8/HN1BTRboE4CqxuXWo0cPNcbE1rPPqrZtqyri/vqWXbguf2vbNvhjWVmqmZnl12Vmuv1FcmxTfUChBomrYdXQRaSviHwmIutFZEKAx88SkVUiclBEhkT9W8cYUyWRpGimTnW19EAibWCtbPoCq+3HSLBI77sBacAGoB1QD/gPcFKFbXKBLsDTwJDK9qlWQzcmroLVnoPV0EPdAtXcs7KC/wp49tngtX2r1VeOEDX0SgcWichpwGRVvchbvtP7Ivh9gG1nAy+p6vOVfZHYwCJjap9gg5qOPdbV0itKSwuekw9ExA1wivRiIGADpHxCDSyqG8bzWwFf+S2XAL2rWJAxwBiANsHGNxtj4sYXJCsGT4h89GogbdqETutU5Bsg5R/ofekbHwv0R9RoLxdVnamqBapakJ2dXZOHNsaEKVDePdI+8FlZwfP0kdblguXvQ42EDZWjjzR/n0j5/nBq6JuA1n7LOd46Y0wK8QX2igLV3B9+2N0PVnuOJK0TTFVr9P7Hrqy2H+n2cf91ECy57rvhgv5GII8jjaInB9l2NtYoakxKqUpDZqDnBGssDdbAGumtKt0ygx07VDfOUK9HNBp9qU6jKICI9Aem4Xq8PKGqU0VkirfjhSLSE/hfoDGwF/hWVU8OtU9rFDXGVDRnTvj5+0hr9CLubxghr8oqa9gNNgd+JDX7UI2iNn2uMabWi0ag9+X7A/WwibVQx27b1rVVhKu6vVyMMSauguXvIfxAX5UvgWA17kh/HQTr2VPZY5GygG6MSViRBHr/7cL9EgjWuBts+2CB3tezJ1ANPZo9uC3lYowxBE7rhMptR5IGqqkcutXQjTGG0LX9SLeP5NdBNLs6Wg3dGGMSiF1T1BhjUoAFdGOMSRIW0I0xJklYQDfGmCRhAd0YY5JE3Hq5iMgWoLJBuE2B72ugOLWNnXdqSdXzhtQ99+qcd1tVDTj/eNwCejhEpDBY95xkZuedWlL1vCF1zz1W520pF2OMSRIW0I0xJknU9oA+M94FiBM779SSqucNqXvuMTnvWp1DN8YYE77aXkM3xhgTJgvoxhiTJGptQBeRviLymYisF5EJ8S5PrIjIEyKyWUQ+9lvXREReE5HPvb+N41nGWBCR1iKyVEQ+EZG1InKztz6pz11EMkTkAxH5j3fev/XW54nI+97nfZ6I1It3WWNBRNJEZLWIvOQtJ/15i0iRiHwkImtEpNBbF5PPea0M6CKSBjwC9ANOAoaLyEnxLVXMzAb6Vlg3AXhdVdsDr3vLyeYgcJuqngScClzvvcfJfu77gPNUtSuQD/QVkVOBPwB/VtWfAD8C18SviDF1M/Cp33KqnPe5qprv1/c8Jp/zWhnQgV7AelXdqKr7gbnA4DiXKSZU9S3ghwqrBwNPefefAi6uyTLVBFX9RlVXefd34P7JW5Hk567OTm8x3bspcB7wvLc+6c4bQERygAHALG9ZSIHzDiImn/PaGtBbAV/5LZd461JFc1X9xrv/LdA8noWJNRHJBboB75MC5+6lHdYAm4HXgA3AVlU96G2SrJ/3acDtwCFvOYvUOG8FXhWRlSIyxlsXk8+5XYKullNVFZGk7VsqIvWBfwK3qOp2V2lzkvXcVbUMyBeRRsD/Ap3iW6LYE5GBwGZVXSki58S5ODXtDFXdJCLNgNdEZJ3/g9H8nNfWGvomoLXfco63LlV8JyItAby/m+NcnpgQkXRcMJ+jqi94q1Pi3AFUdSuwFDgNaCQivgpWMn7e+wCDRKQIl0I9D3iY5D9vVHWT93cz7gu8FzH6nNfWgL4CaO+1gNcDhgEL41ymmrQQuNq7fzXwrziWJSa8/OnjwKeq+ie/h5L63EUk26uZIyLHAhfi2g+WAkO8zZLuvFX1TlXNUdVc3P/zG6o6giQ/bxE5TkQa+O4DPwM+Jkaf81o7UlRE+uNybmnAE6o6Nb4lig0R+QdwDm46ze+AScACYD7QBjfF8OWqWrHhNKGJyBnAcuAjjuRU78Ll0ZP23EWkC64RLA1XoZqvqlNEpB2u5toEWA38UlX3xa+kseOlXH6tqgOT/by98/tfb7Eu8HdVnSoiWcTgc15rA7oxxpjI1NaUizHGmAhZQDfGmCRhAd0YY5KEBXRjjEkSFtCNMSZJWEA3xpgkYQHdGGOSxP8HJmip2zTfiewAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting logits from DNN\n",
      "Getting MBERT similarities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "Got 1808\n",
      "Got 1912\n",
      "Got 2008\n",
      "Got 2112\n",
      "Got 2208\n",
      "Got 2312\n",
      "Got 2408\n",
      "Got 2512\n",
      "Got 2608\n",
      "Got 2712\n",
      "Got 2808\n",
      "Got 2912\n",
      "Got 3008\n",
      "Got 3112\n",
      "Got 3208\n",
      "Got 3312\n",
      "Got 3408\n",
      "Got 3512\n",
      "Got 3608\n",
      "Got 3712\n",
      "Got 3808\n",
      "Got 3912\n",
      "Got 4008\n",
      "Got 4112\n",
      "Got 4208\n",
      "Got 4312\n",
      "Got 4408\n",
      "Got 4512\n",
      "Got 4608\n",
      "Got 4712\n",
      "Got 4808\n",
      "Got 4912\n",
      "Got 5008\n",
      "Got 5112\n",
      "Got 5208\n",
      "Got 5312\n",
      "Got 5408\n",
      "Got 5512\n",
      "Got 5608\n",
      "Got 5712\n",
      "Got 5808\n",
      "Got 5912\n",
      "Got 6008\n",
      "Got 6112\n",
      "Got 6208\n",
      "Got 6312\n",
      "Got 6408\n",
      "Got 6512\n",
      "Got 6608\n",
      "Got 6712\n",
      "Got 6808\n",
      "Got 6912\n",
      "Got 7008\n",
      "Got 7112\n",
      "Got 7208\n",
      "Got 7312\n",
      "Got 7408\n",
      "Got 7512\n",
      "Got 7608\n",
      "Got 7712\n",
      "Got 7808\n",
      "Got 7912\n",
      "Got 8008\n",
      "Got 8112\n",
      "Got 8208\n",
      "Got 8312\n",
      "Got 8408\n",
      "Got 8512\n",
      "Got 8608\n",
      "Got 8712\n",
      "Got 8808\n",
      "Got 8912\n",
      "Got 9008\n",
      "Got 9112\n",
      "Got 9208\n",
      "Got 9312\n",
      "Got 9408\n",
      "Got 9512\n",
      "Got 9608\n",
      "Got 9712\n",
      "Got 9808\n",
      "Got 9912\n",
      "Got 10008\n",
      "Got 10112\n",
      "Got 10208\n",
      "Got 10312\n",
      "Got 10408\n",
      "Got 10512\n",
      "Got 10608\n",
      "Got 10712\n",
      "Got 10808\n",
      "Got 10912\n",
      "Got 11008\n",
      "Got 11112\n",
      "Got 11208\n",
      "Got 11312\n",
      "Got 11408\n",
      "Got 11512\n",
      "Got 11608\n",
      "Got 11712\n",
      "Got 11808\n",
      "Got 11912\n",
      "Got 12008\n",
      "Got 12112\n",
      "Got 12208\n",
      "Got 12312\n",
      "Got 12408\n",
      "Got 12512\n",
      "Got 12608\n",
      "Got 12712\n",
      "Got 12808\n",
      "Got 12912\n",
      "Got 13008\n",
      "Got 13112\n",
      "Got 13208\n",
      "Got 13312\n",
      "Got 13408\n",
      "Got 13512\n",
      "Got 13608\n",
      "Got 13712\n",
      "Got 13808\n",
      "Got 13912\n",
      "Got 14008\n",
      "Got 14112\n",
      "Got 14208\n",
      "Got 14312\n",
      "Got 14408\n",
      "Got 14512\n",
      "Got 14608\n",
      "Got 14712\n",
      "Got 14808\n",
      "Got 14912\n",
      "Got 15008\n",
      "Got 15112\n",
      "Got 15208\n",
      "Got 15312\n",
      "Got 15408\n",
      "Got 15512\n",
      "Got 15608\n",
      "Got 15712\n",
      "Got 15808\n",
      "Got 15912\n",
      "Got 16008\n",
      "Got 16112\n",
      "Got 16208\n",
      "Got 16312\n",
      "Got 16408\n",
      "Got 16512\n",
      "Got 16608\n",
      "Got 16712\n",
      "Got 16808\n",
      "Got 16912\n",
      "Got 17008\n",
      "Got 17112\n",
      "Got 17208\n",
      "Got 17312\n",
      "Got 17408\n",
      "Got 17512\n",
      "Got 17608\n",
      "Got 17712\n",
      "Got 17808\n",
      "Got 17912\n",
      "Got 18008\n",
      "Got 18112\n",
      "Got 18208\n",
      "Got 18312\n",
      "Got 18408\n",
      "Got 18512\n",
      "Got 18608\n",
      "Got 18712\n",
      "Got 18808\n",
      "Got 18912\n",
      "Got 19008\n",
      "Got 19112\n",
      "Got 19208\n",
      "Got 19312\n",
      "Got 19408\n",
      "Got 19512\n",
      "Got 19608\n",
      "Got 19712\n",
      "Got 19808\n",
      "Got 19912\n",
      "Got 20008\n",
      "Got 20112\n",
      "Got 20208\n",
      "Got 20312\n",
      "Got 20408\n",
      "Got 20512\n",
      "Got 20608\n",
      "Got 20712\n",
      "Got 20808\n",
      "Got 20912\n",
      "Got 21008\n",
      "Got 21112\n",
      "Got 21208\n",
      "Got 21312\n",
      "Got 21408\n",
      "Got 21512\n",
      "Got 21608\n",
      "Got 21712\n",
      "Got 21808\n",
      "Got 21912\n",
      "Got 22008\n",
      "Got 22112\n",
      "Got 22208\n",
      "Got 22312\n",
      "Got 22408\n",
      "Got 22512\n",
      "Got 22608\n",
      "Got 22712\n",
      "Got 22808\n",
      "Got 22912\n",
      "Got 23008\n",
      "Got 23112\n",
      "Got 23208\n",
      "Got 23312\n",
      "Got 23408\n",
      "Got 23512\n",
      "Got 23608\n",
      "Got 23712\n",
      "Got 23808\n",
      "Got 23912\n",
      "Got 24008\n",
      "Got 24112\n",
      "Got 24208\n",
      "Got 24312\n",
      "Got 24408\n",
      "Got 24512\n",
      "Got 24608\n",
      "Got 24712\n",
      "Got 24808\n",
      "Got 24912\n",
      "Got 25008\n",
      "Got 25112\n",
      "Got 25208\n",
      "Got 25312\n",
      "Got 25408\n",
      "Got 25512\n",
      "Got 25608\n",
      "Got 25712\n",
      "Got 25808\n",
      "Got 25912\n",
      "Got 26008\n",
      "Got 26112\n",
      "Got 26208\n",
      "Got 26312\n",
      "Got 26408\n",
      "Got 26512\n",
      "Got 26608\n",
      "Got 26712\n",
      "Got 26808\n",
      "Got 26912\n",
      "Got 27008\n",
      "Got 27112\n",
      "Got 27208\n",
      "Got 27312\n",
      "Got 27408\n",
      "Got 27512\n",
      "Got 27608\n",
      "Got 27712\n",
      "Got 27808\n",
      "Got 27912\n",
      "Got 28008\n",
      "Got 28112\n",
      "Got 28208\n",
      "Got 28312\n",
      "Got 28408\n",
      "Got 28512\n",
      "Got 28608\n",
      "Got 28712\n",
      "Got 28808\n",
      "Got 28912\n",
      "Got 29008\n",
      "Got 29112\n",
      "Got 29208\n",
      "Got 29312\n",
      "Got 29408\n",
      "Got 29512\n",
      "Got 29608\n",
      "Got 29712\n",
      "Got 29808\n",
      "Got 29912\n",
      "Got 30008\n",
      "Got 30112\n",
      "Got 30208\n",
      "Got 30312\n",
      "Got 30408\n",
      "Got 30512\n",
      "Got 30608\n",
      "Got 30712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "Got 1808\n",
      "Got 1912\n",
      "Got 2008\n",
      "Got 2112\n",
      "Got 2208\n",
      "Got 2312\n",
      "Got 2408\n",
      "Got 2512\n",
      "Got 2608\n",
      "Got 2712\n",
      "Got 2808\n",
      "Got 2912\n",
      "Got 3008\n",
      "Got 3112\n",
      "Got 3208\n",
      "Got 3312\n",
      "Got 3408\n",
      "\n",
      "\n",
      "Getting XLM similarities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/var/folders/xr/f9q8dphs5vq5mhqy843mnkv40000gn/T/ipykernel_7691/1127116239.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {('l1_' + key): torch.tensor(val[idx]) for key, val in self.l1_encodings.items()}\n",
      "/var/folders/xr/f9q8dphs5vq5mhqy843mnkv40000gn/T/ipykernel_7691/1127116239.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item2 = {('l2_' + key): torch.tensor(val[idx]) for key, val in self.l2_encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "Got 1808\n",
      "Got 1912\n",
      "Got 2008\n",
      "Got 2112\n",
      "Got 2208\n",
      "Got 2312\n",
      "Got 2408\n",
      "Got 2512\n",
      "Got 2608\n",
      "Got 2712\n",
      "Got 2808\n",
      "Got 2912\n",
      "Got 3008\n",
      "Got 3112\n",
      "Got 3208\n",
      "Got 3312\n",
      "Got 3408\n",
      "Got 3512\n",
      "Got 3608\n",
      "Got 3712\n",
      "Got 3808\n",
      "Got 3912\n",
      "Got 4008\n",
      "Got 4112\n",
      "Got 4208\n",
      "Got 4312\n",
      "Got 4408\n",
      "Got 4512\n",
      "Got 4608\n",
      "Got 4712\n",
      "Got 4808\n",
      "Got 4912\n",
      "Got 5008\n",
      "Got 5112\n",
      "Got 5208\n",
      "Got 5312\n",
      "Got 5408\n",
      "Got 5512\n",
      "Got 5608\n",
      "Got 5712\n",
      "Got 5808\n",
      "Got 5912\n",
      "Got 6008\n",
      "Got 6112\n",
      "Got 6208\n",
      "Got 6312\n",
      "Got 6408\n",
      "Got 6512\n",
      "Got 6608\n",
      "Got 6712\n",
      "Got 6808\n",
      "Got 6912\n",
      "Got 7008\n",
      "Got 7112\n",
      "Got 7208\n",
      "Got 7312\n",
      "Got 7408\n",
      "Got 7512\n",
      "Got 7608\n",
      "Got 7712\n",
      "Got 7808\n",
      "Got 7912\n",
      "Got 8008\n",
      "Got 8112\n",
      "Got 8208\n",
      "Got 8312\n",
      "Got 8408\n",
      "Got 8512\n",
      "Got 8608\n",
      "Got 8712\n",
      "Got 8808\n",
      "Got 8912\n",
      "Got 9008\n",
      "Got 9112\n",
      "Got 9208\n",
      "Got 9312\n",
      "Got 9408\n",
      "Got 9512\n",
      "Got 9608\n",
      "Got 9712\n",
      "Got 9808\n",
      "Got 9912\n",
      "Got 10008\n",
      "Got 10112\n",
      "Got 10208\n",
      "Got 10312\n",
      "Got 10408\n",
      "Got 10512\n",
      "Got 10608\n",
      "Got 10712\n",
      "Got 10808\n",
      "Got 10912\n",
      "Got 11008\n",
      "Got 11112\n",
      "Got 11208\n",
      "Got 11312\n",
      "Got 11408\n",
      "Got 11512\n",
      "Got 11608\n",
      "Got 11712\n",
      "Got 11808\n",
      "Got 11912\n",
      "Got 12008\n",
      "Got 12112\n",
      "Got 12208\n",
      "Got 12312\n",
      "Got 12408\n",
      "Got 12512\n",
      "Got 12608\n",
      "Got 12712\n",
      "Got 12808\n",
      "Got 12912\n",
      "Got 13008\n",
      "Got 13112\n",
      "Got 13208\n",
      "Got 13312\n",
      "Got 13408\n",
      "Got 13512\n",
      "Got 13608\n",
      "Got 13712\n",
      "Got 13808\n",
      "Got 13912\n",
      "Got 14008\n",
      "Got 14112\n",
      "Got 14208\n",
      "Got 14312\n",
      "Got 14408\n",
      "Got 14512\n",
      "Got 14608\n",
      "Got 14712\n",
      "Got 14808\n",
      "Got 14912\n",
      "Got 15008\n",
      "Got 15112\n",
      "Got 15208\n",
      "Got 15312\n",
      "Got 15408\n",
      "Got 15512\n",
      "Got 15608\n",
      "Got 15712\n",
      "Got 15808\n",
      "Got 15912\n",
      "Got 16008\n",
      "Got 16112\n",
      "Got 16208\n",
      "Got 16312\n",
      "Got 16408\n",
      "Got 16512\n",
      "Got 16608\n",
      "Got 16712\n",
      "Got 16808\n",
      "Got 16912\n",
      "Got 17008\n",
      "Got 17112\n",
      "Got 17208\n",
      "Got 17312\n",
      "Got 17408\n",
      "Got 17512\n",
      "Got 17608\n",
      "Got 17712\n",
      "Got 17808\n",
      "Got 17912\n",
      "Got 18008\n",
      "Got 18112\n",
      "Got 18208\n",
      "Got 18312\n",
      "Got 18408\n",
      "Got 18512\n",
      "Got 18608\n",
      "Got 18712\n",
      "Got 18808\n",
      "Got 18912\n",
      "Got 19008\n",
      "Got 19112\n",
      "Got 19208\n",
      "Got 19312\n",
      "Got 19408\n",
      "Got 19512\n",
      "Got 19608\n",
      "Got 19712\n",
      "Got 19808\n",
      "Got 19912\n",
      "Got 20008\n",
      "Got 20112\n",
      "Got 20208\n",
      "Got 20312\n",
      "Got 20408\n",
      "Got 20512\n",
      "Got 20608\n",
      "Got 20712\n",
      "Got 20808\n",
      "Got 20912\n",
      "Got 21008\n",
      "Got 21112\n",
      "Got 21208\n",
      "Got 21312\n",
      "Got 21408\n",
      "Got 21512\n",
      "Got 21608\n",
      "Got 21712\n",
      "Got 21808\n",
      "Got 21912\n",
      "Got 22008\n",
      "Got 22112\n",
      "Got 22208\n",
      "Got 22312\n",
      "Got 22408\n",
      "Got 22512\n",
      "Got 22608\n",
      "Got 22712\n",
      "Got 22808\n",
      "Got 22912\n",
      "Got 23008\n",
      "Got 23112\n",
      "Got 23208\n",
      "Got 23312\n",
      "Got 23408\n",
      "Got 23512\n",
      "Got 23608\n",
      "Got 23712\n",
      "Got 23808\n",
      "Got 23912\n",
      "Got 24008\n",
      "Got 24112\n",
      "Got 24208\n",
      "Got 24312\n",
      "Got 24408\n",
      "Got 24512\n",
      "Got 24608\n",
      "Got 24712\n",
      "Got 24808\n",
      "Got 24912\n",
      "Got 25008\n",
      "Got 25112\n",
      "Got 25208\n",
      "Got 25312\n",
      "Got 25408\n",
      "Got 25512\n",
      "Got 25608\n",
      "Got 25712\n",
      "Got 25808\n",
      "Got 25912\n",
      "Got 26008\n",
      "Got 26112\n",
      "Got 26208\n",
      "Got 26312\n",
      "Got 26408\n",
      "Got 26512\n",
      "Got 26608\n",
      "Got 26712\n",
      "Got 26808\n",
      "Got 26912\n",
      "Got 27008\n",
      "Got 27112\n",
      "Got 27208\n",
      "Got 27312\n",
      "Got 27408\n",
      "Got 27512\n",
      "Got 27608\n",
      "Got 27712\n",
      "Got 27808\n",
      "Got 27912\n",
      "Got 28008\n",
      "Got 28112\n",
      "Got 28208\n",
      "Got 28312\n",
      "Got 28408\n",
      "Got 28512\n",
      "Got 28608\n",
      "Got 28712\n",
      "Got 28808\n",
      "Got 28912\n",
      "Got 29008\n",
      "Got 29112\n",
      "Got 29208\n",
      "Got 29312\n",
      "Got 29408\n",
      "Got 29512\n",
      "Got 29608\n",
      "Got 29712\n",
      "Got 29808\n",
      "Got 29912\n",
      "Got 30008\n",
      "Got 30112\n",
      "Got 30208\n",
      "Got 30312\n",
      "Got 30408\n",
      "Got 30512\n",
      "Got 30608\n",
      "Got 30712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/var/folders/xr/f9q8dphs5vq5mhqy843mnkv40000gn/T/ipykernel_7691/1127116239.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {('l1_' + key): torch.tensor(val[idx]) for key, val in self.l1_encodings.items()}\n",
      "/var/folders/xr/f9q8dphs5vq5mhqy843mnkv40000gn/T/ipykernel_7691/1127116239.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item2 = {('l2_' + key): torch.tensor(val[idx]) for key, val in self.l2_encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "Got 1808\n",
      "Got 1912\n",
      "Got 2008\n",
      "Got 2112\n",
      "Got 2208\n",
      "Got 2312\n",
      "Got 2408\n",
      "Got 2512\n",
      "Got 2608\n",
      "Got 2712\n",
      "Got 2808\n",
      "Got 2912\n",
      "Got 3008\n",
      "Got 3112\n",
      "Got 3208\n",
      "Got 3312\n",
      "Got 3408\n",
      "\n",
      "Finnish-Swedish\n",
      "\n",
      "Using cpu device\n",
      "\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=1008, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") \n",
      "\n",
      "epoch 0\n",
      "                    Train set - loss: 0.665, accuracy: 0.805 \n",
      "                    Val set - loss: 0.665, accuracy: 0.798\n",
      "epoch 100\n",
      "                    Train set - loss: 0.42, accuracy: 0.82 \n",
      "                    Val set - loss: 0.42, accuracy: 0.821\n",
      "epoch 200\n",
      "                    Train set - loss: 0.343, accuracy: 0.82 \n",
      "                    Val set - loss: 0.345, accuracy: 0.818\n",
      "epoch 300\n",
      "                    Train set - loss: 0.34, accuracy: 0.821 \n",
      "                    Val set - loss: 0.333, accuracy: 0.829\n",
      "epoch 400\n",
      "                    Train set - loss: 0.331, accuracy: 0.828 \n",
      "                    Val set - loss: 0.337, accuracy: 0.824\n",
      "epoch 500\n",
      "                    Train set - loss: 0.33, accuracy: 0.826 \n",
      "                    Val set - loss: 0.338, accuracy: 0.816\n",
      "epoch 600\n",
      "                    Train set - loss: 0.326, accuracy: 0.823 \n",
      "                    Val set - loss: 0.323, accuracy: 0.828\n",
      "epoch 700\n",
      "                    Train set - loss: 0.327, accuracy: 0.817 \n",
      "                    Val set - loss: 0.324, accuracy: 0.825\n",
      "epoch 800\n",
      "                    Train set - loss: 0.315, accuracy: 0.822 \n",
      "                    Val set - loss: 0.326, accuracy: 0.821\n",
      "epoch 900\n",
      "                    Train set - loss: 0.311, accuracy: 0.822 \n",
      "                    Val set - loss: 0.329, accuracy: 0.81\n",
      "epoch 1000\n",
      "                    Train set - loss: 0.306, accuracy: 0.823 \n",
      "                    Val set - loss: 0.309, accuracy: 0.827\n",
      "epoch 1100\n",
      "                    Train set - loss: 0.297, accuracy: 0.825 \n",
      "                    Val set - loss: 0.316, accuracy: 0.819\n",
      "epoch 1200\n",
      "                    Train set - loss: 0.287, accuracy: 0.823 \n",
      "                    Val set - loss: 0.302, accuracy: 0.827\n",
      "epoch 1300\n",
      "                    Train set - loss: 0.278, accuracy: 0.819 \n",
      "                    Val set - loss: 0.299, accuracy: 0.818\n",
      "epoch 1400\n",
      "                    Train set - loss: 0.268, accuracy: 0.82 \n",
      "                    Val set - loss: 0.297, accuracy: 0.816\n",
      "epoch 1500\n",
      "                    Train set - loss: 0.248, accuracy: 0.835 \n",
      "                    Val set - loss: 0.274, accuracy: 0.84\n",
      "epoch 1600\n",
      "                    Train set - loss: 0.238, accuracy: 0.838 \n",
      "                    Val set - loss: 0.275, accuracy: 0.829\n",
      "epoch 1700\n",
      "                    Train set - loss: 0.225, accuracy: 0.843 \n",
      "                    Val set - loss: 0.273, accuracy: 0.825\n",
      "epoch 1800\n",
      "                    Train set - loss: 0.213, accuracy: 0.852 \n",
      "                    Val set - loss: 0.272, accuracy: 0.822\n",
      "epoch 1900\n",
      "                    Train set - loss: 0.207, accuracy: 0.852 \n",
      "                    Val set - loss: 0.264, accuracy: 0.834\n",
      "epoch 2000\n",
      "                    Train set - loss: 0.191, accuracy: 0.867 \n",
      "                    Val set - loss: 0.252, accuracy: 0.844\n",
      "epoch 2100\n",
      "                    Train set - loss: 0.18, accuracy: 0.873 \n",
      "                    Val set - loss: 0.254, accuracy: 0.845\n",
      "epoch 2200\n",
      "                    Train set - loss: 0.17, accuracy: 0.879 \n",
      "                    Val set - loss: 0.251, accuracy: 0.846\n",
      "epoch 2300\n",
      "                    Train set - loss: 0.163, accuracy: 0.88 \n",
      "                    Val set - loss: 0.246, accuracy: 0.852\n",
      "epoch 2400\n",
      "                    Train set - loss: 0.155, accuracy: 0.885 \n",
      "                    Val set - loss: 0.248, accuracy: 0.847\n",
      "epoch 2500\n",
      "                    Train set - loss: 0.148, accuracy: 0.887 \n",
      "                    Val set - loss: 0.251, accuracy: 0.848\n",
      "epoch 2600\n",
      "                    Train set - loss: 0.139, accuracy: 0.892 \n",
      "                    Val set - loss: 0.233, accuracy: 0.866\n",
      "epoch 2700\n",
      "                    Train set - loss: 0.133, accuracy: 0.891 \n",
      "                    Val set - loss: 0.24, accuracy: 0.859\n",
      "epoch 2800\n",
      "                    Train set - loss: 0.128, accuracy: 0.895 \n",
      "                    Val set - loss: 0.245, accuracy: 0.857\n",
      "epoch 2900\n",
      "                    Train set - loss: 0.123, accuracy: 0.897 \n",
      "                    Val set - loss: 0.247, accuracy: 0.859\n",
      "epoch 3000\n",
      "                    Train set - loss: 0.117, accuracy: 0.899 \n",
      "                    Val set - loss: 0.242, accuracy: 0.865\n",
      "epoch 3100\n",
      "                    Train set - loss: 0.111, accuracy: 0.902 \n",
      "                    Val set - loss: 0.246, accuracy: 0.859\n",
      "epoch 3200\n",
      "                    Train set - loss: 0.107, accuracy: 0.904 \n",
      "                    Val set - loss: 0.249, accuracy: 0.85\n",
      "epoch 3300\n",
      "                    Train set - loss: 0.106, accuracy: 0.902 \n",
      "                    Val set - loss: 0.25, accuracy: 0.857\n",
      "epoch 3400\n",
      "                    Train set - loss: 0.101, accuracy: 0.906 \n",
      "                    Val set - loss: 0.26, accuracy: 0.854\n",
      "epoch 3500\n",
      "                    Train set - loss: 0.095, accuracy: 0.909 \n",
      "                    Val set - loss: 0.258, accuracy: 0.857\n",
      "epoch 3600\n",
      "                    Train set - loss: 0.101, accuracy: 0.898 \n",
      "                    Val set - loss: 0.255, accuracy: 0.851\n",
      "epoch 3700\n",
      "                    Train set - loss: 0.095, accuracy: 0.906 \n",
      "                    Val set - loss: 0.241, accuracy: 0.866\n",
      "epoch 3800\n",
      "                    Train set - loss: 0.094, accuracy: 0.904 \n",
      "                    Val set - loss: 0.273, accuracy: 0.85\n",
      "epoch 3900\n",
      "                    Train set - loss: 0.086, accuracy: 0.912 \n",
      "                    Val set - loss: 0.271, accuracy: 0.857\n",
      "epoch 4000\n",
      "                    Train set - loss: 0.083, accuracy: 0.911 \n",
      "                    Val set - loss: 0.27, accuracy: 0.85\n",
      "epoch 4100\n",
      "                    Train set - loss: 0.083, accuracy: 0.913 \n",
      "                    Val set - loss: 0.279, accuracy: 0.847\n",
      "epoch 4200\n",
      "                    Train set - loss: 0.085, accuracy: 0.905 \n",
      "                    Val set - loss: 0.282, accuracy: 0.847\n",
      "epoch 4300\n",
      "                    Train set - loss: 0.08, accuracy: 0.913 \n",
      "                    Val set - loss: 0.286, accuracy: 0.861\n",
      "epoch 4400\n",
      "                    Train set - loss: 0.082, accuracy: 0.909 \n",
      "                    Val set - loss: 0.282, accuracy: 0.857\n",
      "epoch 4500\n",
      "                    Train set - loss: 0.084, accuracy: 0.906 \n",
      "                    Val set - loss: 0.295, accuracy: 0.855\n",
      "epoch 4600\n",
      "                    Train set - loss: 0.08, accuracy: 0.908 \n",
      "                    Val set - loss: 0.254, accuracy: 0.862\n",
      "epoch 4700\n",
      "                    Train set - loss: 0.078, accuracy: 0.91 \n",
      "                    Val set - loss: 0.294, accuracy: 0.85\n",
      "epoch 4800\n",
      "                    Train set - loss: 0.078, accuracy: 0.909 \n",
      "                    Val set - loss: 0.303, accuracy: 0.849\n",
      "epoch 4900\n",
      "                    Train set - loss: 0.079, accuracy: 0.906 \n",
      "                    Val set - loss: 0.3, accuracy: 0.847\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting logits from DNN\n",
      "Getting MBERT similarities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "Got 1808\n",
      "Got 1912\n",
      "Got 2008\n",
      "Got 2112\n",
      "Got 2208\n",
      "Got 2312\n",
      "Got 2408\n",
      "Got 2512\n",
      "Got 2608\n",
      "Got 2712\n",
      "Got 2808\n",
      "Got 2912\n",
      "Got 3008\n",
      "Got 3112\n",
      "Got 3208\n",
      "Got 3312\n",
      "Got 3408\n",
      "Got 3512\n",
      "Got 3608\n",
      "Got 3712\n",
      "Got 3808\n",
      "Got 3912\n",
      "Got 4008\n",
      "Got 4112\n",
      "Got 4208\n",
      "Got 4312\n",
      "Got 4408\n",
      "Got 4512\n",
      "Got 4608\n",
      "Got 4712\n",
      "Got 4808\n",
      "Got 4912\n",
      "Got 5008\n",
      "Got 5112\n",
      "Got 5208\n",
      "Got 5312\n",
      "Got 5408\n",
      "Got 5512\n",
      "Got 5608\n",
      "Got 5712\n",
      "Got 5808\n",
      "Got 5912\n",
      "Got 6008\n",
      "Got 6112\n",
      "Got 6208\n",
      "Got 6312\n",
      "Got 6408\n",
      "Got 6512\n",
      "Got 6608\n",
      "Got 6712\n",
      "Got 6808\n",
      "Got 6912\n",
      "Got 7008\n",
      "Got 7112\n",
      "Got 7208\n",
      "Got 7312\n",
      "Got 7408\n",
      "Got 7512\n",
      "Got 7608\n",
      "Got 7712\n",
      "Got 7808\n",
      "Got 7912\n",
      "Got 8008\n",
      "Got 8112\n",
      "Got 8208\n",
      "Got 8312\n",
      "Got 8408\n",
      "Got 8512\n",
      "Got 8608\n",
      "Got 8712\n",
      "Got 8808\n",
      "Got 8912\n",
      "Got 9008\n",
      "Got 9112\n",
      "Got 9208\n",
      "Got 9312\n",
      "Got 9408\n",
      "Got 9512\n",
      "Got 9608\n",
      "Got 9712\n",
      "Got 9808\n",
      "Got 9912\n",
      "Got 10008\n",
      "Got 10112\n",
      "Got 10208\n",
      "Got 10312\n",
      "Got 10408\n",
      "Got 10512\n",
      "Got 10608\n",
      "Got 10712\n",
      "Got 10808\n",
      "Got 10912\n",
      "Got 11008\n",
      "Got 11112\n",
      "Got 11208\n",
      "Got 11312\n",
      "Got 11408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "\n",
      "\n",
      "Getting XLM similarities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/var/folders/xr/f9q8dphs5vq5mhqy843mnkv40000gn/T/ipykernel_7691/1127116239.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {('l1_' + key): torch.tensor(val[idx]) for key, val in self.l1_encodings.items()}\n",
      "/var/folders/xr/f9q8dphs5vq5mhqy843mnkv40000gn/T/ipykernel_7691/1127116239.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item2 = {('l2_' + key): torch.tensor(val[idx]) for key, val in self.l2_encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "Got 1808\n",
      "Got 1912\n",
      "Got 2008\n",
      "Got 2112\n",
      "Got 2208\n",
      "Got 2312\n",
      "Got 2408\n",
      "Got 2512\n",
      "Got 2608\n",
      "Got 2712\n",
      "Got 2808\n",
      "Got 2912\n",
      "Got 3008\n",
      "Got 3112\n",
      "Got 3208\n",
      "Got 3312\n",
      "Got 3408\n",
      "Got 3512\n",
      "Got 3608\n",
      "Got 3712\n",
      "Got 3808\n",
      "Got 3912\n",
      "Got 4008\n",
      "Got 4112\n",
      "Got 4208\n",
      "Got 4312\n",
      "Got 4408\n",
      "Got 4512\n",
      "Got 4608\n",
      "Got 4712\n",
      "Got 4808\n",
      "Got 4912\n",
      "Got 5008\n",
      "Got 5112\n",
      "Got 5208\n",
      "Got 5312\n",
      "Got 5408\n",
      "Got 5512\n",
      "Got 5608\n",
      "Got 5712\n",
      "Got 5808\n",
      "Got 5912\n",
      "Got 6008\n",
      "Got 6112\n",
      "Got 6208\n",
      "Got 6312\n",
      "Got 6408\n",
      "Got 6512\n",
      "Got 6608\n",
      "Got 6712\n",
      "Got 6808\n",
      "Got 6912\n",
      "Got 7008\n",
      "Got 7112\n",
      "Got 7208\n",
      "Got 7312\n",
      "Got 7408\n",
      "Got 7512\n",
      "Got 7608\n",
      "Got 7712\n",
      "Got 7808\n",
      "Got 7912\n",
      "Got 8008\n",
      "Got 8112\n",
      "Got 8208\n",
      "Got 8312\n",
      "Got 8408\n",
      "Got 8512\n",
      "Got 8608\n",
      "Got 8712\n",
      "Got 8808\n",
      "Got 8912\n",
      "Got 9008\n",
      "Got 9112\n",
      "Got 9208\n",
      "Got 9312\n",
      "Got 9408\n",
      "Got 9512\n",
      "Got 9608\n",
      "Got 9712\n",
      "Got 9808\n",
      "Got 9912\n",
      "Got 10008\n",
      "Got 10112\n",
      "Got 10208\n",
      "Got 10312\n",
      "Got 10408\n",
      "Got 10512\n",
      "Got 10608\n",
      "Got 10712\n",
      "Got 10808\n",
      "Got 10912\n",
      "Got 11008\n",
      "Got 11112\n",
      "Got 11208\n",
      "Got 11312\n",
      "Got 11408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/var/folders/xr/f9q8dphs5vq5mhqy843mnkv40000gn/T/ipykernel_7691/1127116239.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {('l1_' + key): torch.tensor(val[idx]) for key, val in self.l1_encodings.items()}\n",
      "/var/folders/xr/f9q8dphs5vq5mhqy843mnkv40000gn/T/ipykernel_7691/1127116239.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item2 = {('l2_' + key): torch.tensor(val[idx]) for key, val in self.l2_encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "\n",
      "Kazakh-Russian\n",
      "\n",
      "Using cpu device\n",
      "\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=1224, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") \n",
      "\n",
      "epoch 0\n",
      "                    Train set - loss: 0.669, accuracy: 0.804 \n",
      "                    Val set - loss: 0.669, accuracy: 0.802\n",
      "epoch 100\n",
      "                    Train set - loss: 0.447, accuracy: 0.803 \n",
      "                    Val set - loss: 0.446, accuracy: 0.803\n",
      "epoch 200\n",
      "                    Train set - loss: 0.396, accuracy: 0.805 \n",
      "                    Val set - loss: 0.39, accuracy: 0.809\n",
      "epoch 300\n",
      "                    Train set - loss: 0.383, accuracy: 0.807 \n",
      "                    Val set - loss: 0.378, accuracy: 0.816\n",
      "epoch 400\n",
      "                    Train set - loss: 0.371, accuracy: 0.804 \n",
      "                    Val set - loss: 0.374, accuracy: 0.805\n",
      "epoch 500\n",
      "                    Train set - loss: 0.36, accuracy: 0.804 \n",
      "                    Val set - loss: 0.363, accuracy: 0.806\n",
      "epoch 600\n",
      "                    Train set - loss: 0.348, accuracy: 0.807 \n",
      "                    Val set - loss: 0.352, accuracy: 0.81\n",
      "epoch 700\n",
      "                    Train set - loss: 0.335, accuracy: 0.805 \n",
      "                    Val set - loss: 0.341, accuracy: 0.811\n",
      "epoch 800\n",
      "                    Train set - loss: 0.317, accuracy: 0.81 \n",
      "                    Val set - loss: 0.328, accuracy: 0.808\n",
      "epoch 900\n",
      "                    Train set - loss: 0.3, accuracy: 0.807 \n",
      "                    Val set - loss: 0.314, accuracy: 0.81\n",
      "epoch 1000\n",
      "                    Train set - loss: 0.279, accuracy: 0.812 \n",
      "                    Val set - loss: 0.299, accuracy: 0.809\n",
      "epoch 1100\n",
      "                    Train set - loss: 0.257, accuracy: 0.825 \n",
      "                    Val set - loss: 0.283, accuracy: 0.816\n",
      "epoch 1200\n",
      "                    Train set - loss: 0.237, accuracy: 0.836 \n",
      "                    Val set - loss: 0.269, accuracy: 0.816\n",
      "epoch 1300\n",
      "                    Train set - loss: 0.22, accuracy: 0.851 \n",
      "                    Val set - loss: 0.26, accuracy: 0.819\n",
      "epoch 1400\n",
      "                    Train set - loss: 0.207, accuracy: 0.859 \n",
      "                    Val set - loss: 0.251, accuracy: 0.819\n",
      "epoch 1500\n",
      "                    Train set - loss: 0.188, accuracy: 0.875 \n",
      "                    Val set - loss: 0.241, accuracy: 0.827\n",
      "epoch 1600\n",
      "                    Train set - loss: 0.18, accuracy: 0.878 \n",
      "                    Val set - loss: 0.233, accuracy: 0.834\n",
      "epoch 1700\n",
      "                    Train set - loss: 0.165, accuracy: 0.888 \n",
      "                    Val set - loss: 0.226, accuracy: 0.834\n",
      "epoch 1800\n",
      "                    Train set - loss: 0.157, accuracy: 0.89 \n",
      "                    Val set - loss: 0.214, accuracy: 0.845\n",
      "epoch 1900\n",
      "                    Train set - loss: 0.149, accuracy: 0.893 \n",
      "                    Val set - loss: 0.213, accuracy: 0.845\n",
      "epoch 2000\n",
      "                    Train set - loss: 0.139, accuracy: 0.898 \n",
      "                    Val set - loss: 0.209, accuracy: 0.844\n",
      "epoch 2100\n",
      "                    Train set - loss: 0.128, accuracy: 0.907 \n",
      "                    Val set - loss: 0.205, accuracy: 0.85\n",
      "epoch 2200\n",
      "                    Train set - loss: 0.126, accuracy: 0.904 \n",
      "                    Val set - loss: 0.201, accuracy: 0.85\n",
      "epoch 2300\n",
      "                    Train set - loss: 0.118, accuracy: 0.907 \n",
      "                    Val set - loss: 0.198, accuracy: 0.849\n",
      "epoch 2400\n",
      "                    Train set - loss: 0.112, accuracy: 0.909 \n",
      "                    Val set - loss: 0.193, accuracy: 0.859\n",
      "epoch 2500\n",
      "                    Train set - loss: 0.111, accuracy: 0.904 \n",
      "                    Val set - loss: 0.193, accuracy: 0.851\n",
      "epoch 2600\n",
      "                    Train set - loss: 0.106, accuracy: 0.906 \n",
      "                    Val set - loss: 0.195, accuracy: 0.851\n",
      "epoch 2700\n",
      "                    Train set - loss: 0.1, accuracy: 0.91 \n",
      "                    Val set - loss: 0.191, accuracy: 0.859\n",
      "epoch 2800\n",
      "                    Train set - loss: 0.093, accuracy: 0.915 \n",
      "                    Val set - loss: 0.188, accuracy: 0.857\n",
      "epoch 2900\n",
      "                    Train set - loss: 0.093, accuracy: 0.912 \n",
      "                    Val set - loss: 0.187, accuracy: 0.858\n",
      "epoch 3000\n",
      "                    Train set - loss: 0.093, accuracy: 0.908 \n",
      "                    Val set - loss: 0.188, accuracy: 0.863\n",
      "epoch 3100\n",
      "                    Train set - loss: 0.088, accuracy: 0.913 \n",
      "                    Val set - loss: 0.191, accuracy: 0.857\n",
      "epoch 3200\n",
      "                    Train set - loss: 0.088, accuracy: 0.91 \n",
      "                    Val set - loss: 0.188, accuracy: 0.858\n",
      "epoch 3300\n",
      "                    Train set - loss: 0.082, accuracy: 0.915 \n",
      "                    Val set - loss: 0.176, accuracy: 0.874\n",
      "epoch 3400\n",
      "                    Train set - loss: 0.084, accuracy: 0.911 \n",
      "                    Val set - loss: 0.19, accuracy: 0.857\n",
      "epoch 3500\n",
      "                    Train set - loss: 0.082, accuracy: 0.914 \n",
      "                    Val set - loss: 0.189, accuracy: 0.858\n",
      "epoch 3600\n",
      "                    Train set - loss: 0.083, accuracy: 0.908 \n",
      "                    Val set - loss: 0.186, accuracy: 0.863\n",
      "epoch 3700\n",
      "                    Train set - loss: 0.08, accuracy: 0.911 \n",
      "                    Val set - loss: 0.188, accuracy: 0.858\n",
      "epoch 3800\n",
      "                    Train set - loss: 0.078, accuracy: 0.912 \n",
      "                    Val set - loss: 0.189, accuracy: 0.866\n",
      "epoch 3900\n",
      "                    Train set - loss: 0.078, accuracy: 0.911 \n",
      "                    Val set - loss: 0.185, accuracy: 0.867\n",
      "epoch 4000\n",
      "                    Train set - loss: 0.075, accuracy: 0.915 \n",
      "                    Val set - loss: 0.195, accuracy: 0.855\n",
      "epoch 4100\n",
      "                    Train set - loss: 0.077, accuracy: 0.912 \n",
      "                    Val set - loss: 0.194, accuracy: 0.857\n",
      "epoch 4200\n",
      "                    Train set - loss: 0.075, accuracy: 0.913 \n",
      "                    Val set - loss: 0.186, accuracy: 0.873\n",
      "epoch 4300\n",
      "                    Train set - loss: 0.075, accuracy: 0.912 \n",
      "                    Val set - loss: 0.188, accuracy: 0.869\n",
      "epoch 4400\n",
      "                    Train set - loss: 0.074, accuracy: 0.914 \n",
      "                    Val set - loss: 0.196, accuracy: 0.86\n",
      "epoch 4500\n",
      "                    Train set - loss: 0.074, accuracy: 0.912 \n",
      "                    Val set - loss: 0.197, accuracy: 0.859\n",
      "epoch 4600\n",
      "                    Train set - loss: 0.072, accuracy: 0.916 \n",
      "                    Val set - loss: 0.192, accuracy: 0.869\n",
      "epoch 4700\n",
      "                    Train set - loss: 0.074, accuracy: 0.911 \n",
      "                    Val set - loss: 0.202, accuracy: 0.859\n",
      "epoch 4800\n",
      "                    Train set - loss: 0.072, accuracy: 0.912 \n",
      "                    Val set - loss: 0.196, accuracy: 0.86\n",
      "epoch 4900\n",
      "                    Train set - loss: 0.073, accuracy: 0.911 \n",
      "                    Val set - loss: 0.201, accuracy: 0.857\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting logits from DNN\n",
      "Getting MBERT similarities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m l2_test_balanced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(test_balanced[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_word\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting MBERT similarities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 148\u001b[0m train_alldata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMBERT_cos_sim\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mget_mbert_cos_sims\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml1_train_alldata\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml2_train_alldata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m test_alldata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMBERT_cos_sim\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_mbert_cos_sims(l1_test_alldata,l2_test_alldata)\n\u001b[1;32m    151\u001b[0m train_realdist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMBERT_cos_sim\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_realdist\u001b[38;5;241m.\u001b[39mmerge(pd\u001b[38;5;241m.\u001b[39mconcat([train_alldata,test_alldata]),\\\n\u001b[1;32m    152\u001b[0m                                                        on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloan_word\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_word\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMBERT_cos_sim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mget_mbert_cos_sims\u001b[0;34m(l1_data, l2_data)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#loop through dataset \u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[0;32m---> 20\u001b[0m     l1_vector \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml1_input_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml1_attention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     23\u001b[0m     l2_vector \u001b[38;5;241m=\u001b[39m base_model(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_input_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     24\u001b[0m                                   attention_mask\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_attention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     25\u001b[0m                                   return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     26\u001b[0m     sims \u001b[38;5;241m=\u001b[39m cos_s(l1_vector, l2_vector)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    987\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    989\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    990\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    991\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    994\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    995\u001b[0m )\n\u001b[0;32m--> 996\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1009\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    576\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    577\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    578\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    583\u001b[0m     )\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:513\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    510\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    511\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 513\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/modeling_utils.py:2928\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2925\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m   2926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m-> 2928\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:526\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    525\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 526\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:439\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 439\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    441\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mt/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f:\n",
    "    pairs = json.loads(f.read())\n",
    "\n",
    "for pair in pairs:\n",
    "    print(pair)\n",
    "    L1 = pairs[pair]['target']['name']\n",
    "    L2 = pairs[pair]['source']['name']\n",
    "    \n",
    "    # load datasets\n",
    "    prefix = f'../Datasets/production_train_test/{L1}-{L2}'\n",
    "    \n",
    "    train_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata.csv')\n",
    "    test_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata.csv')\n",
    "\n",
    "    train_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    test_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')\n",
    "\n",
    "    # get and pad PanPhon features for alldata split\n",
    "    get_panphon_features(train_alldata, test_alldata)\n",
    "    alldata_maxlen = (max(np.max(train_alldata['features_loan'].str.len()),\\\n",
    "                          np.max(test_alldata['features_loan'].str.len())),\\\n",
    "                      max(np.max(train_alldata['features_orig'].str.len()),\\\n",
    "                          np.max(test_alldata['features_orig'].str.len())))\n",
    "    pad_panphon_features(train_alldata, test_alldata, alldata_maxlen)\n",
    "\n",
    "    # add target labels\n",
    "    Y_train, Y_test = add_target_labels(train_alldata, test_alldata)\n",
    "\n",
    "    # make train and val splits\n",
    "    X_train, X_val, X_test, Y_train, Y_val = make_train_val_set(train_alldata, test_alldata, Y_train)\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test)\n",
    "\n",
    "    # instantiate network\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\nUsing {device} device\\n\")\n",
    "    \n",
    "    # set random seeds for reproducibility\n",
    "    np.random.seed(666)\n",
    "\n",
    "    model = NeuralNetwork(X_train.shape[1]).to(device)\n",
    "    print(model,\"\\n\")\n",
    "\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "    # train and plot losses, accuracy\n",
    "    train_losses, val_losses, train_accur, val_accur = \\\n",
    "        model.fit(X_train, Y_train, X_val, Y_val, criterion, optimizer)\n",
    "    model.plot_losses(train_losses,val_losses,train_accur,val_accur)\n",
    "\n",
    "    # get and pad PanPhon features for realdist and balanced splits\n",
    "    get_panphon_features(train_realdist,test_realdist)\n",
    "    pad_panphon_features(train_realdist,test_realdist,alldata_maxlen)\n",
    "\n",
    "    get_panphon_features(train_balanced,test_balanced)\n",
    "    pad_panphon_features(train_balanced,test_balanced,alldata_maxlen)\n",
    "\n",
    "    # create data to get logits for\n",
    "    X_train_alldata = torch.tensor(np.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                         np.array([x for x in train_alldata['features_orig']])])).to(device)\n",
    "    X_test_alldata = torch.tensor(np.hstack([np.array([x for x in test_alldata['features_loan']]),\\\n",
    "                        np.array([x for x in test_alldata['features_orig']])])).to(device)\n",
    "\n",
    "    X_train_realdist = torch.tensor(np.hstack([np.array([x for x in train_realdist['features_loan']]),\\\n",
    "                         np.array([x for x in train_realdist['features_orig']])])).to(device)\n",
    "    X_test_realdist = torch.tensor(np.hstack([np.array([x for x in test_realdist['features_loan']]),\\\n",
    "                        np.array([x for x in test_realdist['features_orig']])])).to(device)\n",
    "\n",
    "    X_train_balanced = torch.tensor(np.hstack([np.array([x for x in train_balanced['features_loan']]),\\\n",
    "                         np.array([x for x in train_balanced['features_orig']])])).to(device)\n",
    "    X_test_balanced = torch.tensor(np.hstack([np.array([x for x in test_balanced['features_loan']]),\\\n",
    "                        np.array([x for x in test_balanced['features_orig']])])).to(device)\n",
    "\n",
    "    # place model in eval mode and get logits from DNN for all datasets/splits\n",
    "    print(\"Getting logits from DNN\")\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_logits_dnn_alldata = model(X_train_alldata.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_alldata = model(X_test_alldata.float())[1].detach().cpu().numpy()\n",
    "        train_logits_dnn_realdist = model(X_train_realdist.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_realdist = model(X_test_realdist.float())[1].detach().cpu().numpy()\n",
    "        train_logits_dnn_balanced = model(X_train_balanced.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_balanced = model(X_test_balanced.float())[1].detach().cpu().numpy()\n",
    "\n",
    "    # remove PanPhon features from dataframe and add logits column\n",
    "    train_alldata = train_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_alldata['DNN_logits'] = train_logits_dnn_alldata\n",
    "\n",
    "    test_alldata = test_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_alldata['DNN_logits'] = test_logits_dnn_alldata\n",
    "\n",
    "    train_realdist = train_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_realdist['DNN_logits'] = train_logits_dnn_realdist\n",
    "\n",
    "    test_realdist = test_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_realdist['DNN_logits'] = test_logits_dnn_realdist\n",
    "\n",
    "    train_balanced = train_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_balanced['DNN_logits'] = train_logits_dnn_balanced\n",
    "\n",
    "    test_balanced = test_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_balanced['DNN_logits'] = test_logits_dnn_balanced\n",
    "\n",
    "    #set the seeds for reproducibility even though we are not fine-tuning or training and the weights \n",
    "    #for both these models are effectively frozen for our purpose \n",
    "    torch.manual_seed(7)\n",
    "    random.seed(7)\n",
    "    np.random.seed(7)\n",
    "\n",
    "    # Setting PyTorch's required configuration variables for reproducibility.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "\n",
    "    PRE_TRAINED_bert_MODEL = 'bert-base-multilingual-cased'\n",
    "    PRE_TRAINED_xlm_MODEL = 'xlm-mlm-100-1280'\n",
    "\n",
    "    MAXTOKENS = 5\n",
    "    BS = 8  # batch size\n",
    "\n",
    "    #list of loan-original words for train sets\n",
    "    l1_train_alldata = list(train_alldata[\"loan_word\"])\n",
    "    l2_train_alldata = list(train_alldata[\"original_word\"])\n",
    "\n",
    "    l1_train_realdist = list(train_realdist[\"loan_word\"])\n",
    "    l2_train_realdist = list(train_realdist[\"original_word\"])\n",
    "\n",
    "    l1_train_balanced = list(train_balanced[\"loan_word\"])\n",
    "    l2_train_balanced = list(train_balanced[\"original_word\"])\n",
    "\n",
    "    #list of loan-original words for test sets\n",
    "    l1_test_alldata = list(test_alldata[\"loan_word\"])\n",
    "    l2_test_alldata = list(test_alldata[\"original_word\"])\n",
    "\n",
    "    l1_test_realdist = list(test_realdist[\"loan_word\"])\n",
    "    l2_test_realdist = list(test_realdist[\"original_word\"])\n",
    "\n",
    "    l1_test_balanced = list(test_balanced[\"loan_word\"])\n",
    "    l2_test_balanced = list(test_balanced[\"original_word\"])\n",
    "\n",
    "    print(\"Getting MBERT similarities\")\n",
    "    train_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    test_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    train_realdist['MBERT_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    train_balanced['MBERT_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    test_realdist['MBERT_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    test_balanced['MBERT_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    print()\n",
    "    print(\"Getting XLM similarities\")\n",
    "    train_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    test_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    train_realdist['XLM_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    train_balanced['XLM_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "\n",
    "    test_realdist['XLM_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    test_balanced['XLM_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "        \n",
    "    train_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata.csv')\n",
    "    test_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata.csv')\n",
    "\n",
    "    train_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    test_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cadc6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
