{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d900aa",
   "metadata": {},
   "source": [
    "Assumes you have run `Train_Testset.ipynb` first to make the `alldata`, `realdist`, and `balanced` train/test splits for the chosen language pair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a3a5e",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6819d3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/rahulg/.local/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/rahulg/.local/lib/python3.8/site-packages (from seaborn) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/rahulg/.local/lib/python3.8/site-packages (from seaborn) (1.22.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/lib/python3/dist-packages (from seaborn) (3.1.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/rahulg/.local/lib/python3.8/site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/rahulg/.local/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/rahulg/.local/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas>=0.23->seaborn) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "091671b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import panphon\n",
    "import panphon.distance\n",
    "import editdistance # levenshtein\n",
    "import epitran\n",
    "import eng_to_ipa as eng\n",
    "from epitran.backoff import Backoff\n",
    "from googletrans import Translator\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#epitran.download.cedict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4977c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import nn, optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed2ae9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import io\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "726f5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer specific imports \n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup,\\\n",
    "    BertForSequenceClassification, BertForPreTraining, AutoModel\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel, XLMModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, mean_squared_error\n",
    "import time\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78b4fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    \n",
    "#device = torch.device(\"cuda:0:3\" if torch.cuda.is_available() else \"cpu\") ## specify the GPU id's, GPU id's start from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80da282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e42f7",
   "metadata": {},
   "source": [
    "# DNN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e92610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(n_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            \n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        logits_new = self.linear_relu_stack(x)\n",
    "        logits  = self.dropout(logits_new)\n",
    "        \n",
    "        return torch.sigmoid(logits), logits_new\n",
    "    \n",
    "    def fit(self, X_train, Y_train, X_val, Y_val, criterion, optimizer, n_epochs=5000):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accur = []\n",
    "        val_accur = []\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            y_pred, logits = self(X_train.float())\n",
    "\n",
    "            train_loss = criterion(y_pred, Y_train.float())\n",
    "\n",
    "            if epoch % (n_epochs // 50) == 0:\n",
    "                train_acc,_ = self.calculate_accuracy(Y_train, y_pred)\n",
    "\n",
    "                y_val_pred = self(X_val.float())[0]\n",
    "\n",
    "                val_loss = criterion(y_val_pred, Y_val.float())\n",
    "\n",
    "                val_acc, total_corr = self.calculate_accuracy(Y_val, y_val_pred)\n",
    "\n",
    "                print(f'''epoch {epoch}\n",
    "                    Train set - loss: {self.round_tensor(train_loss)}, accuracy: {self.round_tensor(train_acc)} \n",
    "                    Val set - loss: {self.round_tensor(val_loss)}, accuracy: {self.round_tensor(val_acc)}''')\n",
    "                \n",
    "                train_losses.append(train_loss.detach().cpu().numpy())\n",
    "                val_losses.append(val_loss.detach().cpu().numpy())\n",
    "\n",
    "                val_accur.append(val_acc.detach().cpu().numpy())\n",
    "                train_accur.append(train_acc.detach().cpu().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "        return train_losses,val_losses,train_accur,val_accur\n",
    "    \n",
    "    def calculate_accuracy(self, y_true, y_pred):\n",
    "        predicted = y_pred.ge(.5) \n",
    "        return ((y_true == predicted).sum().float() / len(y_true), (y_true == predicted).sum())\n",
    "    \n",
    "    def round_tensor(self, t, decimal_places=3):\n",
    "        return round(t.item(), decimal_places)\n",
    "    \n",
    "    def plot_losses(self, train_losses, val_losses, train_accur, val_accur):\n",
    "        epochs = range(1, len(train_accur) + 1)\n",
    "\n",
    "        plt.plot(epochs, train_accur, 'bo', label='Training acc')\n",
    "        plt.plot(epochs, val_accur, 'b', label='Vaidation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
    "        plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36154569",
   "metadata": {},
   "source": [
    "# MyDataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8b14ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overriding the Dataset class required for the use of PyTorch's data loader classes.\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, l1_encodings, l2_encodings):\n",
    "        self.l1_encodings = l1_encodings\n",
    "        self.l2_encodings = l2_encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {('l1_' + key): torch.tensor(val[idx]) for key, val in self.l1_encodings.items()}\n",
    "        item2 = {('l2_' + key): torch.tensor(val[idx]) for key, val in self.l2_encodings.items()}\n",
    "        item.update(item2)\n",
    "        # item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l1_encodings['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a47bf8",
   "metadata": {},
   "source": [
    "# Download LMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55834b9",
   "metadata": {},
   "source": [
    "# Pipeline function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4051b",
   "metadata": {},
   "source": [
    "## Get Panphon phonetic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4354d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_panphon_features(train_set, test_set):\n",
    "    #get phonetic features using PanPhon\n",
    "    ft = panphon.FeatureTable()   \n",
    "    \n",
    "    train_set['features_loan'] = train_set.apply(lambda x:ft.word_to_vector_list(x[\"loan_word_epitran\"],numeric=True ), axis=1)\n",
    "    train_set['features_orig'] = train_set.apply(lambda x:ft.word_to_vector_list(x[\"original_word_epitran\"],numeric=True ), axis=1)\n",
    "    test_set['features_loan'] = test_set.apply(lambda x:ft.word_to_vector_list(x[\"loan_word_epitran\"],numeric=True ), axis=1)\n",
    "    test_set['features_orig'] = test_set.apply(lambda x:ft.word_to_vector_list(x[\"original_word_epitran\"],numeric=True ), axis=1)\n",
    "\n",
    "    train_set['features_loan'] = train_set['features_loan'].apply(lambda x:sum(x, []))\n",
    "    train_set['features_orig'] = train_set['features_orig'].apply(lambda x:sum(x, []))\n",
    "    test_set['features_orig'] = test_set['features_orig'].apply(lambda x:sum(x, []))\n",
    "    test_set['features_loan'] = test_set['features_loan'].apply(lambda x:sum(x, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "413d0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_panphon_features(train_set, test_set, maxlen, verbose=False):\n",
    "    # Pad the phonetic features of the loan word and original word out to the maxlen \n",
    "    # of the features appearing in the training set (format: `<loan><pad 0s><orig><pad 0s>`).\n",
    "    train_set['features_loan'] = train_set['features_loan'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[0]-len(x)), 'constant'))\n",
    "    train_set['features_orig'] = train_set['features_orig'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[1]-len(x)), 'constant'))\n",
    "    test_set['features_loan'] = test_set['features_loan'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[0]-len(x)), 'constant'))\n",
    "    test_set['features_orig'] = test_set['features_orig'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[1]-len(x)), 'constant'))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Sample train features:\\n\",\\\n",
    "                train_set['features_loan'][np.random.randint(len(train_set['features_loan']))],\\\n",
    "                train_set['features_orig'][np.random.randint(len(train_set['features_loan']))])\n",
    "\n",
    "        print(\"Sample test features:\\n\",\\\n",
    "                test_set['features_loan'][np.random.randint(len(test_set['features_loan']))],\\\n",
    "                test_set['features_orig'][np.random.randint(len(test_set['features_orig']))])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a031511",
   "metadata": {},
   "source": [
    "## Add target labels and make train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "900f4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target_labels(train_set, test_set):\n",
    "    Y_train = np.array([y for y in train_set['label_bin']])\n",
    "    Y_test = np.array([y for y in test_set['label_bin']])\n",
    "    return Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e93f3aa",
   "metadata": {},
   "source": [
    "Make a validation split for training the DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16fd11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_val_set(train_set, test_set, Y_train):\n",
    "    X_train = np.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                np.array([x for x in train_alldata['features_orig']])])\n",
    "    X_test = np.hstack([np.array([x for x in test_alldata['features_loan']]),\\\n",
    "                np.array([x for x in test_alldata['features_orig']])])\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2,\\\n",
    "                                                      random_state=1, stratify=Y_train)\n",
    "    return X_train, X_val, X_test, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee312b",
   "metadata": {},
   "source": [
    "Make tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44851fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "    X_train = torch.tensor(X_train).to(device)\n",
    "    Y_train = torch.tensor(Y_train).to(device).reshape((-1,1))\n",
    "\n",
    "    X_val = torch.tensor(X_val).to(device)\n",
    "    Y_val = torch.tensor(Y_val).to(device).reshape((-1,1))\n",
    "    \n",
    "    X_test = torch.tensor(X_test).to(device)\n",
    "    Y_test = torch.tensor(Y_test).to(device).reshape((-1,1))\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40b267",
   "metadata": {},
   "source": [
    "## Get cosine similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683ed59",
   "metadata": {},
   "source": [
    "MBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643675a",
   "metadata": {},
   "source": [
    "XLM-100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcffe48",
   "metadata": {},
   "source": [
    "# Load `language-pairs.json` list and run pipeline for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86256869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assamese-Bengali\n"
     ]
    }
   ],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f: # for getting logits from all languages\n",
    " \n",
    "    \n",
    "    pairs = json.loads(f.read())\n",
    "for pair in pairs:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23084e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persian-Arabic\n",
      "Hungarian-German\n",
      "German-Italian\n",
      "Catalan-Arabic\n"
     ]
    }
   ],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs-holdout.json', 'r') as f: # for getting logits from all languages\n",
    " \n",
    "    \n",
    "    pairs = json.loads(f.read())\n",
    "for pair in pairs:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "189eca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assamese-Bengali\n",
      "\n",
      "Using cpu device\n",
      "\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=1272, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") \n",
      "\n",
      "epoch 0\n",
      "                    Train set - loss: 0.699, accuracy: 0.336 \n",
      "                    Val set - loss: 0.699, accuracy: 0.34\n",
      "epoch 100\n",
      "                    Train set - loss: 0.633, accuracy: 0.644 \n",
      "                    Val set - loss: 0.643, accuracy: 0.622\n",
      "epoch 200\n",
      "                    Train set - loss: 0.606, accuracy: 0.639 \n",
      "                    Val set - loss: 0.627, accuracy: 0.612\n",
      "epoch 300\n",
      "                    Train set - loss: 0.579, accuracy: 0.638 \n",
      "                    Val set - loss: 0.625, accuracy: 0.628\n",
      "epoch 400\n",
      "                    Train set - loss: 0.542, accuracy: 0.679 \n",
      "                    Val set - loss: 0.65, accuracy: 0.537\n",
      "epoch 500\n",
      "                    Train set - loss: 0.5, accuracy: 0.728 \n",
      "                    Val set - loss: 0.605, accuracy: 0.617\n",
      "epoch 600\n",
      "                    Train set - loss: 0.439, accuracy: 0.814 \n",
      "                    Val set - loss: 0.598, accuracy: 0.644\n",
      "epoch 700\n",
      "                    Train set - loss: 0.388, accuracy: 0.838 \n",
      "                    Val set - loss: 0.572, accuracy: 0.713\n",
      "epoch 800\n",
      "                    Train set - loss: 0.332, accuracy: 0.88 \n",
      "                    Val set - loss: 0.599, accuracy: 0.681\n",
      "epoch 900\n",
      "                    Train set - loss: 0.287, accuracy: 0.883 \n",
      "                    Val set - loss: 0.571, accuracy: 0.707\n",
      "epoch 1000\n",
      "                    Train set - loss: 0.246, accuracy: 0.896 \n",
      "                    Val set - loss: 0.589, accuracy: 0.665\n",
      "epoch 1100\n",
      "                    Train set - loss: 0.196, accuracy: 0.928 \n",
      "                    Val set - loss: 0.59, accuracy: 0.691\n",
      "epoch 1200\n",
      "                    Train set - loss: 0.185, accuracy: 0.924 \n",
      "                    Val set - loss: 0.584, accuracy: 0.697\n",
      "epoch 1300\n",
      "                    Train set - loss: 0.163, accuracy: 0.92 \n",
      "                    Val set - loss: 0.601, accuracy: 0.707\n",
      "epoch 1400\n",
      "                    Train set - loss: 0.137, accuracy: 0.939 \n",
      "                    Val set - loss: 0.592, accuracy: 0.734\n",
      "epoch 1500\n",
      "                    Train set - loss: 0.126, accuracy: 0.928 \n",
      "                    Val set - loss: 0.613, accuracy: 0.718\n",
      "epoch 1600\n",
      "                    Train set - loss: 0.13, accuracy: 0.917 \n",
      "                    Val set - loss: 0.618, accuracy: 0.718\n",
      "epoch 1700\n",
      "                    Train set - loss: 0.126, accuracy: 0.912 \n",
      "                    Val set - loss: 0.676, accuracy: 0.713\n",
      "epoch 1800\n",
      "                    Train set - loss: 0.115, accuracy: 0.917 \n",
      "                    Val set - loss: 0.569, accuracy: 0.75\n",
      "epoch 1900\n",
      "                    Train set - loss: 0.113, accuracy: 0.917 \n",
      "                    Val set - loss: 0.653, accuracy: 0.755\n",
      "epoch 2000\n",
      "                    Train set - loss: 0.101, accuracy: 0.927 \n",
      "                    Val set - loss: 0.706, accuracy: 0.707\n",
      "epoch 2100\n",
      "                    Train set - loss: 0.103, accuracy: 0.917 \n",
      "                    Val set - loss: 0.725, accuracy: 0.723\n",
      "epoch 2200\n",
      "                    Train set - loss: 0.096, accuracy: 0.924 \n",
      "                    Val set - loss: 0.752, accuracy: 0.697\n",
      "epoch 2300\n",
      "                    Train set - loss: 0.089, accuracy: 0.921 \n",
      "                    Val set - loss: 0.694, accuracy: 0.723\n",
      "epoch 2400\n",
      "                    Train set - loss: 0.1, accuracy: 0.916 \n",
      "                    Val set - loss: 0.723, accuracy: 0.755\n",
      "epoch 2500\n",
      "                    Train set - loss: 0.089, accuracy: 0.927 \n",
      "                    Val set - loss: 0.723, accuracy: 0.718\n",
      "epoch 2600\n",
      "                    Train set - loss: 0.116, accuracy: 0.901 \n",
      "                    Val set - loss: 0.712, accuracy: 0.729\n",
      "epoch 2700\n",
      "                    Train set - loss: 0.081, accuracy: 0.937 \n",
      "                    Val set - loss: 0.733, accuracy: 0.75\n",
      "epoch 2800\n",
      "                    Train set - loss: 0.093, accuracy: 0.917 \n",
      "                    Val set - loss: 0.758, accuracy: 0.718\n",
      "epoch 2900\n",
      "                    Train set - loss: 0.091, accuracy: 0.919 \n",
      "                    Val set - loss: 0.785, accuracy: 0.755\n",
      "epoch 3000\n",
      "                    Train set - loss: 0.08, accuracy: 0.928 \n",
      "                    Val set - loss: 0.827, accuracy: 0.718\n",
      "epoch 3100\n",
      "                    Train set - loss: 0.097, accuracy: 0.905 \n",
      "                    Val set - loss: 0.803, accuracy: 0.739\n",
      "epoch 3200\n",
      "                    Train set - loss: 0.095, accuracy: 0.917 \n",
      "                    Val set - loss: 0.802, accuracy: 0.745\n",
      "epoch 3300\n",
      "                    Train set - loss: 0.087, accuracy: 0.935 \n",
      "                    Val set - loss: 0.817, accuracy: 0.739\n",
      "epoch 3400\n",
      "                    Train set - loss: 0.081, accuracy: 0.939 \n",
      "                    Val set - loss: 0.835, accuracy: 0.745\n",
      "epoch 3500\n",
      "                    Train set - loss: 0.091, accuracy: 0.924 \n",
      "                    Val set - loss: 0.793, accuracy: 0.723\n",
      "epoch 3600\n",
      "                    Train set - loss: 0.081, accuracy: 0.931 \n",
      "                    Val set - loss: 0.806, accuracy: 0.761\n",
      "epoch 3700\n",
      "                    Train set - loss: 0.086, accuracy: 0.933 \n",
      "                    Val set - loss: 0.816, accuracy: 0.766\n",
      "epoch 3800\n",
      "                    Train set - loss: 0.081, accuracy: 0.931 \n",
      "                    Val set - loss: 0.886, accuracy: 0.75\n",
      "epoch 3900\n",
      "                    Train set - loss: 0.091, accuracy: 0.912 \n",
      "                    Val set - loss: 0.872, accuracy: 0.713\n",
      "epoch 4000\n",
      "                    Train set - loss: 0.076, accuracy: 0.925 \n",
      "                    Val set - loss: 0.911, accuracy: 0.745\n",
      "epoch 4100\n",
      "                    Train set - loss: 0.089, accuracy: 0.917 \n",
      "                    Val set - loss: 0.914, accuracy: 0.713\n",
      "epoch 4200\n",
      "                    Train set - loss: 0.083, accuracy: 0.936 \n",
      "                    Val set - loss: 0.892, accuracy: 0.755\n",
      "epoch 4300\n",
      "                    Train set - loss: 0.084, accuracy: 0.925 \n",
      "                    Val set - loss: 0.819, accuracy: 0.745\n",
      "epoch 4400\n",
      "                    Train set - loss: 0.07, accuracy: 0.94 \n",
      "                    Val set - loss: 0.757, accuracy: 0.745\n",
      "epoch 4500\n",
      "                    Train set - loss: 0.086, accuracy: 0.924 \n",
      "                    Val set - loss: 0.952, accuracy: 0.718\n",
      "epoch 4600\n",
      "                    Train set - loss: 0.081, accuracy: 0.927 \n",
      "                    Val set - loss: 0.909, accuracy: 0.729\n",
      "epoch 4700\n",
      "                    Train set - loss: 0.075, accuracy: 0.935 \n",
      "                    Val set - loss: 0.902, accuracy: 0.713\n",
      "epoch 4800\n",
      "                    Train set - loss: 0.102, accuracy: 0.904 \n",
      "                    Val set - loss: 0.921, accuracy: 0.729\n",
      "epoch 4900\n",
      "                    Train set - loss: 0.079, accuracy: 0.923 \n",
      "                    Val set - loss: 0.997, accuracy: 0.734\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 4)\n",
      "torch.Size([9999, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(10000, 5)\n",
      "torch.Size([10000, 1272])\n",
      "Getting logits from DNN\n",
      "(8576, 5)\n",
      "torch.Size([8576, 1272])\n",
      "Getting logits from DNN\n"
     ]
    }
   ],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f:\n",
    "    pairs = json.loads(f.read())\n",
    "\n",
    "for pair in pairs:\n",
    "    print(pair)\n",
    "    L1 = pairs[pair]['target']['name']\n",
    "    L2 = pairs[pair]['source']['name']\n",
    "    \n",
    "    # load datasets\n",
    "    prefix = f'../Datasets/production_train_test/{L1}-{L2}'\n",
    "    i = 1\n",
    "\n",
    "    train_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata_nohn.csv')\n",
    "    test_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata_nohn.csv')\n",
    "\n",
    "    #train_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    #test_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    #train_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    #test_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')\n",
    "\n",
    "    # get and pad PanPhon features for alldata split\n",
    "    get_panphon_features(train_alldata, test_alldata)\n",
    "    alldata_maxlen = (636,636)\n",
    "    #alldata_maxlen = (max(np.max(train_alldata['features_loan'].str.len()),\\\n",
    "    #                      np.max(test_alldata['features_loan'].str.len())),\\\n",
    "    #                  max(np.max(train_alldata['features_orig'].str.len()),\\\n",
    "    #                      np.max(test_alldata['features_orig'].str.len())))\n",
    "    pad_panphon_features(train_alldata, test_alldata, alldata_maxlen)\n",
    "\n",
    "    # add target labels\n",
    "    Y_train, Y_test = add_target_labels(train_alldata, test_alldata)\n",
    "\n",
    "    # make train and val splits\n",
    "    X_train, X_val, X_test, Y_train, Y_val = make_train_val_set(train_alldata, test_alldata, Y_train)\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test)\n",
    "\n",
    "    # instantiate network\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\nUsing {device} device\\n\")\n",
    "    \n",
    "    # set random seeds for reproducibility\n",
    "    np.random.seed(666)\n",
    "\n",
    "    model = NeuralNetwork(X_train.shape[1]).to(device)\n",
    "    print(model,\"\\n\")\n",
    "\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "    # train and plot losses, accuracy\n",
    "    train_losses, val_losses, train_accur, val_accur = \\\n",
    "        model.fit(X_train, Y_train, X_val, Y_val, criterion, optimizer)\n",
    "    model.plot_losses(train_losses,val_losses,train_accur,val_accur)\n",
    "    \n",
    "    # save trained model on noHN data to distinct variable\n",
    "    nohn_model = model\n",
    "    i = 1\n",
    "    while i <= 105:\n",
    "        # get and pad PanPhon features for realdist and balanced splits\n",
    "        #get_panphon_features(train_realdist,test_realdist)\n",
    "        #pad_panphon_features(train_realdist,test_realdist,alldata_maxlen)\n",
    "\n",
    "        #get_panphon_features(train_balanced,test_balanced)\n",
    "        #pad_panphon_features(train_balanced,test_balanced,alldata_maxlen)\n",
    "\n",
    "        # create data to get logits for\n",
    "        # read_csv for full pairing\n",
    "        testPairings_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata_cognates-' + str(i) + '.csv')\n",
    "        print(testPairings_alldata.shape)\n",
    "\n",
    "    \n",
    "        # add panphon features\n",
    "        get_panphon_features(train_alldata, testPairings_alldata)\n",
    "        alldata_maxlen = (max(np.max(train_alldata['features_loan'].str.len()),\\\n",
    "                              np.max(testPairings_alldata['features_loan'].str.len())),\\\n",
    "                          max(np.max(train_alldata['features_orig'].str.len()),\\\n",
    "                              np.max(testPairings_alldata['features_orig'].str.len())))\n",
    "        pad_panphon_features(train_alldata, testPairings_alldata, alldata_maxlen)\n",
    "    \n",
    "        #X_train_alldata = torch.tensor(n\n",
    "        #                               p.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                #         np.array([x for x in train_alldata['features_orig']])])).to(device)\n",
    "        X_testPairings_alldata = torch.tensor(np.hstack([np.array([x for x in testPairings_alldata['features_loan']]),\\\n",
    "                            np.array([x for x in testPairings_alldata['features_orig']])])).to(device)\n",
    "        print(X_testPairings_alldata.shape)\n",
    "    \n",
    "        #X_train_realdist = torch.tensor(np.hstack([np.array([x for x in train_realdist['features_loan']]),\\\n",
    "         #                    np.array([x for x in train_realdist['features_orig']])])).to(device)\n",
    "        #X_test_realdist = torch.tensor(np.hstack([np.array([x for x in test_realdist['features_loan']]),\\\n",
    "         #                   np.array([x for x in test_realdist['features_orig']])])).to(device)\n",
    "\n",
    "        #X_train_balanced = torch.tensor(np.hstack([np.array([x for x in train_balanced['features_loan']]),\\\n",
    "         #                    np.array([x for x in train_balanced['features_orig']])])).to(device)\n",
    "        #X_test_balanced = torch.tensor(np.hstack([np.array([x for x in test_balanced['features_loan']]),\\\n",
    "         #                   np.array([x for x in test_balanced['features_orig']])])).to(device)\n",
    "\n",
    "        # place model in eval mode and get logits from DNN for all datasets/splits\n",
    "        print(\"Getting logits from DNN\")\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            #train_logits_dnn_alldata = model(X_train_alldata.float())[1].detach().cpu().numpy()\n",
    "            test_logits_dnn_alldata = model(X_testPairings_alldata.float())[1].detach().cpu().numpy()\n",
    "           # train_logits_dnn_realdist = model(X_train_realdist.float())[1].detach().cpu().numpy()\n",
    "           # test_logits_dnn_realdist = model(X_test_realdist.float())[1].detach().cpu().numpy()\n",
    "          #  train_logits_dnn_balanced = model(X_train_balanced.float())[1].detach().cpu().numpy()\n",
    "         #   test_logits_dnn_balanced = model(X_test_balanced.float())[1].detach().cpu().numpy()\n",
    "\n",
    "        # remove PanPhon features from dataframe and add logits column\n",
    "        #train_alldata = train_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "        #train_alldata['DNN_logits'] = train_logits_dnn_alldata\n",
    "\n",
    "        testPairings_alldata = testPairings_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "        testPairings_alldata['DNN_logits'] = test_logits_dnn_alldata\n",
    "\n",
    "        #train_realdist = train_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "        #train_realdist['DNN_logits'] = train_logits_dnn_realdist\n",
    "\n",
    "        #test_realdist = test_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "        #test_realdist['DNN_logits'] = test_logits_dnn_realdist\n",
    "\n",
    "       # train_balanced = train_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "        #train_balanced['DNN_logits'] = train_logits_dnn_balanced\n",
    "\n",
    "        #test_balanced = test_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "        #test_balanced['DNN_logits'] = test_logits_dnn_balanced\n",
    "    #stop here\n",
    "   \n",
    "        #start here again    \n",
    "        train_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata_cognates.csv')\n",
    "        testPairings_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata_cognates' + str(i) + '.csv')\n",
    "\n",
    "        #train_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "        #test_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "        #train_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "        #test_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6f72eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_test_alldata,l2_test_alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "821e89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_balanced['MBERT_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "#                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23111eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#print(train_realdist.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b372a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assamese-Bengali\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label_bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_bin'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m pad_panphon_features(train_alldata, test_alldata, alldata_maxlen)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# add target labels\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m Y_train, Y_test \u001b[38;5;241m=\u001b[39m \u001b[43madd_target_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_alldata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_alldata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# make train and val splits\u001b[39;00m\n\u001b[1;32m     37\u001b[0m X_train, X_val, X_test, Y_train, Y_val \u001b[38;5;241m=\u001b[39m make_train_val_set(train_alldata, test_alldata, Y_train)\n",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36madd_target_labels\u001b[0;34m(train_set, test_set)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_target_labels\u001b[39m(train_set, test_set):\n\u001b[1;32m      2\u001b[0m     Y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([y \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m train_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_bin\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m----> 3\u001b[0m     Y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([y \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Y_train, Y_test\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_bin'"
     ]
    }
   ],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f: # for getting logits from all languages\n",
    " \n",
    "    \n",
    "    pairs = json.loads(f.read())\n",
    "\n",
    "for pair in pairs:\n",
    "    print(pair)\n",
    "    L1 = pairs[pair]['target']['name']\n",
    "    L2 = pairs[pair]['source']['name']\n",
    "    \n",
    "    # load datasets\n",
    "    prefix = f'../Datasets/production_train_test/{L1}-{L2}'\n",
    "    \n",
    "    train_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata_cognates.csv')\n",
    "    test_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata_cognates.csv')\n",
    "\n",
    "    #train_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    #test_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')\n",
    "\n",
    "    # get and pad PanPhon features for alldata split\n",
    "    get_panphon_features(train_alldata, test_alldata)\n",
    "    alldata_maxlen = (max(np.max(train_alldata['features_loan'].str.len()),\\\n",
    "                          np.max(test_alldata['features_loan'].str.len())),\\\n",
    "                      max(np.max(train_alldata['features_orig'].str.len()),\\\n",
    "                          np.max(test_alldata['features_orig'].str.len())))\n",
    "    pad_panphon_features(train_alldata, test_alldata, alldata_maxlen)\n",
    "\n",
    "    # add target labels\n",
    "    Y_train, Y_test = add_target_labels(train_alldata, test_alldata)\n",
    "\n",
    "    # make train and val splits\n",
    "    X_train, X_val, X_test, Y_train, Y_val = make_train_val_set(train_alldata, test_alldata, Y_train)\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test)\n",
    "\n",
    "    # instantiate network\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\nUsing {device} device\\n\")\n",
    "    \n",
    "    # set random seeds for reproducibility\n",
    "    np.random.seed(666)\n",
    "\n",
    "    model = NeuralNetwork(X_train.shape[1]).to(device)\n",
    "    print(model,\"\\n\")\n",
    "\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "    # train and plot losses, accuracy\n",
    "    train_losses, val_losses, train_accur, val_accur = \\\n",
    "        model.fit(X_train, Y_train, X_val, Y_val, criterion, optimizer)\n",
    "    model.plot_losses(train_losses,val_losses,train_accur,val_accur)\n",
    "\n",
    "    # get and pad PanPhon features for realdist and balanced splits\n",
    "    #get_panphon_features(train_realdist,test_realdist)\n",
    "    #pad_panphon_features(train_realdist,test_realdist,alldata_maxlen)\n",
    "\n",
    "    #get_panphon_features(train_balanced,test_balanced)\n",
    "    #pad_panphon_features(train_balanced,test_balanced,alldata_maxlen)\n",
    "\n",
    "    # create data to get logits for\n",
    "    X_train_alldata = torch.tensor(np.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                         np.array([x for x in train_alldata['features_orig']])])).to(device)\n",
    "    X_test_alldata = torch.tensor(np.hstack([np.array([x for x in test_alldata['features_loan']]),\\\n",
    "                        np.array([x for x in test_alldata['features_orig']])])).to(device)\n",
    "\n",
    "    #X_train_realdist = torch.tensor(np.hstack([np.array([x for x in train_realdist['features_loan']]),\\\n",
    "     #                    np.array([x for x in train_realdist['features_orig']])])).to(device)\n",
    "    #X_test_realdist = torch.tensor(np.hstack([np.array([x for x in test_realdist['features_loan']]),\\\n",
    "    #                    np.array([x for x in test_realdist['features_orig']])])).to(device)\n",
    "\n",
    "   # X_train_balanced = torch.tensor(np.hstack([np.array([x for x in train_balanced['features_loan']]),\\\n",
    "    #                     np.array([x for x in train_balanced['features_orig']])])).to(device)\n",
    "    #X_test_balanced = torch.tensor(np.hstack([np.array([x for x in test_balanced['features_loan']]),\\\n",
    "    #                    np.array([x for x in test_balanced['features_orig']])])).to(device)\n",
    "\n",
    "    # place model in eval mode and get logits from DNN for all datasets/splits\n",
    "    print(\"Getting logits from DNN\")\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_logits_dnn_alldata = model(X_train_alldata.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_alldata = model(X_test_alldata.float())[1].detach().cpu().numpy()\n",
    "        #train_logits_dnn_realdist = model(X_train_realdist.float())[1].detach().cpu().numpy()\n",
    "        #test_logits_dnn_realdist = model(X_test_realdist.float())[1].detach().cpu().numpy()\n",
    "        #train_logits_dnn_balanced = model(X_train_balanced.float())[1].detach().cpu().numpy()\n",
    "        #test_logits_dnn_balanced = model(X_test_balanced.float())[1].detach().cpu().numpy()\n",
    "\n",
    "    # remove PanPhon features from dataframe and add logits column\n",
    "    #train_alldata = train_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    #train_alldata['DNN_logits'] = train_logits_dnn_alldata\n",
    "\n",
    "    test_alldata = test_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_alldata['DNN_logits'] = test_logits_dnn_alldata\n",
    "\n",
    "   # train_realdist = train_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "   # train_realdist['DNN_logits'] = train_logits_dnn_realdist\n",
    "\n",
    "    #test_realdist = test_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    #test_realdist['DNN_logits'] = test_logits_dnn_realdist\n",
    "\n",
    "    #train_balanced = train_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    #train_balanced['DNN_logits'] = train_logits_dnn_balanced\n",
    "\n",
    "    #test_balanced = test_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    #test_balanced['DNN_logits'] = test_logits_dnn_balanced\n",
    "\n",
    "    #set the seeds for reproducibility even though we are not fine-tuning or training and the weights \n",
    "    #for both these models are effectively frozen for our purpose \n",
    "    torch.manual_seed(7)\n",
    "    random.seed(7)\n",
    "    np.random.seed(7)\n",
    "\n",
    "    # Setting PyTorch's required configuration variables for reproducibility.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "\n",
    "    PRE_TRAINED_bert_MODEL = 'bert-base-multilingual-cased'\n",
    "    PRE_TRAINED_xlm_MODEL = 'xlm-mlm-100-1280'\n",
    "\n",
    "    MAXTOKENS = 5\n",
    "    MAXTOKENS_XLM = 9\n",
    "    BS = 8  # batch size\n",
    "\n",
    "    #list of loan-original words for train sets\n",
    "    l1_train_alldata = list(train_alldata[\"loan_word\"])\n",
    "    l2_train_alldata = list(train_alldata[\"original_word\"])\n",
    "\n",
    "    #l1_train_realdist = list(train_realdist[\"loan_word\"])\n",
    "    #l2_train_realdist = list(train_realdist[\"original_word\"])\n",
    "\n",
    "    #l1_train_balanced = list(train_balanced[\"loan_word\"])\n",
    "    #l2_train_balanced = list(train_balanced[\"original_word\"])\n",
    "\n",
    "    #list of loan-original words for test sets\n",
    "    l1_test_alldata = list(test_alldata[\"loan_word\"])\n",
    "    l2_test_alldata = list(test_alldata[\"original_word\"])\n",
    "\n",
    "    #l1_test_realdist = list(test_realdist[\"loan_word\"])\n",
    "    #l2_test_realdist = list(test_realdist[\"original_word\"])\n",
    "\n",
    "    #l1_test_balanced = list(test_balanced[\"loan_word\"])\n",
    "    #l2_test_balanced = list(test_balanced[\"original_word\"])\n",
    "\n",
    "    print(\"Getting MBERT similarities\")\n",
    "    #train_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    #test_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    #train_realdist['MBERT_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "  #                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    #train_balanced['MBERT_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "#                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    #test_realdist['MBERT_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    " #                                                        on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    #test_balanced['MBERT_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "  #                                                       on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    print()\n",
    "    print(\"Getting XLM similarities\")\n",
    "    #train_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    #test_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    #train_realdist['XLM_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "     #                                                      on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    #train_balanced['XLM_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "#                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "\n",
    " #   test_realdist['XLM_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "  #                                                       on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "   # test_balanced['XLM_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "    #                                                     on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "        \n",
    "    train_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata_cognates.csv')\n",
    "    test_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata_cognates.csv')\n",
    "\n",
    "    #train_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    #test_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    #train_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    #test_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cadc6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
