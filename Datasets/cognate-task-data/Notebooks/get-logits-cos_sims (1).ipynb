{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d900aa",
   "metadata": {},
   "source": [
    "Assumes you have run `Train_Testset.ipynb` first to make the `alldata`, `realdist`, and `balanced` train/test splits for the chosen language pair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a3a5e",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091671b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import panphon\n",
    "import panphon.distance\n",
    "import editdistance # levenshtein\n",
    "import epitran\n",
    "import eng_to_ipa as eng\n",
    "from epitran.backoff import Backoff\n",
    "from googletrans import Translator\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "epitran.download.cedict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4977c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "# sys.argv = ['']\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "#from evaluations.eval import *\n",
    "import os\n",
    "import copy\n",
    "import configparser\n",
    "config_model = configparser.ConfigParser()\n",
    "config_model.read('model_parameters.ini')\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed2ae9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import io\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726f5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer specific imports, and cross encoders for our customized transformer models \n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import *\n",
    "from bert_stuff import *\n",
    "from cognate_encoders.cross_encoder_assamese import FullCrossEncoder, FullCrossEncoderSingle, FullCrossEncoderSingle_muril\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup,\\\n",
    "    BertForSequenceClassification, BertForPreTraining, AutoModel\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel, XLMModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, mean_squared_error\n",
    "import time\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b4fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3090\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    \n",
    "#device = torch.device(\"cuda:0:3\" if torch.cuda.is_available() else \"cpu\") ## specify the GPU id's, GPU id's start from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80da282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e42f7",
   "metadata": {},
   "source": [
    "# DNN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e92610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(n_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            \n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        logits_new = self.linear_relu_stack(x)\n",
    "        logits  = self.dropout(logits_new)\n",
    "        \n",
    "        return torch.sigmoid(logits), logits_new\n",
    "    \n",
    "    def fit(self, X_train, Y_train, X_val, Y_val, criterion, optimizer, n_epochs=5000):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accur = []\n",
    "        val_accur = []\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            y_pred, logits = self(X_train.float())\n",
    "\n",
    "            train_loss = criterion(y_pred, Y_train.float())\n",
    "\n",
    "            if epoch % (n_epochs // 50) == 0:\n",
    "                train_acc,_ = self.calculate_accuracy(Y_train, y_pred)\n",
    "\n",
    "                y_val_pred = self(X_val.float())[0]\n",
    "\n",
    "                val_loss = criterion(y_val_pred, Y_val.float())\n",
    "\n",
    "                val_acc, total_corr = self.calculate_accuracy(Y_val, y_val_pred)\n",
    "\n",
    "                print(f'''epoch {epoch}\n",
    "                    Train set - loss: {self.round_tensor(train_loss)}, accuracy: {self.round_tensor(train_acc)} \n",
    "                    Val set - loss: {self.round_tensor(val_loss)}, accuracy: {self.round_tensor(val_acc)}''')\n",
    "                \n",
    "                train_losses.append(train_loss.detach().cpu().numpy())\n",
    "                val_losses.append(val_loss.detach().cpu().numpy())\n",
    "\n",
    "                val_accur.append(val_acc.detach().cpu().numpy())\n",
    "                train_accur.append(train_acc.detach().cpu().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "        return train_losses,val_losses,train_accur,val_accur\n",
    "    \n",
    "    def calculate_accuracy(self, y_true, y_pred):\n",
    "        predicted = y_pred.ge(.5) \n",
    "        return ((y_true == predicted).sum().float() / len(y_true), (y_true == predicted).sum())\n",
    "    \n",
    "    def round_tensor(self, t, decimal_places=3):\n",
    "        return round(t.item(), decimal_places)\n",
    "    \n",
    "    def plot_losses(self, train_losses, val_losses, train_accur, val_accur):\n",
    "        epochs = range(1, len(train_accur) + 1)\n",
    "\n",
    "        plt.plot(epochs, train_accur, 'bo', label='Training acc')\n",
    "        plt.plot(epochs, val_accur, 'b', label='Vaidation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
    "        plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36154569",
   "metadata": {},
   "source": [
    "# MyDataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b14ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overriding the Dataset class required for the use of PyTorch's data loader classes.\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, l1_encodings, l2_encodings):\n",
    "        self.l1_encodings = l1_encodings\n",
    "        self.l2_encodings = l2_encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {('l1_' + key): torch.tensor(val[idx]) for key, val in self.l1_encodings.items()}\n",
    "        item2 = {('l2_' + key): torch.tensor(val[idx]) for key, val in self.l2_encodings.items()}\n",
    "        item.update(item2)\n",
    "        # item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l1_encodings['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a47bf8",
   "metadata": {},
   "source": [
    "# Download LMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b243a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlm_tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "# xlm_model = XLMModel.from_pretrained(\"xlm-mlm-100-1280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9755402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55834b9",
   "metadata": {},
   "source": [
    "# Pipeline function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4051b",
   "metadata": {},
   "source": [
    "## Get Panphon phonetic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4354d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_panphon_features(train_set, test_set):\n",
    "    #get phonetic features using PanPhon\n",
    "    ft = panphon.FeatureTable()   \n",
    "    \n",
    "    train_set['features_loan'] = train_set.apply(lambda x:ft.word_to_vector_list(x[\"loan_word_epitran\"],numeric=True ), axis=1)\n",
    "    train_set['features_orig'] = train_set.apply(lambda x:ft.word_to_vector_list(x[\"original_word_epitran\"],numeric=True ), axis=1)\n",
    "    test_set['features_loan'] = test_set.apply(lambda x:ft.word_to_vector_list(x[\"loan_word_epitran\"],numeric=True ), axis=1)\n",
    "    test_set['features_orig'] = test_set.apply(lambda x:ft.word_to_vector_list(x[\"original_word_epitran\"],numeric=True ), axis=1)\n",
    "\n",
    "    train_set['features_loan'] = train_set['features_loan'].apply(lambda x:sum(x, []))\n",
    "    train_set['features_orig'] = train_set['features_orig'].apply(lambda x:sum(x, []))\n",
    "    test_set['features_orig'] = test_set['features_orig'].apply(lambda x:sum(x, []))\n",
    "    test_set['features_loan'] = test_set['features_loan'].apply(lambda x:sum(x, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413d0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_panphon_features(train_set, test_set, maxlen, verbose=False):\n",
    "    # Pad the phonetic features of the loan word and original word out to the maxlen \n",
    "    # of the features appearing in the training set (format: `<loan><pad 0s><orig><pad 0s>`).\n",
    "    train_set['features_loan'] = train_set['features_loan'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[0]-len(x)), 'constant'))\n",
    "    train_set['features_orig'] = train_set['features_orig'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[1]-len(x)), 'constant'))\n",
    "    test_set['features_loan'] = test_set['features_loan'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[0]-len(x)), 'constant'))\n",
    "    test_set['features_orig'] = test_set['features_orig'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[1]-len(x)), 'constant'))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Sample train features:\\n\",\\\n",
    "                train_set['features_loan'][np.random.randint(len(train_set['features_loan']))],\\\n",
    "                train_set['features_orig'][np.random.randint(len(train_set['features_loan']))])\n",
    "\n",
    "        print(\"Sample test features:\\n\",\\\n",
    "                test_set['features_loan'][np.random.randint(len(test_set['features_loan']))],\\\n",
    "                test_set['features_orig'][np.random.randint(len(test_set['features_orig']))])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a031511",
   "metadata": {},
   "source": [
    "## Add target labels and make train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900f4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target_labels(train_set, test_set):\n",
    "    Y_train = np.array([y for y in train_set['label_bin']])\n",
    "    Y_test = np.array([y for y in test_set['label_bin']])\n",
    "    return Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e93f3aa",
   "metadata": {},
   "source": [
    "Make a validation split for training the DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16fd11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_val_set(train_set, test_set, Y_train):\n",
    "    X_train = np.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                np.array([x for x in train_alldata['features_orig']])])\n",
    "    X_test = np.hstack([np.array([x for x in test_alldata['features_loan']]),\\\n",
    "                np.array([x for x in test_alldata['features_orig']])])\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2,\\\n",
    "                                                      random_state=1, stratify=Y_train)\n",
    "    return X_train, X_val, X_test, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee312b",
   "metadata": {},
   "source": [
    "Make tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44851fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "    X_train = torch.tensor(X_train).to(device)\n",
    "    Y_train = torch.tensor(Y_train).to(device).reshape((-1,1))\n",
    "\n",
    "    X_val = torch.tensor(X_val).to(device)\n",
    "    Y_val = torch.tensor(Y_val).to(device).reshape((-1,1))\n",
    "    \n",
    "    X_test = torch.tensor(X_test).to(device)\n",
    "    Y_test = torch.tensor(Y_test).to(device).reshape((-1,1))\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40b267",
   "metadata": {},
   "source": [
    "## Get cosine similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683ed59",
   "metadata": {},
   "source": [
    "MBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c98a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_bert_MODEL = 'bert-base-multilingual-cased'\n",
    "PRE_TRAINED_xlm_MODEL = 'xlm-mlm-100-1280'\n",
    "\n",
    "MAXTOKENS = 5\n",
    "BS = 8\n",
    "all_vec= defaultdict(dict)  #stores the model embeddings  for each combination of models \n",
    "all_mapped = defaultdict(dict) \n",
    "cos_mapped = defaultdict(dict) \n",
    "# stores the linearly transformed model embeddings  for each combination of models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc81408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarities(a,b):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity as row wise dot product of 2 arrays of vectors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    a,b : Two arrays/tensors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "    \"\"\"\n",
    "    def normed(a):\n",
    "        return a/np.linalg.norm(a, axis=1).reshape((-1, 1))\n",
    "     \n",
    "    lhs = a\n",
    "    rhs = b\n",
    " \n",
    "\n",
    "    return np.sum(normed(lhs) * normed(rhs), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48e84130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mbert_cos_sims(l1_data,l2_data):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    with torch.no_grad():\n",
    "        tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_bert_MODEL)\n",
    "        tokenizer.model_max_length = MAXTOKENS\n",
    "        l1_encodings = tokenizer(l1_data, truncation=False, padding=True, max_length=MAXTOKENS)\n",
    "        l2_encodings = tokenizer(l2_data, truncation=False, padding=True, max_length=MAXTOKENS)\n",
    "        \n",
    "        dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "        \n",
    "        data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "        \n",
    "        base_model = BertModel.from_pretrained(PRE_TRAINED_bert_MODEL).to(device)\n",
    "        base_model.eval()\n",
    "        cos_s = torch.nn.CosineSimilarity()\n",
    "        \n",
    "        sim_lst = []\n",
    "#         l1 = base_model(input_ids = l1_encodings['input_ids'],\n",
    "#                                         attention_mask = l1_encodings['attention_mask']).last_hidden_state[:, 0, :]\n",
    "#         l2 = base_model(input_ids = l2_encodings['input_ids'],attention_mask = \n",
    "#                                           l2_encodings['attention_mask']\n",
    "#                                         ).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        #loop through dataset \n",
    "        for step, batch in enumerate(data_loader):\n",
    "            l1_vector = base_model(batch['l1_input_ids'].to(device),\n",
    "                                          attention_mask=batch['l1_attention_mask'].to(device),\n",
    "                                          return_dict=True).last_hidden_state[:, 0, :]\n",
    "            l2_vector = base_model(batch['l2_input_ids'].to(device),\n",
    "                                          attention_mask=batch['l2_attention_mask'].to(device),\n",
    "                                          return_dict=True).last_hidden_state[:, 0, :]\n",
    "            \n",
    "            l1.extend(l1_vector.data.cpu().numpy())\n",
    "            l2.extend(l2_vector.data.cpu().numpy())\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            sims = cos_s(l1_vector, l2_vector).data.cpu().numpy()\n",
    "            sim_lst.extend(list(sims))\n",
    "            if (step * BS) % 100 < BS:\n",
    "                print(\"Got {}\".format(len(sim_lst)))\n",
    "        all_vec['mbert']['loan'] = np.array(l1)\n",
    "        all_vec['mbert']['original'] = np.array(l2)\n",
    "        print()\n",
    "                \n",
    "    return sim_lst, all_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643675a",
   "metadata": {},
   "source": [
    "XLM-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6ecafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xlm_cos_sims(l1_data,l2_data):\n",
    "    with torch.no_grad():\n",
    "        tokenizer = XLMTokenizer.from_pretrained(PRE_TRAINED_xlm_MODEL)\n",
    "        tokenizer.model_max_length = MAXTOKENS \n",
    "        l1_encodings = tokenizer(l1_data, truncation=False, padding=True, max_length=MAXTOKENS, return_tensors=\"pt\", return_special_tokens_mask=True)\n",
    "        l2_encodings = tokenizer(l2_data, truncation=False, padding=True, max_length=MAXTOKENS, return_tensors=\"pt\", return_special_tokens_mask=True)\n",
    "\n",
    "        dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "\n",
    "        data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "\n",
    "        \n",
    "        base_model = XLMModel.from_pretrained(PRE_TRAINED_xlm_MODEL).to(device)\n",
    "        \n",
    "        base_model.eval()\n",
    "        cos_s = torch.nn.CosineSimilarity()\n",
    "        \n",
    "        sim_lst = []\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "\n",
    "        #loop through dataset \n",
    "        for step, batch in enumerate(data_loader):\n",
    "            \n",
    "            l1_vector = base_model(batch['l1_input_ids'].to(device), output_hidden_states=False).last_hidden_state[:, 0, :]\n",
    "            l2_vector = base_model(batch['l2_input_ids'].to(device), output_hidden_states=False).last_hidden_state[:, 0, :]\n",
    "            l1.extend(l1_vector.data.cpu().numpy())\n",
    "            l2.extend(l2_vector.data.cpu().numpy())\n",
    "            sims = cos_s(l1_vector,l2_vector).data.cpu().numpy()\n",
    "            sim_lst.extend(list(sims))\n",
    "            if (step * BS) % 100 < BS:\n",
    "                print(\"Got {}\".format(len(sim_lst)))\n",
    "            \n",
    "        all_vec['xlm']['loan'] = np.array(l1)\n",
    "        all_vec['xlm']['original'] = np.array(l2)\n",
    "        \n",
    "        print()\n",
    "                \n",
    "    return sim_lst , all_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20bcf57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ass_albert_cos_sims(l1_data,l2_data, lin_transform =False):  #only assamese, monolingual, albert \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if lin_transform ==True:\n",
    "                \n",
    "            tokenizer_mbert = BertTokenizer.from_pretrained(PRE_TRAINED_bert_MODEL)\n",
    "            tokenizer_assbert = AutoTokenizer.from_pretrained(config_model['model_ass_bert']['token_path'] )\n",
    "            \n",
    "\n",
    "            #tokenizer.model_max_length = MAXTOKENS \n",
    "            l1_encodings = tokenizer_assbert(l1_data,padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "            l2_encodings = tokenizer_assbert(l2_data, padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "\n",
    "            dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "\n",
    "            data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "\n",
    "\n",
    "            source_model = AutoModel.from_pretrained(config_model['model_ass_bert']['model_name'] ).to(device)\n",
    "            target_model = BertModel.from_pretrained(PRE_TRAINED_bert_MODEL).to(device) #do not use this when working with the transformation matrix\n",
    "             \n",
    "            target_model.eval()\n",
    "            \n",
    "            cos_s = torch.nn.CosineSimilarity()\n",
    "\n",
    "            sim_lst = []\n",
    "            l1_new = []\n",
    "            l2_new = []\n",
    "\n",
    "            #loop through dataset \n",
    "            for step, batch in enumerate(data_loader):\n",
    "\n",
    "                l1_vector = source_model(batch['l1_input_ids'].to(device), output_hidden_states=True).last_hidden_state #albert has only 6 encoder layers\n",
    "                l2_vector = source_model(batch['l2_input_ids'].to(device), output_hidden_states=True).last_hidden_state\n",
    "                l1_new.extend(l1_vector[:, 0, :].data.cpu().numpy() )\n",
    "                l2_new.extend(l2_vector[:, 0, :].data.cpu().numpy() )\n",
    "                \n",
    "                l2_vector = l2_vector.cpu()\n",
    "                \n",
    "                l1  = l1_vector.sum(1).cpu().numpy()\n",
    "                l2  = l2_vector.sum(1).cpu().numpy()\n",
    "                 \n",
    "                #get the linear transform here \n",
    "                \n",
    "                mapper_ = sklearn.linear_model.Ridge(fit_intercept=False).fit(l1,l2) \n",
    "                mapper_ = mapper_.coef_\n",
    "                mapped_= l1 @ mapper_.transpose()\n",
    "                \n",
    "                \n",
    "\n",
    "                #sims = cos_s(l1_vector[:,0,:],l2_vector[:,0,:]).data.cpu().numpy()\n",
    "                sims = cos_s(torch.tensor(mapped_),l2_vector[:,0,:]).data.cpu().numpy()\n",
    "                sim_lst.extend(list(sims))\n",
    "                if (step * BS) % 100 < BS:\n",
    "                    print(\"Got {}\".format(len(sim_lst)))\n",
    "                    \n",
    "                    \n",
    "            all_vec['ass_bert']['loan'] = np.array(l1_new)\n",
    "            all_vec['ass_bert']['original'] = np.array(l2_new)\n",
    "            print()\n",
    "                \n",
    "    return sim_lst, all_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "826239df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Indic_bert_cos_sims(l1_data,l2_data, lin_transform =False ):  #only assamese, monolingual \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert', keep_accents=True)\n",
    "        base_model = AutoModel.from_pretrained('ai4bharat/indic-bert').to(device)\n",
    "        \n",
    "        #tokenizer.model_max_length = MAXTOKENS \n",
    "        l1_encodings = tokenizer(l1_data,padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "        l2_encodings = tokenizer(l2_data, padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "\n",
    "        dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "\n",
    "        data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "\n",
    "        \n",
    "          \n",
    "        \n",
    "        base_model.eval()\n",
    "        cos_s = torch.nn.CosineSimilarity()\n",
    "        \n",
    "        sim_lst = []\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "        if lin_transform ==False:\n",
    "            \n",
    "\n",
    "            #loop through dataset \n",
    "            for step, batch in enumerate(data_loader):\n",
    "\n",
    "                l1_vector = base_model(batch['l1_input_ids'].to(device), output_hidden_states=True).last_hidden_state[:, 0, :]\n",
    "                l2_vector = base_model(batch['l2_input_ids'].to(device), output_hidden_states=True).last_hidden_state[:, 0, :]\n",
    "                l1.extend(l1_vector.data.cpu().numpy())\n",
    "                l2.extend(l2_vector.data.cpu().numpy())\n",
    "                sims = cos_s(l1_vector,l2_vector).data.cpu().numpy()\n",
    "                sim_lst.extend(list(sims))\n",
    "                if (step * BS) % 100 < BS:\n",
    "                    print(\"Got {}\".format(len(sim_lst)))\n",
    "            print()\n",
    "            all_vec['indic_bert']['loan'] = np.array(l1)\n",
    "            all_vec['indic_bert']['original'] = np.array(l2)\n",
    "    \n",
    "            \n",
    "                \n",
    "    return sim_lst, all_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d452029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Muril_cos_sims(l1_data,l2_data):  #only assamese, monolingual \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "\n",
    "        base_model = AutoModelForMaskedLM.from_pretrained(\"google/muril-base-cased\").to(device)\n",
    "        \n",
    "        #tokenizer.model_max_length = MAXTOKENS \n",
    "        l1_encodings = tokenizer(l1_data,padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "        l2_encodings = tokenizer(l2_data, padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "\n",
    "        dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "\n",
    "        data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "\n",
    "        base_model.eval()\n",
    "        cos_s = torch.nn.CosineSimilarity()\n",
    "        \n",
    "        sim_lst = []\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "\n",
    "        #loop through dataset \n",
    "        for step, batch in enumerate(data_loader):\n",
    "            \n",
    "            l1_vector = base_model(batch['l1_input_ids'].to(device), output_hidden_states =True).hidden_states[12][:, 0, :]\n",
    "            l2_vector = base_model(batch['l2_input_ids'].to(device), output_hidden_states =True).hidden_states[12][:, 0, :]\n",
    "            l1.extend(l1_vector.data.cpu().numpy())\n",
    "            l2.extend(l2_vector.data.cpu().numpy())\n",
    "            sims = cos_s(l1_vector,l2_vector).data.cpu().numpy()\n",
    "            sim_lst.extend(list(sims))\n",
    "            if (step * BS) % 100 < BS:\n",
    "                print(\"Got {}\".format(len(sim_lst)))\n",
    "        all_vec['muril']['loan'] = np.array(l1)\n",
    "        all_vec['muril']['original'] = np.array(l2)\n",
    "        print()\n",
    "        \n",
    "                \n",
    "    return sim_lst, all_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58253874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63a3f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias #loading\n",
      "no stored variable or alias the\n",
      "no stored variable or alias transformation\n",
      "no stored variable or alias matrix\n",
      "no stored variable or alias from\n",
      "no stored variable or alias the\n",
      "no stored variable or alias 339\n",
      "no stored variable or alias sample\n",
      "no stored variable or alias equivalent\n",
      "no stored variable or alias sentences\n"
     ]
    }
   ],
   "source": [
    "%store -r beng_m_bertvec #loading the transformation matrix from the 339 sample equivalent sentences \n",
    "%store -r ass_bertvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6b8ea31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((339, 768), (339, 768))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beng_m_bertvec.shape, ass_bertvec.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50474ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ben_ass_train = pd.read_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Bengali-Assamese-train_production_alldata.csv', index_col=False)\n",
    "ben_ass_test = pd.read_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Bengali-Assamese-test_production_alldata.csv', index_col=False)\n",
    "\n",
    "ass_ben_train = pd.read_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Assamese-Bengali-train_production_alldata.csv', index_col=False)\n",
    "ass_ben_test = pd.read_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Assamese-Bengali-test_production_alldata.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5e017b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2280: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/vocab.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/fcfbd016a54060fb3e7290d39ac4fd04b0c7ca2c683e5fdd87928b0feaa2c367.bd20142f530c7b681cef79e2153e77f8d9e8c9fdb3f6db29f37298198166236d\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/merges.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0693c49aba9ba31f442ba9a6c368bc400d2a81e5931d983d63d8648a043bf551.a1730275bc49c3d660f1d9bf50222d8cb849f3ae93e75e5865a3037650459b27\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/91dad0f1b901ee17a1ca86293a46619408e812441cfa380050cd03359564b95f.fabc897dd998cd3c78df5e8469be3194040e8a0f7dd4ee9278748dfcea803743\n",
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"_name_or_path\": \"xlm-mlm-100-1280\",\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/xlm-mlm-100-1280/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/5ba8c43e22aeb247eee7a4d27014eabe361cbfd2a9e00bd337946aaa0dece8ce.f11dc7ef5f30811d164556022e3174da0d6e8bb13676833dabdb1f50f61f39a5\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of XLMModel were initialized from the model checkpoint at xlm-mlm-100-1280.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Didn't find file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer.json. We won't load it.\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/spiece.model\n",
      "loading file None\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/added_tokens.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/special_tokens_map.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer_config.json\n",
      "Adding <pad> to the vocabulary\n",
      "loading configuration file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2\",\n",
      "  \"architectures\": [\n",
      "    \"AlbertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing AlbertModel.\n",
      "\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/spiece.model from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/97e976f62c951292c6fdb2bb5bf1f34f5450585dda98be8dedea2b97e4f25b86.5c8e83e7afe2b2faae1dc1a6b0fcdb911480df6af7079e9df53aa83ed0763de2\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.dense.weight', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at ai4bharat/indic-bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b97fc49fcc6c4b696e73d117cd105e9896633d546afdaa10fbdc2e3964b7ccce.6238bf3b1b7ad31c55bb4415faa9477a5f8e50723e8d1d70df19a65433db277f\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/special_tokens_map.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/290471f6a01c9af0dd0bcf02112dc77b9b0aee820ebb1fb023c96ac2dda9d8ef.750293617705dd39d21eef1e163d80ca5b23e1a0ec507fff24a087c44632142c\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/677de489a9460181a44c530abce89d7d341485a3d49dacc89a9b5a1fed34c328.94e1730f1b81d6fdf365e5e59d01a4e387286e650a02ed6512f3dba8668dd876\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/muril-base-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b4704f25323c21eafa8f1b6196e294d7252e11aa35d082c49d6ae62f3ca168dd.767d38e2461040f361197f7fc27e1968320609d399f194178c3adb49eeeb8ca9\n",
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at google/muril-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get cosine sims for ben_ass_train\n",
    "\n",
    "\n",
    "mbert_cos, all_vec = get_mbert_cos_sims(list(ben_ass_train['loan_word']),list(ben_ass_train['original_word']))\n",
    "xlm_cos,all_vec = get_xlm_cos_sims(list(ben_ass_train['loan_word']),list(ben_ass_train['original_word']))\n",
    "ass_bert_cos, all_vec = get_ass_albert_cos_sims(list(ben_ass_train['original_word']),list(ben_ass_train['loan_word']), lin_transform =True)\n",
    "indic_bert_cos, all_vec = Indic_bert_cos_sims(list(ben_ass_train['loan_word']),list(ben_ass_train['original_word']))\n",
    "muril_cos, all_vec = Muril_cos_sims(list(ben_ass_train['loan_word']),list(ben_ass_train['original_word']))\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea62c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert (1648, 768) (1648, 768) <class 'numpy.ndarray'>\n",
      "xlm (1648, 1280) (1648, 1280) <class 'numpy.ndarray'>\n",
      "ass_bert (1648, 768) (1648, 768) <class 'numpy.ndarray'>\n",
      "indic_bert (1648, 768) (1648, 768) <class 'numpy.ndarray'>\n",
      "muril (1648, 768) (1648, 768) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i, j in all_vec.items():\n",
    "    print(i,j['loan'].shape, j['original'].shape, type(j['original']))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a1d1289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1648, 768), (1648, 768))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vec['ass_bert']['original'].shape,all_vec['mbert']['loan'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7b87751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768)\n"
     ]
    }
   ],
   "source": [
    "# get the linear transformation from mbert space to ass_bert space using the precalculated transformation matrix i.e beng_m_bertvec, ass_bertvec\n",
    "\n",
    "m = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec, ass_bertvec) \n",
    "m = m.coef_ \n",
    "print(m.shape) #this is the 768 by 768 transformation matrix between mbert and assbert \n",
    "mapped_= all_vec['mbert']['loan'] @ m.transpose()\n",
    "beng_ass_cos_mapped = get_cosine_similarities(mapped_, all_vec['ass_bert']['original'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7090fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train production set and add the new cosim column\n",
    "ben_ass_train = pd.read_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Bengali-Assamese-train_production_alldata.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "623e20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_ass_train['mbert_src_assbert_trg'] = beng_ass_cos_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "400eaa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1</th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>loan_word_epitran</th>\n",
       "      <th>original_word_epitran</th>\n",
       "      <th>...</th>\n",
       "      <th>ass_bertmuril</th>\n",
       "      <th>indic_bertmbert</th>\n",
       "      <th>indic_bertxlm</th>\n",
       "      <th>indic_bertass_bert</th>\n",
       "      <th>indic_bertmuril</th>\n",
       "      <th>murilmbert</th>\n",
       "      <th>murilxlm</th>\n",
       "      <th>murilass_bert</th>\n",
       "      <th>murilindic_bert</th>\n",
       "      <th>mbert_src_assbert_trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pinda</td>\n",
       "      <td>at</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.995502</td>\n",
       "      <td>0.987439</td>\n",
       "      <td>-0.036634</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>0.997388</td>\n",
       "      <td>-0.037025</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.063041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>615</td>\n",
       "      <td>615</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pup</td>\n",
       "      <td>dxt</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.993861</td>\n",
       "      <td>-0.037131</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.998016</td>\n",
       "      <td>-0.036950</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>-0.003760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>336</td>\n",
       "      <td>336</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dnan</td>\n",
       "      <td>xun</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.996036</td>\n",
       "      <td>0.997111</td>\n",
       "      <td>-0.037456</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.997383</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>-0.036918</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.129613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kali</td>\n",
       "      <td>kali</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.997840</td>\n",
       "      <td>0.997473</td>\n",
       "      <td>-0.036673</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.998332</td>\n",
       "      <td>-0.037079</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.032470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>tbi</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.993710</td>\n",
       "      <td>0.992030</td>\n",
       "      <td>-0.037115</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.998208</td>\n",
       "      <td>0.998024</td>\n",
       "      <td>-0.037072</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.012763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>1643</td>\n",
       "      <td>1643</td>\n",
       "      <td>1643</td>\n",
       "      <td>1643</td>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ar</td>\n",
       "      <td>ija</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.992731</td>\n",
       "      <td>0.987405</td>\n",
       "      <td>-0.037828</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.997372</td>\n",
       "      <td>0.998031</td>\n",
       "      <td>-0.037065</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>-0.060017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>1644</td>\n",
       "      <td>1644</td>\n",
       "      <td>1644</td>\n",
       "      <td>1644</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pup</td>\n",
       "      <td>paund</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.997582</td>\n",
       "      <td>0.998046</td>\n",
       "      <td>-0.036369</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.998415</td>\n",
       "      <td>0.998395</td>\n",
       "      <td>-0.037102</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>-0.003760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>1645</td>\n",
       "      <td>1645</td>\n",
       "      <td>1645</td>\n",
       "      <td>1645</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kla</td>\n",
       "      <td>kka</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.992143</td>\n",
       "      <td>0.981005</td>\n",
       "      <td>-0.037294</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.997453</td>\n",
       "      <td>0.997853</td>\n",
       "      <td>-0.037073</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.049187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>1646</td>\n",
       "      <td>1646</td>\n",
       "      <td>1646</td>\n",
       "      <td>1646</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>din</td>\n",
       "      <td>dim</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.997719</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>-0.037080</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.998300</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>-0.037104</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.051215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>1647</td>\n",
       "      <td>1647</td>\n",
       "      <td>1647</td>\n",
       "      <td>1647</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kitab</td>\n",
       "      <td>puti</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.996928</td>\n",
       "      <td>0.996682</td>\n",
       "      <td>-0.036917</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.998358</td>\n",
       "      <td>0.998365</td>\n",
       "      <td>-0.037068</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.015616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1648 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0              0             0               0                 0   \n",
       "1              1             1               1                 1   \n",
       "2              2             2               2                 2   \n",
       "3              3             3               3                 3   \n",
       "4              4             4               4                 4   \n",
       "...          ...           ...             ...               ...   \n",
       "1643        1643          1643            1643              1643   \n",
       "1644        1644          1644            1644              1644   \n",
       "1645        1645          1645            1645              1645   \n",
       "1646        1646          1646            1646              1646   \n",
       "1647        1647          1647            1647              1647   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1 loan_word original_word  \\\n",
       "0                    180                   180                   \n",
       "1                    615                   615                 \n",
       "2                    336                   336                 \n",
       "3                     47                    47                   \n",
       "4                    105                   105                     \n",
       "...                  ...                   ...       ...           ...   \n",
       "1643                 348                   348                 \n",
       "1644                 136                   136                \n",
       "1645                  37                    37                     \n",
       "1646                 589                   589                     \n",
       "1647                 195                   195                  \n",
       "\n",
       "     loan_word_epitran original_word_epitran  ... ass_bertmuril  \\\n",
       "0             pinda                   at  ...      0.999895   \n",
       "1                pup                 dxt  ...      0.999765   \n",
       "2              dnan                 xun  ...      0.999856   \n",
       "3                 kali                  kali  ...      0.999915   \n",
       "4              tbi                  t  ...      0.999907   \n",
       "...                ...                   ...  ...           ...   \n",
       "1643             ar                  ija  ...      0.999483   \n",
       "1644             pup                paund  ...      0.999741   \n",
       "1645              kla                  kka  ...      0.999899   \n",
       "1646             din                   dim  ...      0.999900   \n",
       "1647            kitab                 puti  ...      0.999924   \n",
       "\n",
       "     indic_bertmbert  indic_bertxlm  indic_bertass_bert  indic_bertmuril  \\\n",
       "0           0.995502       0.987439           -0.036634         0.999794   \n",
       "1           0.995714       0.993861           -0.037131         0.999983   \n",
       "2           0.996036       0.997111           -0.037456         0.999987   \n",
       "3           0.997840       0.997473           -0.036673         0.999995   \n",
       "4           0.993710       0.992030           -0.037115         0.999976   \n",
       "...              ...            ...                 ...              ...   \n",
       "1643        0.992731       0.987405           -0.037828         0.999939   \n",
       "1644        0.997582       0.998046           -0.036369         0.999993   \n",
       "1645        0.992143       0.981005           -0.037294         0.999865   \n",
       "1646        0.997719       0.994965           -0.037080         0.999971   \n",
       "1647        0.996928       0.996682           -0.036917         0.999988   \n",
       "\n",
       "      murilmbert  murilxlm  murilass_bert  murilindic_bert  \\\n",
       "0       0.998521  0.997388      -0.037025         0.999968   \n",
       "1       0.997182  0.998016      -0.036950         0.999891   \n",
       "2       0.997383  0.997570      -0.036918         0.999913   \n",
       "3       0.998325  0.998332      -0.037079         0.999947   \n",
       "4       0.998208  0.998024      -0.037072         0.999954   \n",
       "...          ...       ...            ...              ...   \n",
       "1643    0.997372  0.998031      -0.037065         0.999911   \n",
       "1644    0.998415  0.998395      -0.037102         0.999950   \n",
       "1645    0.997453  0.997853      -0.037073         0.999909   \n",
       "1646    0.998300  0.998274      -0.037104         0.999951   \n",
       "1647    0.998358  0.998365      -0.037068         0.999950   \n",
       "\n",
       "     mbert_src_assbert_trg  \n",
       "0                 0.063041  \n",
       "1                -0.003760  \n",
       "2                 0.129613  \n",
       "3                 0.032470  \n",
       "4                 0.012763  \n",
       "...                    ...  \n",
       "1643             -0.060017  \n",
       "1644             -0.003760  \n",
       "1645              0.049187  \n",
       "1646              0.051215  \n",
       "1647              0.015616  \n",
       "\n",
       "[1648 rows x 50 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_ass_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5780dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lt_maps(all_vec):\n",
    "    #this function is for getting linear maps without using the transformation matrix from 339 sentences \n",
    "    \n",
    "  \n",
    "    \n",
    "    for i, j in all_vec.items():\n",
    "        #print(i,len(j['loan']) )\n",
    "\n",
    "\n",
    "        for m,n in all_vec.items():\n",
    "            if i ==m:\n",
    "                continue\n",
    "\n",
    "\n",
    "            print(i,m)\n",
    "          \n",
    "\n",
    "           #get linear maps for loans and originals separately    \n",
    "\n",
    "            mapper_loan = sklearn.linear_model.Ridge(fit_intercept=False).fit(j['loan'],n['loan']) \n",
    "            #mapper_loan = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec,ass_bertvec) \n",
    "            mapper_loan = mapper_loan.coef_\n",
    "            mapped_loan= j['loan'] @ mapper_loan.transpose()\n",
    "            all_mapped[i+m]['loan']  = mapped_loan\n",
    "\n",
    "            mapper_orig = sklearn.linear_model.Ridge(fit_intercept=False).fit(j['original'],n['original']) \n",
    "            #mapper_orig = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec,ass_bertvec) \n",
    "            mapper_orig = mapper_orig.coef_\n",
    "            mapped_orig= j['original'] @ mapper_orig.transpose()\n",
    "            all_mapped[i+m]['original']  = mapped_orig\n",
    "\n",
    "            cos_mapped[i+m] = get_cosine_similarities(mapped_loan, mapped_orig ) #get the cosine sims for mapped embeddings\n",
    "    return cos_mapped\n",
    "\n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc2428a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbertxlm [0.6520988  0.88991714 0.71950054 ... 0.5739207  0.68108535 0.84755015]\n",
      "mbertass_bert [-0.04072228 -0.03144859 -0.03459077 ... -0.03657508 -0.040287\n",
      " -0.03287696]\n",
      "mbertindic_bert [0.9978991  0.99957275 0.9991308  ... 0.9979694  0.9989909  0.99966216]\n",
      "mbertmuril [0.99839866 0.9986011  0.99890715 ... 0.9994731  0.999819   0.99949217]\n",
      "xlmmbert [0.85940564 0.8999516  0.80412424 ... 0.90755445 0.8564594  0.9402543 ]\n",
      "xlmass_bert [-0.04139591 -0.01836748 -0.03869876 ... -0.04617794 -0.04134841\n",
      " -0.03475533]\n",
      "xlmindic_bert [0.99683017 0.99924695 0.9993081  ... 0.9966495  0.9988537  0.9997119 ]\n",
      "xlmmuril [0.9977406  0.9966437  0.99824786 ... 0.99884045 0.99976546 0.9997694 ]\n",
      "ass_bertmbert [0.9877634  0.9778743  0.9747802  ... 0.982127   0.98322934 0.9801762 ]\n",
      "ass_bertxlm [0.95709693 0.95912945 0.95943815 ... 0.969867   0.9682539  0.96623474]\n",
      "ass_bertindic_bert [0.99980676 0.9999196  0.99984217 ... 0.99959093 0.999913   0.9999382 ]\n",
      "ass_bertmuril [0.9998949  0.9997655  0.9998558  ... 0.99989915 0.99990046 0.9999244 ]\n",
      "indic_bertmbert [0.9955022  0.99571407 0.99603605 ... 0.99214256 0.9977193  0.9969278 ]\n",
      "indic_bertxlm [0.987439   0.9938611  0.99711144 ... 0.9810046  0.99496514 0.9966817 ]\n",
      "indic_bertass_bert [-0.03663442 -0.03713082 -0.03745616 ... -0.03729449 -0.03708001\n",
      " -0.03691736]\n",
      "indic_bertmuril [0.9997935  0.9999833  0.9999873  ... 0.9998646  0.99997056 0.9999877 ]\n",
      "murilmbert [0.9985212  0.99718237 0.99738324 ... 0.99745274 0.9982999  0.9983579 ]\n",
      "murilxlm [0.99738777 0.9980155  0.99757016 ... 0.9978533  0.99827445 0.9983646 ]\n",
      "murilass_bert [-0.03702481 -0.0369499  -0.03691846 ... -0.03707321 -0.03710388\n",
      " -0.03706779]\n",
      "murilindic_bert [0.9999684  0.99989086 0.99991256 ... 0.99990946 0.99995065 0.9999495 ]\n"
     ]
    }
   ],
   "source": [
    "cos_mapped = get_lt_maps(all_vec)\n",
    "for i, j  in cos_mapped.items():\n",
    "    print(i,j)\n",
    "    \n",
    "    ben_ass_train[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5eae6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1',\n",
       "       'Unnamed: 0.1.1.1.1', 'Unnamed: 0.1.1.1.1.1', 'loan_word',\n",
       "       'original_word', 'loan_word_epitran', 'original_word_epitran',\n",
       "       'loan_english', 'original_english',\n",
       "       'Fast Levenshtein Distance Div Maxlen',\n",
       "       'Dolgo Prime Distance Div Maxlen', 'Feature Edit Distance Div Maxlen',\n",
       "       'Hamming Feature Distance Div Maxlen',\n",
       "       'Weighted Feature Distance Div Maxlen',\n",
       "       'Partial Hamming Feature Distance Div Maxlen', 'plain Levenshtein',\n",
       "       'loan_unicode', 'original_unicode', 'label', 'label_bin', 'DNN_logits',\n",
       "       'mbert_cos', 'xlm_cos', 'ass_bert_mbert_cos', 'indic_bert_cos',\n",
       "       'muril_cos', 'mbertxlm', 'mbertass_bert', 'mbertindic_bert',\n",
       "       'mbertmuril', 'xlmmbert', 'xlmass_bert', 'xlmindic_bert', 'xlmmuril',\n",
       "       'ass_bertmbert', 'ass_bertxlm', 'ass_bertindic_bert', 'ass_bertmuril',\n",
       "       'indic_bertmbert', 'indic_bertxlm', 'indic_bertass_bert',\n",
       "       'indic_bertmuril', 'murilmbert', 'murilxlm', 'murilass_bert',\n",
       "       'murilindic_bert', 'mbert_src_assbert_trg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_ass_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60a96845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mbertass_bert</th>\n",
       "      <th>xlmass_bert</th>\n",
       "      <th>ass_bertxlm</th>\n",
       "      <th>ass_bertmbert</th>\n",
       "      <th>ass_bertindic_bert</th>\n",
       "      <th>ass_bertmuril</th>\n",
       "      <th>indic_bert_cos</th>\n",
       "      <th>ass_bert_mbert_cos</th>\n",
       "      <th>mbert_cos</th>\n",
       "      <th>xlm_cos</th>\n",
       "      <th>muril_cos</th>\n",
       "      <th>indic_bert_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.040722</td>\n",
       "      <td>-0.041396</td>\n",
       "      <td>0.957097</td>\n",
       "      <td>0.987763</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.996818</td>\n",
       "      <td>0.437369</td>\n",
       "      <td>0.859162</td>\n",
       "      <td>0.619778</td>\n",
       "      <td>0.997738</td>\n",
       "      <td>0.996818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.031449</td>\n",
       "      <td>-0.018367</td>\n",
       "      <td>0.959129</td>\n",
       "      <td>0.977874</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>0.999240</td>\n",
       "      <td>0.399135</td>\n",
       "      <td>0.899460</td>\n",
       "      <td>0.880066</td>\n",
       "      <td>0.996626</td>\n",
       "      <td>0.999240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.034591</td>\n",
       "      <td>-0.038699</td>\n",
       "      <td>0.959438</td>\n",
       "      <td>0.974780</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.999310</td>\n",
       "      <td>0.527592</td>\n",
       "      <td>0.803146</td>\n",
       "      <td>0.689375</td>\n",
       "      <td>0.998220</td>\n",
       "      <td>0.999310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040505</td>\n",
       "      <td>-0.039202</td>\n",
       "      <td>0.976788</td>\n",
       "      <td>0.986098</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.456332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.036145</td>\n",
       "      <td>-0.035271</td>\n",
       "      <td>0.962915</td>\n",
       "      <td>0.976585</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.320201</td>\n",
       "      <td>0.787768</td>\n",
       "      <td>0.661757</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>0.999882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>-0.041362</td>\n",
       "      <td>-0.040279</td>\n",
       "      <td>0.907283</td>\n",
       "      <td>0.969478</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.998596</td>\n",
       "      <td>0.636795</td>\n",
       "      <td>0.835814</td>\n",
       "      <td>0.682145</td>\n",
       "      <td>0.998156</td>\n",
       "      <td>0.998596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>-0.032763</td>\n",
       "      <td>-0.011251</td>\n",
       "      <td>0.961271</td>\n",
       "      <td>0.980109</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.999694</td>\n",
       "      <td>0.399142</td>\n",
       "      <td>0.945338</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>0.999694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>-0.036575</td>\n",
       "      <td>-0.046178</td>\n",
       "      <td>0.969867</td>\n",
       "      <td>0.982127</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.996649</td>\n",
       "      <td>0.494424</td>\n",
       "      <td>0.907485</td>\n",
       "      <td>0.485389</td>\n",
       "      <td>0.998837</td>\n",
       "      <td>0.996649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>-0.040287</td>\n",
       "      <td>-0.041348</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.983229</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.998854</td>\n",
       "      <td>0.551089</td>\n",
       "      <td>0.856364</td>\n",
       "      <td>0.629492</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.998854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>-0.032877</td>\n",
       "      <td>-0.034755</td>\n",
       "      <td>0.966235</td>\n",
       "      <td>0.980176</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>0.471480</td>\n",
       "      <td>0.940100</td>\n",
       "      <td>0.769101</td>\n",
       "      <td>0.999769</td>\n",
       "      <td>0.999709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1648 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mbertass_bert  xlmass_bert  ass_bertxlm  ass_bertmbert  \\\n",
       "0         -0.040722    -0.041396     0.957097       0.987763   \n",
       "1         -0.031449    -0.018367     0.959129       0.977874   \n",
       "2         -0.034591    -0.038699     0.959438       0.974780   \n",
       "3         -0.040505    -0.039202     0.976788       0.986098   \n",
       "4         -0.036145    -0.035271     0.962915       0.976585   \n",
       "...             ...          ...          ...            ...   \n",
       "1643      -0.041362    -0.040279     0.907283       0.969478   \n",
       "1644      -0.032763    -0.011251     0.961271       0.980109   \n",
       "1645      -0.036575    -0.046178     0.969867       0.982127   \n",
       "1646      -0.040287    -0.041348     0.968254       0.983229   \n",
       "1647      -0.032877    -0.034755     0.966235       0.980176   \n",
       "\n",
       "      ass_bertindic_bert  ass_bertmuril  indic_bert_cos  ass_bert_mbert_cos  \\\n",
       "0               0.999807       0.999895        0.996818            0.437369   \n",
       "1               0.999920       0.999766        0.999240            0.399135   \n",
       "2               0.999842       0.999856        0.999310            0.527592   \n",
       "3               0.999668       0.999915        0.999681            0.456332   \n",
       "4               0.999851       0.999907        0.999882            0.320201   \n",
       "...                  ...            ...             ...                 ...   \n",
       "1643            0.998929       0.999483        0.998596            0.636795   \n",
       "1644            0.999886       0.999741        0.999694            0.399142   \n",
       "1645            0.999591       0.999899        0.996649            0.494424   \n",
       "1646            0.999913       0.999900        0.998854            0.551089   \n",
       "1647            0.999938       0.999924        0.999709            0.471480   \n",
       "\n",
       "      mbert_cos   xlm_cos  muril_cos  indic_bert_cos  \n",
       "0      0.859162  0.619778   0.997738        0.996818  \n",
       "1      0.899460  0.880066   0.996626        0.999240  \n",
       "2      0.803146  0.689375   0.998220        0.999310  \n",
       "3      1.000000  1.000000   1.000000        0.999681  \n",
       "4      0.787768  0.661757   0.999328        0.999882  \n",
       "...         ...       ...        ...             ...  \n",
       "1643   0.835814  0.682145   0.998156        0.998596  \n",
       "1644   0.945338  0.737297   0.999730        0.999694  \n",
       "1645   0.907485  0.485389   0.998837        0.996649  \n",
       "1646   0.856364  0.629492   0.999765        0.998854  \n",
       "1647   0.940100  0.769101   0.999769        0.999709  \n",
       "\n",
       "[1648 rows x 12 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_ass_train.loc[:,['mbertass_bert', 'xlmass_bert', 'ass_bertxlm', 'ass_bertmbert', 'ass_bertindic_bert','ass_bertmuril' ,'indic_bert_cos', 'ass_bert_mbert_cos','mbert_cos', 'xlm_cos', 'muril_cos', 'indic_bert_cos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cb9d993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1648, 1648, 1648, 1648, 1648)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mbert_cos ), len(xlm_cos), len(ass_bert_cos), len(indic_bert_cos), len(muril_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2274589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_ass_train['mbert_cos'] = mbert_cos\n",
    "ben_ass_train['xlm_cos'] = xlm_cos\n",
    "ben_ass_train['ass_bert_mbert_cos'] = ass_bert_cos\n",
    "ben_ass_train['indic_bert_cos'] = indic_bert_cos\n",
    "ben_ass_train['muril_cos'] = muril_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d408044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2280: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/vocab.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/fcfbd016a54060fb3e7290d39ac4fd04b0c7ca2c683e5fdd87928b0feaa2c367.bd20142f530c7b681cef79e2153e77f8d9e8c9fdb3f6db29f37298198166236d\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/merges.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0693c49aba9ba31f442ba9a6c368bc400d2a81e5931d983d63d8648a043bf551.a1730275bc49c3d660f1d9bf50222d8cb849f3ae93e75e5865a3037650459b27\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/91dad0f1b901ee17a1ca86293a46619408e812441cfa380050cd03359564b95f.fabc897dd998cd3c78df5e8469be3194040e8a0f7dd4ee9278748dfcea803743\n",
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"_name_or_path\": \"xlm-mlm-100-1280\",\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/xlm-mlm-100-1280/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/5ba8c43e22aeb247eee7a4d27014eabe361cbfd2a9e00bd337946aaa0dece8ce.f11dc7ef5f30811d164556022e3174da0d6e8bb13676833dabdb1f50f61f39a5\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of XLMModel were initialized from the model checkpoint at xlm-mlm-100-1280.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Didn't find file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer.json. We won't load it.\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/spiece.model\n",
      "loading file None\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/added_tokens.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/special_tokens_map.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer_config.json\n",
      "Adding <pad> to the vocabulary\n",
      "loading configuration file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2\",\n",
      "  \"architectures\": [\n",
      "    \"AlbertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing AlbertModel.\n",
      "\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/spiece.model from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/97e976f62c951292c6fdb2bb5bf1f34f5450585dda98be8dedea2b97e4f25b86.5c8e83e7afe2b2faae1dc1a6b0fcdb911480df6af7079e9df53aa83ed0763de2\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.dense.weight', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at ai4bharat/indic-bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b97fc49fcc6c4b696e73d117cd105e9896633d546afdaa10fbdc2e3964b7ccce.6238bf3b1b7ad31c55bb4415faa9477a5f8e50723e8d1d70df19a65433db277f\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/special_tokens_map.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/290471f6a01c9af0dd0bcf02112dc77b9b0aee820ebb1fb023c96ac2dda9d8ef.750293617705dd39d21eef1e163d80ca5b23e1a0ec507fff24a087c44632142c\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/677de489a9460181a44c530abce89d7d341485a3d49dacc89a9b5a1fed34c328.94e1730f1b81d6fdf365e5e59d01a4e387286e650a02ed6512f3dba8668dd876\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/muril-base-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b4704f25323c21eafa8f1b6196e294d7252e11aa35d082c49d6ae62f3ca168dd.767d38e2461040f361197f7fc27e1968320609d399f194178c3adb49eeeb8ca9\n",
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at google/muril-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now get the cosin sims and embeddings for ass_ben_train\n",
    "\n",
    "mbert_cos, all_vec = get_mbert_cos_sims(list(ass_ben_train['loan_word']),list(ass_ben_train['original_word']))\n",
    "xlm_cos, all_vec = get_xlm_cos_sims(list(ass_ben_train['loan_word']),list(ass_ben_train['original_word']))\n",
    "ass_bert_cos, all_vec = get_ass_albert_cos_sims(list(ass_ben_train['loan_word']),list(ass_ben_train['original_word']), lin_transform =True)\n",
    "indic_bert_cos, all_vec = Indic_bert_cos_sims(list(ass_ben_train['loan_word']),list(ass_ben_train['original_word']))\n",
    "muril_cos, all_vec = Muril_cos_sims(list(ass_ben_train['loan_word']),list(ass_ben_train['original_word']))\n",
    " \n",
    "# ass_ben_train['mbert_cos'] = mbert_cos\n",
    "# ass_ben_train['xlm_cos'] = xlm_cos\n",
    "# ass_ben_train['ass_bert_mbert_cos'] = ass_bert_cos\n",
    "# ass_ben_train['indic_bert_cos'] = indic_bert_cos\n",
    "# ass_ben_train['muril_cos'] = muril_cos   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf18ddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert (1715, 768) (1715, 768) <class 'numpy.ndarray'>\n",
      "xlm (1715, 1280) (1715, 1280) <class 'numpy.ndarray'>\n",
      "ass_bert (1715, 768) (1715, 768) <class 'numpy.ndarray'>\n",
      "indic_bert (1715, 768) (1715, 768) <class 'numpy.ndarray'>\n",
      "muril (1715, 768) (1715, 768) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i, j in all_vec.items():\n",
    "    print(i,j['loan'].shape, j['original'].shape, type(j['original']))\n",
    "# all_vec['mbert']['loan'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1acade4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ce514f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768)\n"
     ]
    }
   ],
   "source": [
    "# get the linear transformation from mbert space to ass_bert space using the precalculated transformation matrix i.e beng_m_bertvec, ass_bertvec\n",
    "#for ass_ben_train\n",
    "m = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec, ass_bertvec) \n",
    "m = m.coef_ \n",
    "print(m.shape) #this is the 768 by 768 transformation matrix between mbert and assbert \n",
    "mapped_= all_vec['mbert']['loan'] @ m.transpose()\n",
    "ass_beng_cos_mapped = get_cosine_similarities(mapped_, all_vec['ass_bert']['original'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc5b6c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>loan_word_epitran</th>\n",
       "      <th>original_word_epitran</th>\n",
       "      <th>loan_english</th>\n",
       "      <th>...</th>\n",
       "      <th>ass_bertmuril</th>\n",
       "      <th>indic_bertmbert</th>\n",
       "      <th>indic_bertxlm</th>\n",
       "      <th>indic_bertass_bert</th>\n",
       "      <th>indic_bertmuril</th>\n",
       "      <th>murilmbert</th>\n",
       "      <th>murilxlm</th>\n",
       "      <th>murilass_bert</th>\n",
       "      <th>murilindic_bert</th>\n",
       "      <th>mbert_src_assbert_trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>568</td>\n",
       "      <td>568</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kija</td>\n",
       "      <td>iea</td>\n",
       "      <td>Action</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999289</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>0.995359</td>\n",
       "      <td>-0.036194</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.998514</td>\n",
       "      <td>0.997798</td>\n",
       "      <td>-0.037001</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>-0.010115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sand</td>\n",
       "      <td>tndr</td>\n",
       "      <td>Chand</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999310</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>-0.036599</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.997993</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>-0.037443</td>\n",
       "      <td>0.999867</td>\n",
       "      <td>0.080588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>818</td>\n",
       "      <td>818</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pkila</td>\n",
       "      <td>bkul</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999154</td>\n",
       "      <td>0.994700</td>\n",
       "      <td>0.990668</td>\n",
       "      <td>-0.037378</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>0.998522</td>\n",
       "      <td>-0.037572</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>0.003350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td>bag</td>\n",
       "      <td>red</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>0.997704</td>\n",
       "      <td>0.995973</td>\n",
       "      <td>-0.037347</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.998912</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>-0.037650</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.066199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>665</td>\n",
       "      <td>665</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bil</td>\n",
       "      <td>pal</td>\n",
       "      <td>to the b</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.997192</td>\n",
       "      <td>0.992324</td>\n",
       "      <td>-0.037832</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.998419</td>\n",
       "      <td>0.998129</td>\n",
       "      <td>-0.037200</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.054813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>1710</td>\n",
       "      <td>1710</td>\n",
       "      <td>1710</td>\n",
       "      <td>269</td>\n",
       "      <td>269</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>gni</td>\n",
       "      <td>ana</td>\n",
       "      <td>Fire</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999530</td>\n",
       "      <td>0.997056</td>\n",
       "      <td>0.995438</td>\n",
       "      <td>-0.037099</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.998927</td>\n",
       "      <td>0.998485</td>\n",
       "      <td>-0.037632</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.020783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>1711</td>\n",
       "      <td>1711</td>\n",
       "      <td>1711</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>t</td>\n",
       "      <td>pea</td>\n",
       "      <td>The tail</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998865</td>\n",
       "      <td>0.996444</td>\n",
       "      <td>0.995111</td>\n",
       "      <td>-0.037162</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>-0.037122</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.032935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>1712</td>\n",
       "      <td>1712</td>\n",
       "      <td>1712</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>knd</td>\n",
       "      <td>aknd</td>\n",
       "      <td>hub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.998104</td>\n",
       "      <td>0.995225</td>\n",
       "      <td>-0.036582</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>0.997997</td>\n",
       "      <td>-0.037136</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>-0.064774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>1713</td>\n",
       "      <td>1713</td>\n",
       "      <td>1713</td>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kan</td>\n",
       "      <td>kan</td>\n",
       "      <td>ear</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.997004</td>\n",
       "      <td>0.992971</td>\n",
       "      <td>-0.037427</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.998260</td>\n",
       "      <td>-0.037465</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.020544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>1714</td>\n",
       "      <td>1714</td>\n",
       "      <td>1714</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>gla</td>\n",
       "      <td>baeu</td>\n",
       "      <td>Swallow</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.990788</td>\n",
       "      <td>0.982646</td>\n",
       "      <td>-0.036785</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.998217</td>\n",
       "      <td>0.998046</td>\n",
       "      <td>-0.037464</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.077583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1715 rows  49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0              0             0               0               568   \n",
       "1              1             1               1               119   \n",
       "2              2             2               2               818   \n",
       "3              3             3               3               277   \n",
       "4              4             4               4               665   \n",
       "...          ...           ...             ...               ...   \n",
       "1710        1710          1710            1710               269   \n",
       "1711        1711          1711            1711               153   \n",
       "1712        1712          1712            1712                48   \n",
       "1713        1713          1713            1713               790   \n",
       "1714        1714          1714            1714                76   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1 loan_word original_word loan_word_epitran  \\\n",
       "0                    568                       kija   \n",
       "1                    119                          sand   \n",
       "2                    818                          pkila   \n",
       "3                    277                                a   \n",
       "4                    665                             bil   \n",
       "...                  ...       ...           ...               ...   \n",
       "1710                 269                              gni   \n",
       "1711                 153                              t   \n",
       "1712                  48                        knd   \n",
       "1713                 790                                 kan   \n",
       "1714                  76                             gla   \n",
       "\n",
       "     original_word_epitran loan_english  ... ass_bertmuril  indic_bertmbert  \\\n",
       "0                   iea       Action  ...      0.999289         0.997465   \n",
       "1               tndr        Chand  ...      0.999310         0.998168   \n",
       "2                   bkul    butterfly  ...      0.999154         0.994700   \n",
       "3                    bag          red  ...      0.999649         0.997704   \n",
       "4                    pal     to the b  ...      0.999687         0.997192   \n",
       "...                    ...          ...  ...           ...              ...   \n",
       "1710                  ana         Fire  ...      0.999530         0.997056   \n",
       "1711                pea     The tail  ...      0.998865         0.996444   \n",
       "1712             aknd          hub  ...      0.999608         0.998104   \n",
       "1713                 kan          ear  ...      0.999526         0.997004   \n",
       "1714                 baeu      Swallow  ...      0.999689         0.990788   \n",
       "\n",
       "      indic_bertxlm  indic_bertass_bert  indic_bertmuril  murilmbert  \\\n",
       "0          0.995359           -0.036194         0.999959    0.998514   \n",
       "1          0.997567           -0.036599         0.999959    0.997993   \n",
       "2          0.990668           -0.037378         0.999927    0.998900   \n",
       "3          0.995973           -0.037347         0.999954    0.998912   \n",
       "4          0.992324           -0.037832         0.999953    0.998419   \n",
       "...             ...                 ...              ...         ...   \n",
       "1710       0.995438           -0.037099         0.999946    0.998927   \n",
       "1711       0.995111           -0.037162         0.999935    0.998588   \n",
       "1712       0.995225           -0.036582         0.999951    0.998639   \n",
       "1713       0.992971           -0.037427         0.999954    0.998824   \n",
       "1714       0.982646           -0.036785         0.999650    0.998217   \n",
       "\n",
       "      murilxlm  murilass_bert murilindic_bert mbert_src_assbert_trg  \n",
       "0     0.997798      -0.037001        0.999945             -0.010115  \n",
       "1     0.997674      -0.037443        0.999867              0.080588  \n",
       "2     0.998522      -0.037572        0.999914              0.003350  \n",
       "3     0.998547      -0.037650        0.999915              0.066199  \n",
       "4     0.998129      -0.037200        0.999898              0.054813  \n",
       "...        ...            ...             ...                   ...  \n",
       "1710  0.998485      -0.037632        0.999912              0.020783  \n",
       "1711  0.997881      -0.037122        0.999946              0.032935  \n",
       "1712  0.997997      -0.037136        0.999943             -0.064774  \n",
       "1713  0.998260      -0.037465        0.999940              0.020544  \n",
       "1714  0.998046      -0.037464        0.999873              0.077583  \n",
       "\n",
       "[1715 rows x 49 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ass_ben_train['mbert_src_assbert_trg'] = ass_beng_cos_mapped\n",
    "ass_ben_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef854a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert xlm\n",
      "mbert ass_bert\n",
      "mbert indic_bert\n",
      "mbert muril\n",
      "xlm mbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.17004e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.37965e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.17004e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm ass_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.37965e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.17004e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.37965e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm indic_bert\n",
      "xlm muril\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.17004e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.37965e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.21621e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert mbert\n",
      "ass_bert xlm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.21621e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.21621e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert indic_bert\n",
      "ass_bert muril\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.21621e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indic_bert mbert\n",
      "indic_bert xlm\n",
      "indic_bert ass_bert\n",
      "indic_bert muril\n",
      "muril mbert\n",
      "muril xlm\n",
      "muril ass_bert\n",
      "muril indic_bert\n",
      "mbertxlm [0.81422913 0.9049548  0.8283074  ... 0.8414111  0.72653395 0.8292563 ]\n",
      "mbertass_bert [-0.02195851 -0.01808187 -0.04044119 ... -0.03736622 -0.06029329\n",
      " -0.04182959]\n",
      "mbertindic_bert [0.999145   0.99959475 0.9984933  ... 0.9996923  0.9992353  0.9958416 ]\n",
      "mbertmuril [0.99905944 0.9985286  0.99879175 ... 0.9997323  0.99941474 0.99884534]\n",
      "xlmmbert [0.7086066  0.89907426 0.91591007 ... 0.87726027 0.84559566 0.8776003 ]\n",
      "xlmass_bert [-0.0197074  -0.01707486 -0.0403541  ... -0.0462508  -0.05708092\n",
      " -0.03930154]\n",
      "xlmindic_bert [0.9993415  0.99957055 0.998573   ... 0.9992578  0.99840796 0.9955033 ]\n",
      "xlmmuril [0.998371   0.9983493  0.9987029  ... 0.9984844  0.99921745 0.99828595]\n",
      "ass_bertmbert [0.7582203  0.92474973 0.92758924 ... 0.89519167 0.91026926 0.91854024]\n",
      "ass_bertxlm [0.82852423 0.9215591  0.87545663 ... 0.84163153 0.865111   0.8806467 ]\n",
      "ass_bertindic_bert [0.99961257 0.99969643 0.9988258  ... 0.99964744 0.99954474 0.9987945 ]\n",
      "ass_bertmuril [0.9992885  0.99930966 0.9991535  ... 0.99960846 0.999526   0.9996892 ]\n",
      "indic_bertmbert [0.99746525 0.99816793 0.9946995  ... 0.9981043  0.9970039  0.9907875 ]\n",
      "indic_bertxlm [0.995359   0.99756676 0.9906676  ... 0.99522483 0.99297124 0.98264635]\n",
      "indic_bertass_bert [-0.03619361 -0.0365987  -0.03737849 ... -0.03658162 -0.03742659\n",
      " -0.03678454]\n",
      "indic_bertmuril [0.99995905 0.9999588  0.9999267  ... 0.9999514  0.9999545  0.99964994]\n",
      "murilmbert [0.9985142  0.99799347 0.99890006 ... 0.9986393  0.998824   0.99821675]\n",
      "murilxlm [0.9977978  0.99767375 0.9985216  ... 0.9979966  0.9982602  0.9980457 ]\n",
      "murilass_bert [-0.03700086 -0.03744312 -0.03757237 ... -0.0371356  -0.03746517\n",
      " -0.03746393]\n",
      "murilindic_bert [0.9999454  0.99986714 0.99991405 ... 0.999943   0.99993956 0.99987304]\n"
     ]
    }
   ],
   "source": [
    "cos_mapped = get_lt_maps(all_vec) # get the mapped embeddings and transformed cosine sims for ass_ben_train\n",
    "for i, j  in cos_mapped.items():\n",
    "    print(i,j)\n",
    "    \n",
    "    ass_ben_train[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c21c753a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mbertxlm',\n",
       " 'mbertass_bert',\n",
       " 'mbertindic_bert',\n",
       " 'mbertmuril',\n",
       " 'xlmmbert',\n",
       " 'xlmass_bert',\n",
       " 'xlmindic_bert',\n",
       " 'xlmmuril',\n",
       " 'ass_bertmbert',\n",
       " 'ass_bertxlm',\n",
       " 'ass_bertindic_bert',\n",
       " 'ass_bertmuril',\n",
       " 'indic_bertmbert',\n",
       " 'indic_bertxlm',\n",
       " 'indic_bertass_bert',\n",
       " 'indic_bertmuril',\n",
       " 'murilmbert',\n",
       " 'murilxlm',\n",
       " 'murilass_bert',\n",
       " 'murilindic_bert']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cos_mapped.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77450910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2280: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/vocab.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/fcfbd016a54060fb3e7290d39ac4fd04b0c7ca2c683e5fdd87928b0feaa2c367.bd20142f530c7b681cef79e2153e77f8d9e8c9fdb3f6db29f37298198166236d\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/merges.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0693c49aba9ba31f442ba9a6c368bc400d2a81e5931d983d63d8648a043bf551.a1730275bc49c3d660f1d9bf50222d8cb849f3ae93e75e5865a3037650459b27\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/91dad0f1b901ee17a1ca86293a46619408e812441cfa380050cd03359564b95f.fabc897dd998cd3c78df5e8469be3194040e8a0f7dd4ee9278748dfcea803743\n",
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"_name_or_path\": \"xlm-mlm-100-1280\",\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/xlm-mlm-100-1280/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/5ba8c43e22aeb247eee7a4d27014eabe361cbfd2a9e00bd337946aaa0dece8ce.f11dc7ef5f30811d164556022e3174da0d6e8bb13676833dabdb1f50f61f39a5\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of XLMModel were initialized from the model checkpoint at xlm-mlm-100-1280.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Didn't find file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer.json. We won't load it.\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/spiece.model\n",
      "loading file None\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/added_tokens.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/special_tokens_map.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer_config.json\n",
      "Adding <pad> to the vocabulary\n",
      "loading configuration file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2\",\n",
      "  \"architectures\": [\n",
      "    \"AlbertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing AlbertModel.\n",
      "\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/spiece.model from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/97e976f62c951292c6fdb2bb5bf1f34f5450585dda98be8dedea2b97e4f25b86.5c8e83e7afe2b2faae1dc1a6b0fcdb911480df6af7079e9df53aa83ed0763de2\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.dense.weight', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at ai4bharat/indic-bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b97fc49fcc6c4b696e73d117cd105e9896633d546afdaa10fbdc2e3964b7ccce.6238bf3b1b7ad31c55bb4415faa9477a5f8e50723e8d1d70df19a65433db277f\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/special_tokens_map.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/290471f6a01c9af0dd0bcf02112dc77b9b0aee820ebb1fb023c96ac2dda9d8ef.750293617705dd39d21eef1e163d80ca5b23e1a0ec507fff24a087c44632142c\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/677de489a9460181a44c530abce89d7d341485a3d49dacc89a9b5a1fed34c328.94e1730f1b81d6fdf365e5e59d01a4e387286e650a02ed6512f3dba8668dd876\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/muril-base-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b4704f25323c21eafa8f1b6196e294d7252e11aa35d082c49d6ae62f3ca168dd.767d38e2461040f361197f7fc27e1968320609d399f194178c3adb49eeeb8ca9\n",
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at google/muril-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get all the mapped embeddings and cosine sims for ben_ass_test\n",
    "mbert_cos, all_vec = get_mbert_cos_sims(list(ben_ass_test['loan_word']),list(ben_ass_test['original_word']))\n",
    "xlm_cos, all_vec = get_xlm_cos_sims(list(ben_ass_test['loan_word']),list(ben_ass_test['original_word']))\n",
    "ass_bert_cos, all_vec = get_ass_albert_cos_sims(list(ben_ass_test['original_word']),list(ben_ass_test['loan_word']), lin_transform =True)\n",
    "indic_bert_cos, all_vec = Indic_bert_cos_sims(list(ben_ass_test['loan_word']),list(ben_ass_test['original_word']))\n",
    "muril_cos, all_vec = Muril_cos_sims(list(ben_ass_test['loan_word']),list(ben_ass_test['original_word']))\n",
    "\n",
    "# ben_ass_test['mbert_cos'] = mbert_cos\n",
    "# ben_ass_test['xlm_cos'] = xlm_cos\n",
    "# ben_ass_test['ass_bert_mbert_cos'] = ass_bert_cos\n",
    "# ben_ass_test['indic_bert_cos'] = indic_bert_cos\n",
    "# ben_ass_test['muril_cos'] = muril_cos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73c90348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert (1631, 768) (1631, 768) <class 'numpy.ndarray'>\n",
      "xlm (1631, 1280) (1631, 1280) <class 'numpy.ndarray'>\n",
      "ass_bert (1631, 768) (1631, 768) <class 'numpy.ndarray'>\n",
      "indic_bert (1631, 768) (1631, 768) <class 'numpy.ndarray'>\n",
      "muril (1631, 768) (1631, 768) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i, j in all_vec.items():\n",
    "    print(i,j['loan'].shape, j['original'].shape, type(j['original']))\n",
    "# all_vec['mbert']['loan'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed718ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768)\n"
     ]
    }
   ],
   "source": [
    "# get the linear transformation from mbert space to ass_bert space using the precalculated transformation matrix i.e beng_m_bertvec, ass_bertvec\n",
    "#for ben_ass_test\n",
    "m = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec, ass_bertvec) \n",
    "m = m.coef_ \n",
    "print(m.shape) #this is the 768 by 768 transformation matrix between mbert and assbert \n",
    "mapped_= all_vec['mbert']['loan'] @ m.transpose()\n",
    "beng_ass_test_cos_mapped = get_cosine_similarities(mapped_, all_vec['ass_bert']['original'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33ca8d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>loan_word_epitran</th>\n",
       "      <th>original_word_epitran</th>\n",
       "      <th>loan_english</th>\n",
       "      <th>...</th>\n",
       "      <th>ass_bertmuril</th>\n",
       "      <th>indic_bertmbert</th>\n",
       "      <th>indic_bertxlm</th>\n",
       "      <th>indic_bertass_bert</th>\n",
       "      <th>indic_bertmuril</th>\n",
       "      <th>murilmbert</th>\n",
       "      <th>murilxlm</th>\n",
       "      <th>murilass_bert</th>\n",
       "      <th>murilindic_bert</th>\n",
       "      <th>mbert_src_assbert_trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td>puti</td>\n",
       "      <td>Hat</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.995602</td>\n",
       "      <td>0.995207</td>\n",
       "      <td>-0.037043</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.998250</td>\n",
       "      <td>0.998064</td>\n",
       "      <td>-0.037110</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.053788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>lde</td>\n",
       "      <td>gla</td>\n",
       "      <td>Neck</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.993731</td>\n",
       "      <td>0.990757</td>\n",
       "      <td>-0.036650</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.997744</td>\n",
       "      <td>0.997690</td>\n",
       "      <td>-0.036971</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.003743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ka</td>\n",
       "      <td>k</td>\n",
       "      <td>Draw</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.996707</td>\n",
       "      <td>0.996931</td>\n",
       "      <td>-0.036699</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.997577</td>\n",
       "      <td>0.998135</td>\n",
       "      <td>-0.037100</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.069326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mia</td>\n",
       "      <td>ndi</td>\n",
       "      <td>Mida</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.993703</td>\n",
       "      <td>0.982903</td>\n",
       "      <td>-0.037739</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>0.998603</td>\n",
       "      <td>0.997843</td>\n",
       "      <td>-0.037069</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.022493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>onumti</td>\n",
       "      <td>pani</td>\n",
       "      <td>Permission</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.998033</td>\n",
       "      <td>0.997661</td>\n",
       "      <td>-0.037113</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.998184</td>\n",
       "      <td>0.998295</td>\n",
       "      <td>-0.037151</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.066781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>1626</td>\n",
       "      <td>1626</td>\n",
       "      <td>1626</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bada</td>\n",
       "      <td>taka</td>\n",
       "      <td>Fried</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.996144</td>\n",
       "      <td>0.994600</td>\n",
       "      <td>-0.037110</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.998329</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>-0.037136</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.063769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>1627</td>\n",
       "      <td>1627</td>\n",
       "      <td>1627</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>k</td>\n",
       "      <td>Bite</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.996940</td>\n",
       "      <td>0.987930</td>\n",
       "      <td>-0.036750</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998310</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>-0.036979</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.121835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mldz</td>\n",
       "      <td>xi</td>\n",
       "      <td>Good luck</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999517</td>\n",
       "      <td>0.995814</td>\n",
       "      <td>0.989882</td>\n",
       "      <td>-0.036404</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.998445</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>-0.037016</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.003480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>1629</td>\n",
       "      <td>1629</td>\n",
       "      <td>1629</td>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>nd</td>\n",
       "      <td>xndija</td>\n",
       "      <td>Evening</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.996680</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>-0.037186</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.998191</td>\n",
       "      <td>0.998367</td>\n",
       "      <td>-0.037138</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.010274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>1630</td>\n",
       "      <td>1630</td>\n",
       "      <td>1630</td>\n",
       "      <td>272</td>\n",
       "      <td>272</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>meee</td>\n",
       "      <td>akax</td>\n",
       "      <td>Girl</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.998088</td>\n",
       "      <td>0.993749</td>\n",
       "      <td>-0.037103</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.998008</td>\n",
       "      <td>0.998292</td>\n",
       "      <td>-0.037172</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.013591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows  49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0              0             0               0               328   \n",
       "1              1             1               1                60   \n",
       "2              2             2               2                15   \n",
       "3              3             3               3               255   \n",
       "4              4             4               4                 9   \n",
       "...          ...           ...             ...               ...   \n",
       "1626        1626          1626            1626               232   \n",
       "1627        1627          1627            1627                84   \n",
       "1628        1628          1628            1628               311   \n",
       "1629        1629          1629            1629               311   \n",
       "1630        1630          1630            1630               272   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1 loan_word original_word loan_word_epitran  \\\n",
       "0                    328                               a   \n",
       "1                     60                         lde   \n",
       "2                     15                                ka   \n",
       "3                    255                               mia   \n",
       "4                      9                        onumti   \n",
       "...                  ...       ...           ...               ...   \n",
       "1626                 232                           bada   \n",
       "1627                  84                                  \n",
       "1628                 311                     mldz   \n",
       "1629                 311                   nd   \n",
       "1630                 272                            meee   \n",
       "\n",
       "     original_word_epitran loan_english  ... ass_bertmuril  indic_bertmbert  \\\n",
       "0                    puti          Hat  ...      0.999896         0.995602   \n",
       "1                     gla         Neck  ...      0.999892         0.993731   \n",
       "2                      k         Draw  ...      0.999945         0.996707   \n",
       "3                     ndi         Mida  ...      0.999900         0.993703   \n",
       "4                     pani   Permission  ...      0.999640         0.998033   \n",
       "...                    ...          ...  ...           ...              ...   \n",
       "1626                  taka        Fried  ...      0.999945         0.996144   \n",
       "1627                   k         Bite  ...      0.999847         0.996940   \n",
       "1628                   xi    Good luck  ...      0.999517         0.995814   \n",
       "1629              xndija      Evening  ...      0.999760         0.996680   \n",
       "1630                  akax         Girl  ...      0.999922         0.998088   \n",
       "\n",
       "      indic_bertxlm  indic_bertass_bert  indic_bertmuril  murilmbert  \\\n",
       "0          0.995207           -0.037043         0.999959    0.998250   \n",
       "1          0.990757           -0.036650         0.999945    0.997744   \n",
       "2          0.996931           -0.036699         0.999989    0.997577   \n",
       "3          0.982903           -0.037739         0.999721    0.998603   \n",
       "4          0.997661           -0.037113         0.999993    0.998184   \n",
       "...             ...                 ...              ...         ...   \n",
       "1626       0.994600           -0.037110         0.999983    0.998329   \n",
       "1627       0.987930           -0.036750         0.999786    0.998310   \n",
       "1628       0.989882           -0.036404         0.999950    0.998445   \n",
       "1629       0.993957           -0.037186         0.999987    0.998191   \n",
       "1630       0.993749           -0.037103         0.999986    0.998008   \n",
       "\n",
       "      murilxlm  murilass_bert murilindic_bert mbert_src_assbert_trg  \n",
       "0     0.998064      -0.037110        0.999959              0.053788  \n",
       "1     0.997690      -0.036971        0.999936              0.003743  \n",
       "2     0.998135      -0.037100        0.999910              0.069326  \n",
       "3     0.997843      -0.037069        0.999968              0.022493  \n",
       "4     0.998295      -0.037151        0.999949              0.066781  \n",
       "...        ...            ...             ...                   ...  \n",
       "1626  0.998383      -0.037136        0.999948              0.063769  \n",
       "1627  0.997333      -0.036979        0.999958              0.121835  \n",
       "1628  0.997835      -0.037016        0.999963              0.003480  \n",
       "1629  0.998367      -0.037138        0.999944              0.010274  \n",
       "1630  0.998292      -0.037172        0.999939              0.013591  \n",
       "\n",
       "[1631 rows x 49 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_ass_test['mbert_src_assbert_trg'] = beng_ass_test_cos_mapped \n",
    "ben_ass_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "108d7cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert xlm\n",
      "mbert ass_bert\n",
      "mbert indic_bert\n",
      "mbert muril\n",
      "xlm mbert\n",
      "xlm ass_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.02671e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.25199e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.02671e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.25199e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.02671e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm indic_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.25199e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.02671e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.25199e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm muril\n",
      "ass_bert mbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.34718e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.34718e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert xlm\n",
      "ass_bert indic_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.34718e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.34718e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert muril\n",
      "indic_bert mbert\n",
      "indic_bert xlm\n",
      "indic_bert ass_bert\n",
      "indic_bert muril\n",
      "muril mbert\n",
      "muril xlm\n",
      "muril ass_bert\n",
      "muril indic_bert\n",
      "mbertxlm [0.68755674 0.6841567  0.8534988  ... 0.82382274 0.84723943 0.6884533 ]\n",
      "mbertass_bert [-0.03226281 -0.03727898 -0.03546291 ... -0.02263128 -0.02630463\n",
      " -0.03139025]\n",
      "mbertindic_bert [0.9993046  0.99761856 0.99946994 ... 0.9992995  0.9992915  0.99969566]\n",
      "mbertmuril [0.99955285 0.99912673 0.9995197  ... 0.99956286 0.9997964  0.99970603]\n",
      "xlmmbert [0.752661   0.896068   0.97391474 ... 0.8989773  0.9174396  0.83722556]\n",
      "xlmass_bert [-0.03177009 -0.03839995 -0.03367117 ... -0.01886591 -0.02574864\n",
      " -0.03231563]\n",
      "xlmindic_bert [0.9992496  0.9971322  0.99961483 ... 0.99843436 0.9987686  0.99955803]\n",
      "xlmmuril [0.99931383 0.9988723  0.9991207  ... 0.9991207  0.9997629  0.9996088 ]\n",
      "ass_bertmbert [0.97233784 0.96923876 0.98733175 ... 0.9767873  0.9857687  0.9736726 ]\n",
      "ass_bertxlm [0.9623678  0.94629645 0.9579295  ... 0.9473304  0.95603776 0.93384033]\n",
      "ass_bertindic_bert [0.9999118 0.9993599 0.9999355 ... 0.9998403 0.9998528 0.9998953]\n",
      "ass_bertmuril [0.9998965  0.99989223 0.999945   ... 0.9995174  0.9997602  0.99992216]\n",
      "indic_bertmbert [0.9956024  0.9937305  0.9967067  ... 0.99581367 0.99667984 0.99808836]\n",
      "indic_bertxlm [0.9952071  0.99075735 0.99693054 ... 0.9898816  0.99395657 0.99374884]\n",
      "indic_bertass_bert [-0.03704281 -0.03664971 -0.03669919 ... -0.03640383 -0.03718582\n",
      " -0.0371028 ]\n",
      "indic_bertmuril [0.9999594  0.9999454  0.99998945 ... 0.99994993 0.9999865  0.9999864 ]\n",
      "murilmbert [0.99825   0.9977438 0.9975773 ... 0.9984449 0.9981906 0.9980075]\n",
      "murilxlm [0.99806446 0.9976903  0.9981352  ... 0.99783504 0.9983667  0.9982916 ]\n",
      "murilass_bert [-0.0371102  -0.03697082 -0.03710019 ... -0.03701585 -0.037138\n",
      " -0.03717186]\n",
      "murilindic_bert [0.9999589  0.9999357  0.99991035 ... 0.9999628  0.99994385 0.9999386 ]\n"
     ]
    }
   ],
   "source": [
    "cos_mapped = get_lt_maps(all_vec) # get the mapped embeddings and cosine sims for ass_ben_train\n",
    "for i, j  in cos_mapped.items():\n",
    "    print(i,j)\n",
    "    \n",
    "    ben_ass_test[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5edff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2280: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/vocab.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/fcfbd016a54060fb3e7290d39ac4fd04b0c7ca2c683e5fdd87928b0feaa2c367.bd20142f530c7b681cef79e2153e77f8d9e8c9fdb3f6db29f37298198166236d\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/merges.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0693c49aba9ba31f442ba9a6c368bc400d2a81e5931d983d63d8648a043bf551.a1730275bc49c3d660f1d9bf50222d8cb849f3ae93e75e5865a3037650459b27\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/91dad0f1b901ee17a1ca86293a46619408e812441cfa380050cd03359564b95f.fabc897dd998cd3c78df5e8469be3194040e8a0f7dd4ee9278748dfcea803743\n",
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"_name_or_path\": \"xlm-mlm-100-1280\",\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/xlm-mlm-100-1280/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/5ba8c43e22aeb247eee7a4d27014eabe361cbfd2a9e00bd337946aaa0dece8ce.f11dc7ef5f30811d164556022e3174da0d6e8bb13676833dabdb1f50f61f39a5\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of XLMModel were initialized from the model checkpoint at xlm-mlm-100-1280.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Didn't find file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer.json. We won't load it.\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/spiece.model\n",
      "loading file None\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/added_tokens.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/special_tokens_map.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer_config.json\n",
      "Adding <pad> to the vocabulary\n",
      "loading configuration file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2\",\n",
      "  \"architectures\": [\n",
      "    \"AlbertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing AlbertModel.\n",
      "\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/spiece.model from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/97e976f62c951292c6fdb2bb5bf1f34f5450585dda98be8dedea2b97e4f25b86.5c8e83e7afe2b2faae1dc1a6b0fcdb911480df6af7079e9df53aa83ed0763de2\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.dense.weight', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at ai4bharat/indic-bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b97fc49fcc6c4b696e73d117cd105e9896633d546afdaa10fbdc2e3964b7ccce.6238bf3b1b7ad31c55bb4415faa9477a5f8e50723e8d1d70df19a65433db277f\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/special_tokens_map.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/290471f6a01c9af0dd0bcf02112dc77b9b0aee820ebb1fb023c96ac2dda9d8ef.750293617705dd39d21eef1e163d80ca5b23e1a0ec507fff24a087c44632142c\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/677de489a9460181a44c530abce89d7d341485a3d49dacc89a9b5a1fed34c328.94e1730f1b81d6fdf365e5e59d01a4e387286e650a02ed6512f3dba8668dd876\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/muril-base-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b4704f25323c21eafa8f1b6196e294d7252e11aa35d082c49d6ae62f3ca168dd.767d38e2461040f361197f7fc27e1968320609d399f194178c3adb49eeeb8ca9\n",
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at google/muril-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mbert_cos = get_mbert_cos_sims(list(ass_ben_test['loan_word']),list(ass_ben_test['original_word']))\n",
    "xlm_cos = get_xlm_cos_sims(list(ass_ben_test['loan_word']),list(ass_ben_test['original_word']))\n",
    "ass_bert_cos = get_ass_albert_cos_sims(list(ass_ben_test['loan_word']),list(ass_ben_test['original_word']), lin_transform =True)\n",
    "indic_bert_cos = Indic_bert_cos_sims(list(ass_ben_test['loan_word']),list(ass_ben_test['original_word']))\n",
    "muril_cos = Muril_cos_sims(list(ass_ben_test['loan_word']),list(ass_ben_test['original_word']))\n",
    " \n",
    "# ass_ben_test['mbert_cos'] = mbert_cos\n",
    "# ass_ben_test['xlm_cos'] = xlm_cos\n",
    "# ass_ben_test['ass_bert_mbert_cos'] = ass_bert_cos\n",
    "# ass_ben_test['indic_bert_cos'] = indic_bert_cos\n",
    "# ass_ben_test['muril_cos'] = muril_cos   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da7af5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert (1700, 768) (1700, 768) <class 'numpy.ndarray'>\n",
      "xlm (1700, 1280) (1700, 1280) <class 'numpy.ndarray'>\n",
      "ass_bert (1700, 768) (1700, 768) <class 'numpy.ndarray'>\n",
      "indic_bert (1700, 768) (1700, 768) <class 'numpy.ndarray'>\n",
      "muril (1700, 768) (1700, 768) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i, j in all_vec.items():\n",
    "    print(i,j['loan'].shape, j['original'].shape, type(j['original']))\n",
    "# all_vec['mbert']['loan'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3df06606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768)\n"
     ]
    }
   ],
   "source": [
    "# get the linear transformation from mbert space to ass_bert space using the precalculated transformation matrix i.e beng_m_bertvec, ass_bertvec\n",
    "#for ass_ben_test\n",
    "m = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec, ass_bertvec) \n",
    "m = m.coef_ \n",
    "print(m.shape) #this is the 768 by 768 transformation matrix between mbert and assbert \n",
    "mapped_= all_vec['mbert']['loan'] @ m.transpose()\n",
    "ass_beng_test_cos_mapped = get_cosine_similarities(mapped_, all_vec['ass_bert']['original'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12eae1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>loan_word_epitran</th>\n",
       "      <th>original_word_epitran</th>\n",
       "      <th>loan_english</th>\n",
       "      <th>...</th>\n",
       "      <th>ass_bertmuril</th>\n",
       "      <th>indic_bertmbert</th>\n",
       "      <th>indic_bertxlm</th>\n",
       "      <th>indic_bertass_bert</th>\n",
       "      <th>indic_bertmuril</th>\n",
       "      <th>murilmbert</th>\n",
       "      <th>murilxlm</th>\n",
       "      <th>murilass_bert</th>\n",
       "      <th>murilindic_bert</th>\n",
       "      <th>mbert_src_assbert_trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>azi</td>\n",
       "      <td>dt</td>\n",
       "      <td>today</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999816</td>\n",
       "      <td>0.995245</td>\n",
       "      <td>0.984364</td>\n",
       "      <td>-0.037255</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.998842</td>\n",
       "      <td>0.998491</td>\n",
       "      <td>-0.037662</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.003580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>424</td>\n",
       "      <td>424</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bxtu</td>\n",
       "      <td>bkti</td>\n",
       "      <td>Objects</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.998458</td>\n",
       "      <td>0.995757</td>\n",
       "      <td>-0.037769</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.998917</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>-0.037490</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.134114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>gxi</td>\n",
       "      <td>kla</td>\n",
       "      <td>Gosain</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997764</td>\n",
       "      <td>0.995150</td>\n",
       "      <td>0.983945</td>\n",
       "      <td>-0.036948</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.996424</td>\n",
       "      <td>-0.037293</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.081233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>xi</td>\n",
       "      <td>oot</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.997368</td>\n",
       "      <td>0.994264</td>\n",
       "      <td>-0.035945</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.998593</td>\n",
       "      <td>0.997663</td>\n",
       "      <td>-0.036670</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.063111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>Duck</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>0.995704</td>\n",
       "      <td>0.991231</td>\n",
       "      <td>-0.036069</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.998209</td>\n",
       "      <td>0.997781</td>\n",
       "      <td>-0.036462</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.116244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1695</td>\n",
       "      <td>1695</td>\n",
       "      <td>1695</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>laz</td>\n",
       "      <td>ldda</td>\n",
       "      <td>Shame</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.993459</td>\n",
       "      <td>-0.037235</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>-0.037537</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.099490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>1696</td>\n",
       "      <td>1696</td>\n",
       "      <td>1696</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kj</td>\n",
       "      <td>okki</td>\n",
       "      <td>Axis</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999457</td>\n",
       "      <td>0.994719</td>\n",
       "      <td>0.988365</td>\n",
       "      <td>-0.036510</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.998698</td>\n",
       "      <td>0.997802</td>\n",
       "      <td>-0.037324</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.043864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>1697</td>\n",
       "      <td>1697</td>\n",
       "      <td>1697</td>\n",
       "      <td>586</td>\n",
       "      <td>586</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sd</td>\n",
       "      <td>dt</td>\n",
       "      <td>The moon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.997607</td>\n",
       "      <td>0.996476</td>\n",
       "      <td>-0.036991</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.998912</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>-0.037662</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.170446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>1698</td>\n",
       "      <td>1698</td>\n",
       "      <td>1698</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>xsa</td>\n",
       "      <td>bad</td>\n",
       "      <td>true</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.997836</td>\n",
       "      <td>0.996538</td>\n",
       "      <td>-0.037763</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.998426</td>\n",
       "      <td>0.998303</td>\n",
       "      <td>-0.037575</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.083471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1699</td>\n",
       "      <td>1699</td>\n",
       "      <td>1699</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>gma</td>\n",
       "      <td>gama</td>\n",
       "      <td>Sweat</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>0.995235</td>\n",
       "      <td>0.989131</td>\n",
       "      <td>-0.036336</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.998407</td>\n",
       "      <td>0.998010</td>\n",
       "      <td>-0.036879</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.019352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows  49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0              0             0               0                20   \n",
       "1              1             1               1               424   \n",
       "2              2             2               2                83   \n",
       "3              3             3               3               318   \n",
       "4              4             4               4               129   \n",
       "...          ...           ...             ...               ...   \n",
       "1695        1695          1695            1695               296   \n",
       "1696        1696          1696            1696                 7   \n",
       "1697        1697          1697            1697               586   \n",
       "1698        1698          1698            1698               327   \n",
       "1699        1699          1699            1699                88   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1 loan_word original_word loan_word_epitran  \\\n",
       "0                     20                                azi   \n",
       "1                    424                           bxtu   \n",
       "2                     83                            gxi   \n",
       "3                    318                               xi   \n",
       "4                    129                              d   \n",
       "...                  ...       ...           ...               ...   \n",
       "1695                 296                               laz   \n",
       "1696                   7                            kj   \n",
       "1697                 586                              sd   \n",
       "1698                 327                              xsa   \n",
       "1699                  88                              gma   \n",
       "\n",
       "     original_word_epitran loan_english  ... ass_bertmuril  indic_bertmbert  \\\n",
       "0                   dt        today  ...      0.999816         0.995245   \n",
       "1                  bkti      Objects  ...      0.999737         0.998458   \n",
       "2                     kla       Gosain  ...      0.997764         0.995150   \n",
       "3                    oot          Mr.  ...      0.999268         0.997368   \n",
       "4                              Duck  ...      0.999721         0.995704   \n",
       "...                    ...          ...  ...           ...              ...   \n",
       "1695             ldda        Shame  ...      0.999359         0.997234   \n",
       "1696                 okki         Axis  ...      0.999457         0.994719   \n",
       "1697                dt     The moon  ...      0.999868         0.997607   \n",
       "1698                 bad         true  ...      0.998944         0.997836   \n",
       "1699                 gama        Sweat  ...      0.999729         0.995235   \n",
       "\n",
       "      indic_bertxlm  indic_bertass_bert  indic_bertmuril  murilmbert  \\\n",
       "0          0.984364           -0.037255         0.999860    0.998842   \n",
       "1          0.995757           -0.037769         0.999962    0.998917   \n",
       "2          0.983945           -0.036948         0.999825    0.997333   \n",
       "3          0.994264           -0.035945         0.999937    0.998593   \n",
       "4          0.991231           -0.036069         0.999895    0.998209   \n",
       "...             ...                 ...              ...         ...   \n",
       "1695       0.993459           -0.037235         0.999956    0.998167   \n",
       "1696       0.988365           -0.036510         0.999899    0.998698   \n",
       "1697       0.996476           -0.036991         0.999951    0.998912   \n",
       "1698       0.996538           -0.037763         0.999941    0.998426   \n",
       "1699       0.989131           -0.036336         0.999837    0.998407   \n",
       "\n",
       "      murilxlm  murilass_bert murilindic_bert mbert_src_assbert_trg  \n",
       "0     0.998491      -0.037662        0.999918              0.003580  \n",
       "1     0.998437      -0.037490        0.999925              0.134114  \n",
       "2     0.996424      -0.037293        0.999829              0.081233  \n",
       "3     0.997663      -0.036670        0.999940              0.063111  \n",
       "4     0.997781      -0.036462        0.999917              0.116244  \n",
       "...        ...            ...             ...                   ...  \n",
       "1695  0.997904      -0.037537        0.999868              0.099490  \n",
       "1696  0.997802      -0.037324        0.999946              0.043864  \n",
       "1697  0.998486      -0.037662        0.999921              0.170446  \n",
       "1698  0.998303      -0.037575        0.999887              0.083471  \n",
       "1699  0.998010      -0.036879        0.999918              0.019352  \n",
       "\n",
       "[1700 rows x 49 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ass_ben_test['mbert_src_assbert_trg'] = ass_beng_test_cos_mapped\n",
    "ass_ben_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c0f5a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert xlm\n",
      "mbert ass_bert\n",
      "mbert indic_bert\n",
      "mbert muril\n",
      "xlm mbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.23923e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.4278e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm ass_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.23923e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.4278e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.23923e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm indic_bert\n",
      "xlm muril\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.4278e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.23923e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.4278e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert mbert\n",
      "ass_bert xlm\n",
      "ass_bert indic_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.23287e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.23287e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.23287e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert muril\n",
      "indic_bert mbert\n",
      "indic_bert xlm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.23287e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indic_bert ass_bert\n",
      "indic_bert muril\n",
      "muril mbert\n",
      "muril xlm\n",
      "muril ass_bert\n",
      "muril indic_bert\n",
      "mbertxlm [0.7835372  0.8324632  0.7524152  ... 0.83098465 0.8068333  0.8784781 ]\n",
      "mbertass_bert [-0.02294929 -0.02864049 -0.04234096 ... -0.02772318 -0.035661\n",
      " -0.03385013]\n",
      "mbertindic_bert [0.99575704 0.99916756 0.996084   ... 0.9997469  0.99915326 0.998631  ]\n",
      "mbertmuril [0.99969953 0.99971086 0.997231   ... 0.9998252  0.9987678  0.9994286 ]\n",
      "xlmmbert [0.8258198  0.8333431  0.76705796 ... 0.7853576  0.9124824  0.95633495]\n",
      "xlmass_bert [-0.02109283 -0.02265036 -0.04356567 ... -0.02540999 -0.03646286\n",
      " -0.02866849]\n",
      "xlmindic_bert [0.9954077  0.9984507  0.99488956 ... 0.99955475 0.9991399  0.99553984]\n",
      "xlmmuril [0.9996149  0.9997564  0.99652153 ... 0.9997771  0.99840975 0.99922234]\n",
      "ass_bertmbert [0.87931776 0.942175   0.82123417 ... 0.8644617  0.9282237  0.9772395 ]\n",
      "ass_bertxlm [0.8653891  0.88182724 0.7863366  ... 0.8756689  0.8359395  0.96302044]\n",
      "ass_bertindic_bert [0.998331   0.99960446 0.9974607  ... 0.9995295  0.9993796  0.99899477]\n",
      "ass_bertmuril [0.99981576 0.99973726 0.99776447 ... 0.999868   0.99894446 0.99972934]\n",
      "indic_bertmbert [0.99524486 0.9984577  0.9951499  ... 0.9976066  0.99783623 0.9952351 ]\n",
      "indic_bertxlm [0.9843641  0.9957572  0.9839449  ... 0.9964763  0.9965382  0.98913074]\n",
      "indic_bertass_bert [-0.03725499 -0.0377688  -0.0369476  ... -0.03699121 -0.03776292\n",
      " -0.0363365 ]\n",
      "indic_bertmuril [0.9998599  0.9999622  0.9998254  ... 0.9999508  0.99994123 0.99983716]\n",
      "murilmbert [0.99884164 0.99891746 0.9973332  ... 0.99891174 0.9984257  0.99840724]\n",
      "murilxlm [0.9984909  0.99843657 0.9964235  ... 0.9984859  0.9983027  0.9980104 ]\n",
      "murilass_bert [-0.03766162 -0.03748998 -0.03729313 ... -0.03766231 -0.03757496\n",
      " -0.03687856]\n",
      "murilindic_bert [0.999918  0.9999249 0.9998285 ... 0.9999214 0.9998865 0.9999177]\n"
     ]
    }
   ],
   "source": [
    "cos_mapped = get_lt_maps(all_vec) # get the mapped embeddings and cosine sims for ass_ben_test\n",
    "for i, j  in cos_mapped.items():\n",
    "    print(i,j)\n",
    "    \n",
    "    ass_ben_test[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d5f0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "ben_ass_train.to_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Bengali-Assamese-train_production_alldata.csv')\n",
    "ass_ben_train.to_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Assamese-Bengali-train_production_alldata.csv')\n",
    "ben_ass_test.to_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Bengali-Assamese-test_production_alldata.csv')\n",
    "ass_ben_test.to_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Assamese-Bengali-test_production_alldata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcffe48",
   "metadata": {},
   "source": [
    "# Load `language-pairs.json` list and run pipeline for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44a4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9700120",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f: # for getting logits from all languages\n",
    " \n",
    "    \n",
    "    pairs = json.loads(f.read())\n",
    "for pair in pairs:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs-holdout.json', 'r') as f: # for getting logits from all languages\n",
    " \n",
    "    \n",
    "    pairs = json.loads(f.read())\n",
    "for pair in pairs:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231fcdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f:\n",
    "    pairs = json.loads(f.read())\n",
    "\n",
    "for pair in pairs:\n",
    "    print(pair)\n",
    "    L1 = pairs[pair]['target']['name']\n",
    "    L2 = pairs[pair]['source']['name']\n",
    "    \n",
    "    # load datasets\n",
    "    prefix = f'../Datasets/production_train_test/{L1}-{L2}'\n",
    "    \n",
    "    train_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata.csv')\n",
    "    test_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata.csv')\n",
    "\n",
    "    train_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    test_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')\n",
    "\n",
    "    # get and pad PanPhon features for alldata split\n",
    "    get_panphon_features(train_alldata, test_alldata)\n",
    "    alldata_maxlen = (max(np.max(train_alldata['features_loan'].str.len()),\\\n",
    "                          np.max(test_alldata['features_loan'].str.len())),\\\n",
    "                      max(np.max(train_alldata['features_orig'].str.len()),\\\n",
    "                          np.max(test_alldata['features_orig'].str.len())))\n",
    "    pad_panphon_features(train_alldata, test_alldata, alldata_maxlen)\n",
    "\n",
    "    # add target labels\n",
    "    Y_train, Y_test = add_target_labels(train_alldata, test_alldata)\n",
    "\n",
    "    # make train and val splits\n",
    "    X_train, X_val, X_test, Y_train, Y_val = make_train_val_set(train_alldata, test_alldata, Y_train)\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test)\n",
    "\n",
    "    # instantiate network\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\nUsing {device} device\\n\")\n",
    "    \n",
    "    # set random seeds for reproducibility\n",
    "    np.random.seed(666)\n",
    "\n",
    "    model = NeuralNetwork(X_train.shape[1]).to(device)\n",
    "    print(model,\"\\n\")\n",
    "\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "    # train and plot losses, accuracy\n",
    "    train_losses, val_losses, train_accur, val_accur = \\\n",
    "        model.fit(X_train, Y_train, X_val, Y_val, criterion, optimizer)\n",
    "    model.plot_losses(train_losses,val_losses,train_accur,val_accur)\n",
    "\n",
    "    # get and pad PanPhon features for realdist and balanced splits\n",
    "    get_panphon_features(train_realdist,test_realdist)\n",
    "    pad_panphon_features(train_realdist,test_realdist,alldata_maxlen)\n",
    "\n",
    "    get_panphon_features(train_balanced,test_balanced)\n",
    "    pad_panphon_features(train_balanced,test_balanced,alldata_maxlen)\n",
    "\n",
    "    # create data to get logits for\n",
    "    X_train_alldata = torch.tensor(np.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                         np.array([x for x in train_alldata['features_orig']])])).to(device)\n",
    "    X_test_alldata = torch.tensor(np.hstack([np.array([x for x in test_alldata['features_loan']]),\\\n",
    "                        np.array([x for x in test_alldata['features_orig']])])).to(device)\n",
    "\n",
    "    X_train_realdist = torch.tensor(np.hstack([np.array([x for x in train_realdist['features_loan']]),\\\n",
    "                         np.array([x for x in train_realdist['features_orig']])])).to(device)\n",
    "    X_test_realdist = torch.tensor(np.hstack([np.array([x for x in test_realdist['features_loan']]),\\\n",
    "                        np.array([x for x in test_realdist['features_orig']])])).to(device)\n",
    "\n",
    "    X_train_balanced = torch.tensor(np.hstack([np.array([x for x in train_balanced['features_loan']]),\\\n",
    "                         np.array([x for x in train_balanced['features_orig']])])).to(device)\n",
    "    X_test_balanced = torch.tensor(np.hstack([np.array([x for x in test_balanced['features_loan']]),\\\n",
    "                        np.array([x for x in test_balanced['features_orig']])])).to(device)\n",
    "\n",
    "    # place model in eval mode and get logits from DNN for all datasets/splits\n",
    "    print(\"Getting logits from DNN\")\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_logits_dnn_alldata = model(X_train_alldata.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_alldata = model(X_test_alldata.float())[1].detach().cpu().numpy()\n",
    "        train_logits_dnn_realdist = model(X_train_realdist.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_realdist = model(X_test_realdist.float())[1].detach().cpu().numpy()\n",
    "        train_logits_dnn_balanced = model(X_train_balanced.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_balanced = model(X_test_balanced.float())[1].detach().cpu().numpy()\n",
    "\n",
    "    # remove PanPhon features from dataframe and add logits column\n",
    "    train_alldata = train_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_alldata['DNN_logits'] = train_logits_dnn_alldata\n",
    "\n",
    "    test_alldata = test_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_alldata['DNN_logits'] = test_logits_dnn_alldata\n",
    "\n",
    "    train_realdist = train_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_realdist['DNN_logits'] = train_logits_dnn_realdist\n",
    "\n",
    "    test_realdist = test_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_realdist['DNN_logits'] = test_logits_dnn_realdist\n",
    "\n",
    "    train_balanced = train_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_balanced['DNN_logits'] = train_logits_dnn_balanced\n",
    "\n",
    "    test_balanced = test_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_balanced['DNN_logits'] = test_logits_dnn_balanced\n",
    "\n",
    "    #set the seeds for reproducibility even though we are not fine-tuning or training and the weights \n",
    "    #for both these models are effectively frozen for our purpose \n",
    "    torch.manual_seed(7)\n",
    "    random.seed(7)\n",
    "    np.random.seed(7)\n",
    "\n",
    "    # Setting PyTorch's required configuration variables for reproducibility.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "\n",
    "    PRE_TRAINED_bert_MODEL = 'bert-base-multilingual-cased'\n",
    "    PRE_TRAINED_xlm_MODEL = 'xlm-mlm-100-1280'\n",
    "\n",
    "    MAXTOKENS = 5\n",
    "    BS = 8  # batch size\n",
    "\n",
    "    #list of loan-original words for train sets\n",
    "    l1_train_alldata = list(train_alldata[\"loan_word\"])\n",
    "    l2_train_alldata = list(train_alldata[\"original_word\"])\n",
    "\n",
    "    l1_train_realdist = list(train_realdist[\"loan_word\"])\n",
    "    l2_train_realdist = list(train_realdist[\"original_word\"])\n",
    "\n",
    "    l1_train_balanced = list(train_balanced[\"loan_word\"])\n",
    "    l2_train_balanced = list(train_balanced[\"original_word\"])\n",
    "\n",
    "    #list of loan-original words for test sets\n",
    "    l1_test_alldata = list(test_alldata[\"loan_word\"])\n",
    "    l2_test_alldata = list(test_alldata[\"original_word\"])\n",
    "\n",
    "    l1_test_realdist = list(test_realdist[\"loan_word\"])\n",
    "    l2_test_realdist = list(test_realdist[\"original_word\"])\n",
    "\n",
    "    l1_test_balanced = list(test_balanced[\"loan_word\"])\n",
    "    l2_test_balanced = list(test_balanced[\"original_word\"])\n",
    "\n",
    "    print(\"Getting MBERT similarities\")\n",
    "    train_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    test_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    train_realdist['MBERT_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    train_balanced['MBERT_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    test_realdist['MBERT_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    test_balanced['MBERT_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    print()\n",
    "    print(\"Getting XLM similarities\")\n",
    "    train_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    test_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    train_realdist['XLM_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    train_balanced['XLM_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "\n",
    "    test_realdist['XLM_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    test_balanced['XLM_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "        \n",
    "    train_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata.csv')\n",
    "    test_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata.csv')\n",
    "\n",
    "    train_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    test_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_test_alldata,l2_test_alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25016d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced['MBERT_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3363a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "print(train_realdist.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b372a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f: # for getting logits from all languages\n",
    " \n",
    "    \n",
    "    pairs = json.loads(f.read())\n",
    "\n",
    "for pair in pairs:\n",
    "    print(pair)\n",
    "    L1 = pairs[pair]['target']['name']\n",
    "    L2 = pairs[pair]['source']['name']\n",
    "    \n",
    "    # load datasets\n",
    "    prefix = f'../Datasets/production_train_test/{L1}-{L2}'\n",
    "    \n",
    "    train_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata.csv')\n",
    "    test_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata.csv')\n",
    "\n",
    "    train_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    test_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')\n",
    "\n",
    "    # get and pad PanPhon features for alldata split\n",
    "    get_panphon_features(train_alldata, test_alldata)\n",
    "    alldata_maxlen = (max(np.max(train_alldata['features_loan'].str.len()),\\\n",
    "                          np.max(test_alldata['features_loan'].str.len())),\\\n",
    "                      max(np.max(train_alldata['features_orig'].str.len()),\\\n",
    "                          np.max(test_alldata['features_orig'].str.len())))\n",
    "    pad_panphon_features(train_alldata, test_alldata, alldata_maxlen)\n",
    "\n",
    "    # add target labels\n",
    "    Y_train, Y_test = add_target_labels(train_alldata, test_alldata)\n",
    "\n",
    "    # make train and val splits\n",
    "    X_train, X_val, X_test, Y_train, Y_val = make_train_val_set(train_alldata, test_alldata, Y_train)\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test)\n",
    "\n",
    "    # instantiate network\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\nUsing {device} device\\n\")\n",
    "    \n",
    "    # set random seeds for reproducibility\n",
    "    np.random.seed(666)\n",
    "\n",
    "    model = NeuralNetwork(X_train.shape[1]).to(device)\n",
    "    print(model,\"\\n\")\n",
    "\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "    # train and plot losses, accuracy\n",
    "    train_losses, val_losses, train_accur, val_accur = \\\n",
    "        model.fit(X_train, Y_train, X_val, Y_val, criterion, optimizer)\n",
    "    model.plot_losses(train_losses,val_losses,train_accur,val_accur)\n",
    "\n",
    "    # get and pad PanPhon features for realdist and balanced splits\n",
    "    get_panphon_features(train_realdist,test_realdist)\n",
    "    pad_panphon_features(train_realdist,test_realdist,alldata_maxlen)\n",
    "\n",
    "    get_panphon_features(train_balanced,test_balanced)\n",
    "    pad_panphon_features(train_balanced,test_balanced,alldata_maxlen)\n",
    "\n",
    "    # create data to get logits for\n",
    "    X_train_alldata = torch.tensor(np.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                         np.array([x for x in train_alldata['features_orig']])])).to(device)\n",
    "    X_test_alldata = torch.tensor(np.hstack([np.array([x for x in test_alldata['features_loan']]),\\\n",
    "                        np.array([x for x in test_alldata['features_orig']])])).to(device)\n",
    "\n",
    "    X_train_realdist = torch.tensor(np.hstack([np.array([x for x in train_realdist['features_loan']]),\\\n",
    "                         np.array([x for x in train_realdist['features_orig']])])).to(device)\n",
    "    X_test_realdist = torch.tensor(np.hstack([np.array([x for x in test_realdist['features_loan']]),\\\n",
    "                        np.array([x for x in test_realdist['features_orig']])])).to(device)\n",
    "\n",
    "    X_train_balanced = torch.tensor(np.hstack([np.array([x for x in train_balanced['features_loan']]),\\\n",
    "                         np.array([x for x in train_balanced['features_orig']])])).to(device)\n",
    "    X_test_balanced = torch.tensor(np.hstack([np.array([x for x in test_balanced['features_loan']]),\\\n",
    "                        np.array([x for x in test_balanced['features_orig']])])).to(device)\n",
    "\n",
    "    # place model in eval mode and get logits from DNN for all datasets/splits\n",
    "    print(\"Getting logits from DNN\")\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_logits_dnn_alldata = model(X_train_alldata.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_alldata = model(X_test_alldata.float())[1].detach().cpu().numpy()\n",
    "        train_logits_dnn_realdist = model(X_train_realdist.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_realdist = model(X_test_realdist.float())[1].detach().cpu().numpy()\n",
    "        train_logits_dnn_balanced = model(X_train_balanced.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_balanced = model(X_test_balanced.float())[1].detach().cpu().numpy()\n",
    "\n",
    "    # remove PanPhon features from dataframe and add logits column\n",
    "    train_alldata = train_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_alldata['DNN_logits'] = train_logits_dnn_alldata\n",
    "\n",
    "    test_alldata = test_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_alldata['DNN_logits'] = test_logits_dnn_alldata\n",
    "\n",
    "    train_realdist = train_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_realdist['DNN_logits'] = train_logits_dnn_realdist\n",
    "\n",
    "    test_realdist = test_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_realdist['DNN_logits'] = test_logits_dnn_realdist\n",
    "\n",
    "    train_balanced = train_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_balanced['DNN_logits'] = train_logits_dnn_balanced\n",
    "\n",
    "    test_balanced = test_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_balanced['DNN_logits'] = test_logits_dnn_balanced\n",
    "\n",
    "    #set the seeds for reproducibility even though we are not fine-tuning or training and the weights \n",
    "    #for both these models are effectively frozen for our purpose \n",
    "    torch.manual_seed(7)\n",
    "    random.seed(7)\n",
    "    np.random.seed(7)\n",
    "\n",
    "    # Setting PyTorch's required configuration variables for reproducibility.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "\n",
    "    PRE_TRAINED_bert_MODEL = 'bert-base-multilingual-cased'\n",
    "    PRE_TRAINED_xlm_MODEL = 'xlm-mlm-100-1280'\n",
    "\n",
    "    MAXTOKENS = 5\n",
    "    MAXTOKENS_XLM = 9\n",
    "    BS = 8  # batch size\n",
    "\n",
    "    #list of loan-original words for train sets\n",
    "    l1_train_alldata = list(train_alldata[\"loan_word\"])\n",
    "    l2_train_alldata = list(train_alldata[\"original_word\"])\n",
    "\n",
    "    l1_train_realdist = list(train_realdist[\"loan_word\"])\n",
    "    l2_train_realdist = list(train_realdist[\"original_word\"])\n",
    "\n",
    "    l1_train_balanced = list(train_balanced[\"loan_word\"])\n",
    "    l2_train_balanced = list(train_balanced[\"original_word\"])\n",
    "\n",
    "    #list of loan-original words for test sets\n",
    "    l1_test_alldata = list(test_alldata[\"loan_word\"])\n",
    "    l2_test_alldata = list(test_alldata[\"original_word\"])\n",
    "\n",
    "    l1_test_realdist = list(test_realdist[\"loan_word\"])\n",
    "    l2_test_realdist = list(test_realdist[\"original_word\"])\n",
    "\n",
    "    l1_test_balanced = list(test_balanced[\"loan_word\"])\n",
    "    l2_test_balanced = list(test_balanced[\"original_word\"])\n",
    "\n",
    "    print(\"Getting MBERT similarities\")\n",
    "    train_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    test_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    train_realdist['MBERT_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    train_balanced['MBERT_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    test_realdist['MBERT_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    test_balanced['MBERT_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    print()\n",
    "    print(\"Getting XLM similarities\")\n",
    "    train_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    test_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    train_realdist['XLM_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    train_balanced['XLM_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "\n",
    "    test_realdist['XLM_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    test_balanced['XLM_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "        \n",
    "    train_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata.csv')\n",
    "    test_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata.csv')\n",
    "\n",
    "    train_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    test_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c96c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
