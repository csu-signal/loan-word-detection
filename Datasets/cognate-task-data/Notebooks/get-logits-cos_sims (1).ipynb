{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d900aa",
   "metadata": {},
   "source": [
    "Assumes you have run `Train_Testset.ipynb` first to make the `alldata`, `realdist`, and `balanced` train/test splits for the chosen language pair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a3a5e",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091671b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import panphon\n",
    "import panphon.distance\n",
    "import editdistance # levenshtein\n",
    "import epitran\n",
    "import eng_to_ipa as eng\n",
    "from epitran.backoff import Backoff\n",
    "from googletrans import Translator\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "epitran.download.cedict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4977c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "# sys.argv = ['']\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "#from evaluations.eval import *\n",
    "import os\n",
    "import copy\n",
    "import configparser\n",
    "config_model = configparser.ConfigParser()\n",
    "config_model.read('model_parameters.ini')\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed2ae9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import io\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726f5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer specific imports, and cross encoders for our customized transformer models \n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import *\n",
    "from bert_stuff import *\n",
    "from cognate_encoders.cross_encoder_assamese import FullCrossEncoder, FullCrossEncoderSingle, FullCrossEncoderSingle_muril\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup,\\\n",
    "    BertForSequenceClassification, BertForPreTraining, AutoModel\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel, XLMModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, mean_squared_error\n",
    "import time\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b4fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3090\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    \n",
    "#device = torch.device(\"cuda:0:3\" if torch.cuda.is_available() else \"cpu\") ## specify the GPU id's, GPU id's start from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80da282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e42f7",
   "metadata": {},
   "source": [
    "# DNN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e92610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(n_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            \n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        logits_new = self.linear_relu_stack(x)\n",
    "        logits  = self.dropout(logits_new)\n",
    "        \n",
    "        return torch.sigmoid(logits), logits_new\n",
    "    \n",
    "    def fit(self, X_train, Y_train, X_val, Y_val, criterion, optimizer, n_epochs=5000):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accur = []\n",
    "        val_accur = []\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            y_pred, logits = self(X_train.float())\n",
    "\n",
    "            train_loss = criterion(y_pred, Y_train.float())\n",
    "\n",
    "            if epoch % (n_epochs // 50) == 0:\n",
    "                train_acc,_ = self.calculate_accuracy(Y_train, y_pred)\n",
    "\n",
    "                y_val_pred = self(X_val.float())[0]\n",
    "\n",
    "                val_loss = criterion(y_val_pred, Y_val.float())\n",
    "\n",
    "                val_acc, total_corr = self.calculate_accuracy(Y_val, y_val_pred)\n",
    "\n",
    "                print(f'''epoch {epoch}\n",
    "                    Train set - loss: {self.round_tensor(train_loss)}, accuracy: {self.round_tensor(train_acc)} \n",
    "                    Val set - loss: {self.round_tensor(val_loss)}, accuracy: {self.round_tensor(val_acc)}''')\n",
    "                \n",
    "                train_losses.append(train_loss.detach().cpu().numpy())\n",
    "                val_losses.append(val_loss.detach().cpu().numpy())\n",
    "\n",
    "                val_accur.append(val_acc.detach().cpu().numpy())\n",
    "                train_accur.append(train_acc.detach().cpu().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "        return train_losses,val_losses,train_accur,val_accur\n",
    "    \n",
    "    def calculate_accuracy(self, y_true, y_pred):\n",
    "        predicted = y_pred.ge(.5) \n",
    "        return ((y_true == predicted).sum().float() / len(y_true), (y_true == predicted).sum())\n",
    "    \n",
    "    def round_tensor(self, t, decimal_places=3):\n",
    "        return round(t.item(), decimal_places)\n",
    "    \n",
    "    def plot_losses(self, train_losses, val_losses, train_accur, val_accur):\n",
    "        epochs = range(1, len(train_accur) + 1)\n",
    "\n",
    "        plt.plot(epochs, train_accur, 'bo', label='Training acc')\n",
    "        plt.plot(epochs, val_accur, 'b', label='Vaidation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
    "        plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36154569",
   "metadata": {},
   "source": [
    "# MyDataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b14ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overriding the Dataset class required for the use of PyTorch's data loader classes.\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, l1_encodings, l2_encodings):\n",
    "        self.l1_encodings = l1_encodings\n",
    "        self.l2_encodings = l2_encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {('l1_' + key): torch.tensor(val[idx]) for key, val in self.l1_encodings.items()}\n",
    "        item2 = {('l2_' + key): torch.tensor(val[idx]) for key, val in self.l2_encodings.items()}\n",
    "        item.update(item2)\n",
    "        # item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l1_encodings['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a47bf8",
   "metadata": {},
   "source": [
    "# Download LMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b243a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlm_tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "# xlm_model = XLMModel.from_pretrained(\"xlm-mlm-100-1280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9755402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55834b9",
   "metadata": {},
   "source": [
    "# Pipeline function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4051b",
   "metadata": {},
   "source": [
    "## Get Panphon phonetic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4354d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_panphon_features(train_set, test_set):\n",
    "    #get phonetic features using PanPhon\n",
    "    ft = panphon.FeatureTable()   \n",
    "    \n",
    "    train_set['features_loan'] = train_set.apply(lambda x:ft.word_to_vector_list(x[\"loan_word_epitran\"],numeric=True ), axis=1)\n",
    "    train_set['features_orig'] = train_set.apply(lambda x:ft.word_to_vector_list(x[\"original_word_epitran\"],numeric=True ), axis=1)\n",
    "    test_set['features_loan'] = test_set.apply(lambda x:ft.word_to_vector_list(x[\"loan_word_epitran\"],numeric=True ), axis=1)\n",
    "    test_set['features_orig'] = test_set.apply(lambda x:ft.word_to_vector_list(x[\"original_word_epitran\"],numeric=True ), axis=1)\n",
    "\n",
    "    train_set['features_loan'] = train_set['features_loan'].apply(lambda x:sum(x, []))\n",
    "    train_set['features_orig'] = train_set['features_orig'].apply(lambda x:sum(x, []))\n",
    "    test_set['features_orig'] = test_set['features_orig'].apply(lambda x:sum(x, []))\n",
    "    test_set['features_loan'] = test_set['features_loan'].apply(lambda x:sum(x, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413d0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_panphon_features(train_set, test_set, maxlen, verbose=False):\n",
    "    # Pad the phonetic features of the loan word and original word out to the maxlen \n",
    "    # of the features appearing in the training set (format: `<loan><pad 0s><orig><pad 0s>`).\n",
    "    train_set['features_loan'] = train_set['features_loan'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[0]-len(x)), 'constant'))\n",
    "    train_set['features_orig'] = train_set['features_orig'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[1]-len(x)), 'constant'))\n",
    "    test_set['features_loan'] = test_set['features_loan'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[0]-len(x)), 'constant'))\n",
    "    test_set['features_orig'] = test_set['features_orig'].apply(lambda x: \\\n",
    "                                    np.pad(x,\\\n",
    "                                    (0,maxlen[1]-len(x)), 'constant'))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Sample train features:\\n\",\\\n",
    "                train_set['features_loan'][np.random.randint(len(train_set['features_loan']))],\\\n",
    "                train_set['features_orig'][np.random.randint(len(train_set['features_loan']))])\n",
    "\n",
    "        print(\"Sample test features:\\n\",\\\n",
    "                test_set['features_loan'][np.random.randint(len(test_set['features_loan']))],\\\n",
    "                test_set['features_orig'][np.random.randint(len(test_set['features_orig']))])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a031511",
   "metadata": {},
   "source": [
    "## Add target labels and make train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900f4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target_labels(train_set, test_set):\n",
    "    Y_train = np.array([y for y in train_set['label_bin']])\n",
    "    Y_test = np.array([y for y in test_set['label_bin']])\n",
    "    return Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e93f3aa",
   "metadata": {},
   "source": [
    "Make a validation split for training the DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16fd11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_val_set(train_set, test_set, Y_train):\n",
    "    X_train = np.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                np.array([x for x in train_alldata['features_orig']])])\n",
    "    X_test = np.hstack([np.array([x for x in test_alldata['features_loan']]),\\\n",
    "                np.array([x for x in test_alldata['features_orig']])])\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2,\\\n",
    "                                                      random_state=1, stratify=Y_train)\n",
    "    return X_train, X_val, X_test, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee312b",
   "metadata": {},
   "source": [
    "Make tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44851fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "    X_train = torch.tensor(X_train).to(device)\n",
    "    Y_train = torch.tensor(Y_train).to(device).reshape((-1,1))\n",
    "\n",
    "    X_val = torch.tensor(X_val).to(device)\n",
    "    Y_val = torch.tensor(Y_val).to(device).reshape((-1,1))\n",
    "    \n",
    "    X_test = torch.tensor(X_test).to(device)\n",
    "    Y_test = torch.tensor(Y_test).to(device).reshape((-1,1))\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40b267",
   "metadata": {},
   "source": [
    "## Get cosine similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683ed59",
   "metadata": {},
   "source": [
    "MBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c98a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_bert_MODEL = 'bert-base-multilingual-cased'\n",
    "PRE_TRAINED_xlm_MODEL = 'xlm-mlm-100-1280'\n",
    "\n",
    "MAXTOKENS = 5\n",
    "BS = 8\n",
    "all_vec= defaultdict(dict)  #stores the model embeddings  for each combination of models \n",
    "all_mapped = defaultdict(dict) \n",
    "cos_mapped = defaultdict(dict) \n",
    "# stores the linearly transformed model embeddings  for each combination of models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc81408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarities(a,b):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity as row wise dot product of 2 arrays of vectors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    a,b : Two arrays/tensors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "    \"\"\"\n",
    "    def normed(a):\n",
    "        return a/np.linalg.norm(a, axis=1).reshape((-1, 1))\n",
    "     \n",
    "    lhs = a\n",
    "    rhs = b\n",
    " \n",
    "\n",
    "    return np.sum(normed(lhs) * normed(rhs), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48e84130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mbert_cos_sims(l1_data,l2_data):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    with torch.no_grad():\n",
    "        tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_bert_MODEL)\n",
    "        tokenizer.model_max_length = MAXTOKENS\n",
    "        l1_encodings = tokenizer(l1_data, truncation=False, padding=True, max_length=MAXTOKENS)\n",
    "        l2_encodings = tokenizer(l2_data, truncation=False, padding=True, max_length=MAXTOKENS)\n",
    "        \n",
    "        dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "        \n",
    "        data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "        \n",
    "        base_model = BertModel.from_pretrained(PRE_TRAINED_bert_MODEL).to(device)\n",
    "        base_model.eval()\n",
    "        cos_s = torch.nn.CosineSimilarity()\n",
    "        \n",
    "        sim_lst = []\n",
    "#         l1 = base_model(input_ids = l1_encodings['input_ids'],\n",
    "#                                         attention_mask = l1_encodings['attention_mask']).last_hidden_state[:, 0, :]\n",
    "#         l2 = base_model(input_ids = l2_encodings['input_ids'],attention_mask = \n",
    "#                                           l2_encodings['attention_mask']\n",
    "#                                         ).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        #loop through dataset \n",
    "        for step, batch in enumerate(data_loader):\n",
    "            l1_vector = base_model(batch['l1_input_ids'].to(device),\n",
    "                                          attention_mask=batch['l1_attention_mask'].to(device),\n",
    "                                          return_dict=True).last_hidden_state[:, 0, :]\n",
    "            l2_vector = base_model(batch['l2_input_ids'].to(device),\n",
    "                                          attention_mask=batch['l2_attention_mask'].to(device),\n",
    "                                          return_dict=True).last_hidden_state[:, 0, :]\n",
    "            \n",
    "            l1.extend(l1_vector.data.cpu().numpy())\n",
    "            l2.extend(l2_vector.data.cpu().numpy())\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            sims = cos_s(l1_vector, l2_vector).data.cpu().numpy()\n",
    "            sim_lst.extend(list(sims))\n",
    "            if (step * BS) % 100 < BS:\n",
    "                print(\"Got {}\".format(len(sim_lst)))\n",
    "        all_vec['mbert']['loan'] = np.array(l1)\n",
    "        all_vec['mbert']['original'] = np.array(l2)\n",
    "        print()\n",
    "                \n",
    "    return sim_lst, all_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643675a",
   "metadata": {},
   "source": [
    "XLM-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6ecafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xlm_cos_sims(l1_data,l2_data):\n",
    "    with torch.no_grad():\n",
    "        tokenizer = XLMTokenizer.from_pretrained(PRE_TRAINED_xlm_MODEL)\n",
    "        tokenizer.model_max_length = MAXTOKENS \n",
    "        l1_encodings = tokenizer(l1_data, truncation=False, padding=True, max_length=MAXTOKENS, return_tensors=\"pt\", return_special_tokens_mask=True)\n",
    "        l2_encodings = tokenizer(l2_data, truncation=False, padding=True, max_length=MAXTOKENS, return_tensors=\"pt\", return_special_tokens_mask=True)\n",
    "\n",
    "        dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "\n",
    "        data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "\n",
    "        \n",
    "        base_model = XLMModel.from_pretrained(PRE_TRAINED_xlm_MODEL).to(device)\n",
    "        \n",
    "        base_model.eval()\n",
    "        cos_s = torch.nn.CosineSimilarity()\n",
    "        \n",
    "        sim_lst = []\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "\n",
    "        #loop through dataset \n",
    "        for step, batch in enumerate(data_loader):\n",
    "            \n",
    "            l1_vector = base_model(batch['l1_input_ids'].to(device), output_hidden_states=False).last_hidden_state[:, 0, :]\n",
    "            l2_vector = base_model(batch['l2_input_ids'].to(device), output_hidden_states=False).last_hidden_state[:, 0, :]\n",
    "            l1.extend(l1_vector.data.cpu().numpy())\n",
    "            l2.extend(l2_vector.data.cpu().numpy())\n",
    "            sims = cos_s(l1_vector,l2_vector).data.cpu().numpy()\n",
    "            sim_lst.extend(list(sims))\n",
    "            if (step * BS) % 100 < BS:\n",
    "                print(\"Got {}\".format(len(sim_lst)))\n",
    "            \n",
    "        all_vec['xlm']['loan'] = np.array(l1)\n",
    "        all_vec['xlm']['original'] = np.array(l2)\n",
    "        \n",
    "        print()\n",
    "                \n",
    "    return sim_lst , all_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20bcf57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ass_albert_cos_sims(l1_data,l2_data, lin_transform =False):  #only assamese, monolingual, albert \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if lin_transform ==True:\n",
    "                \n",
    "            tokenizer_mbert = BertTokenizer.from_pretrained(PRE_TRAINED_bert_MODEL)\n",
    "            tokenizer_assbert = AutoTokenizer.from_pretrained(config_model['model_ass_bert']['token_path'] )\n",
    "            \n",
    "\n",
    "            #tokenizer.model_max_length = MAXTOKENS \n",
    "            l1_encodings = tokenizer_assbert(l1_data,padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "            l2_encodings = tokenizer_assbert(l2_data, padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "\n",
    "            dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "\n",
    "            data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "\n",
    "\n",
    "            source_model = AutoModel.from_pretrained(config_model['model_ass_bert']['model_name'] ).to(device)\n",
    "            target_model = BertModel.from_pretrained(PRE_TRAINED_bert_MODEL).to(device) #do not use this when working with the transformation matrix\n",
    "             \n",
    "            target_model.eval()\n",
    "            \n",
    "            cos_s = torch.nn.CosineSimilarity()\n",
    "\n",
    "            sim_lst = []\n",
    "            l1_new = []\n",
    "            l2_new = []\n",
    "\n",
    "            #loop through dataset \n",
    "            for step, batch in enumerate(data_loader):\n",
    "\n",
    "                l1_vector = source_model(batch['l1_input_ids'].to(device), output_hidden_states=True).last_hidden_state #albert has only 6 encoder layers\n",
    "                l2_vector = source_model(batch['l2_input_ids'].to(device), output_hidden_states=True).last_hidden_state\n",
    "                l1_new.extend(l1_vector[:, 0, :].data.cpu().numpy() )\n",
    "                l2_new.extend(l2_vector[:, 0, :].data.cpu().numpy() )\n",
    "                \n",
    "                l2_vector = l2_vector.cpu()\n",
    "                \n",
    "                l1  = l1_vector.sum(1).cpu().numpy()\n",
    "                l2  = l2_vector.sum(1).cpu().numpy()\n",
    "                 \n",
    "                #get the linear transform here \n",
    "                \n",
    "                mapper_ = sklearn.linear_model.Ridge(fit_intercept=False).fit(l1,l2) \n",
    "                mapper_ = mapper_.coef_\n",
    "                mapped_= l1 @ mapper_.transpose()\n",
    "                \n",
    "                \n",
    "\n",
    "                #sims = cos_s(l1_vector[:,0,:],l2_vector[:,0,:]).data.cpu().numpy()\n",
    "                sims = cos_s(torch.tensor(mapped_),l2_vector[:,0,:]).data.cpu().numpy()\n",
    "                sim_lst.extend(list(sims))\n",
    "                if (step * BS) % 100 < BS:\n",
    "                    print(\"Got {}\".format(len(sim_lst)))\n",
    "                    \n",
    "                    \n",
    "            all_vec['ass_bert']['loan'] = np.array(l1_new)\n",
    "            all_vec['ass_bert']['original'] = np.array(l2_new)\n",
    "            print()\n",
    "                \n",
    "    return sim_lst, all_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "826239df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Indic_bert_cos_sims(l1_data,l2_data, lin_transform =False ):  #only assamese, monolingual \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert', keep_accents=True)\n",
    "        base_model = AutoModel.from_pretrained('ai4bharat/indic-bert').to(device)\n",
    "        \n",
    "        #tokenizer.model_max_length = MAXTOKENS \n",
    "        l1_encodings = tokenizer(l1_data,padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "        l2_encodings = tokenizer(l2_data, padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "\n",
    "        dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "\n",
    "        data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "\n",
    "        \n",
    "          \n",
    "        \n",
    "        base_model.eval()\n",
    "        cos_s = torch.nn.CosineSimilarity()\n",
    "        \n",
    "        sim_lst = []\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "        if lin_transform ==False:\n",
    "            \n",
    "\n",
    "            #loop through dataset \n",
    "            for step, batch in enumerate(data_loader):\n",
    "\n",
    "                l1_vector = base_model(batch['l1_input_ids'].to(device), output_hidden_states=True).last_hidden_state[:, 0, :]\n",
    "                l2_vector = base_model(batch['l2_input_ids'].to(device), output_hidden_states=True).last_hidden_state[:, 0, :]\n",
    "                l1.extend(l1_vector.data.cpu().numpy())\n",
    "                l2.extend(l2_vector.data.cpu().numpy())\n",
    "                sims = cos_s(l1_vector,l2_vector).data.cpu().numpy()\n",
    "                sim_lst.extend(list(sims))\n",
    "                if (step * BS) % 100 < BS:\n",
    "                    print(\"Got {}\".format(len(sim_lst)))\n",
    "            print()\n",
    "            all_vec['indic_bert']['loan'] = np.array(l1)\n",
    "            all_vec['indic_bert']['original'] = np.array(l2)\n",
    "    \n",
    "            \n",
    "                \n",
    "    return sim_lst, all_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d452029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Muril_cos_sims(l1_data,l2_data):  #only assamese, monolingual \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "\n",
    "        base_model = AutoModelForMaskedLM.from_pretrained(\"google/muril-base-cased\").to(device)\n",
    "        \n",
    "        #tokenizer.model_max_length = MAXTOKENS \n",
    "        l1_encodings = tokenizer(l1_data,padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "        l2_encodings = tokenizer(l2_data, padding='longest', return_tensors=\"pt\", return_special_tokens_mask=True, add_special_tokens=True, truncation =False)\n",
    "\n",
    "        dataset = MyDataset(l1_encodings, l2_encodings)\n",
    "\n",
    "        data_loader = DataLoader(dataset, batch_size=BS, shuffle=False)  # shuffle False for reproducibility\n",
    "\n",
    "        base_model.eval()\n",
    "        cos_s = torch.nn.CosineSimilarity()\n",
    "        \n",
    "        sim_lst = []\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "\n",
    "        #loop through dataset \n",
    "        for step, batch in enumerate(data_loader):\n",
    "            \n",
    "            l1_vector = base_model(batch['l1_input_ids'].to(device), output_hidden_states =True).hidden_states[12][:, 0, :]\n",
    "            l2_vector = base_model(batch['l2_input_ids'].to(device), output_hidden_states =True).hidden_states[12][:, 0, :]\n",
    "            l1.extend(l1_vector.data.cpu().numpy())\n",
    "            l2.extend(l2_vector.data.cpu().numpy())\n",
    "            sims = cos_s(l1_vector,l2_vector).data.cpu().numpy()\n",
    "            sim_lst.extend(list(sims))\n",
    "            if (step * BS) % 100 < BS:\n",
    "                print(\"Got {}\".format(len(sim_lst)))\n",
    "        all_vec['muril']['loan'] = np.array(l1)\n",
    "        all_vec['muril']['original'] = np.array(l2)\n",
    "        print()\n",
    "        \n",
    "                \n",
    "    return sim_lst, all_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58253874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63a3f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias #loading\n",
      "no stored variable or alias the\n",
      "no stored variable or alias transformation\n",
      "no stored variable or alias matrix\n",
      "no stored variable or alias from\n",
      "no stored variable or alias the\n",
      "no stored variable or alias 339\n",
      "no stored variable or alias sample\n",
      "no stored variable or alias equivalent\n",
      "no stored variable or alias sentences\n"
     ]
    }
   ],
   "source": [
    "%store -r beng_m_bertvec #loading the transformation matrix from the 339 sample equivalent sentences \n",
    "%store -r ass_bertvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6b8ea31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((339, 768), (339, 768))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beng_m_bertvec.shape, ass_bertvec.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50474ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ben_ass_train = pd.read_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Bengali-Assamese-train_production_alldata.csv', index_col=False)\n",
    "ben_ass_test = pd.read_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Bengali-Assamese-test_production_alldata.csv', index_col=False)\n",
    "\n",
    "ass_ben_train = pd.read_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Assamese-Bengali-train_production_alldata.csv', index_col=False)\n",
    "ass_ben_test = pd.read_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Assamese-Bengali-test_production_alldata.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5e017b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2280: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/vocab.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/fcfbd016a54060fb3e7290d39ac4fd04b0c7ca2c683e5fdd87928b0feaa2c367.bd20142f530c7b681cef79e2153e77f8d9e8c9fdb3f6db29f37298198166236d\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/merges.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0693c49aba9ba31f442ba9a6c368bc400d2a81e5931d983d63d8648a043bf551.a1730275bc49c3d660f1d9bf50222d8cb849f3ae93e75e5865a3037650459b27\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/91dad0f1b901ee17a1ca86293a46619408e812441cfa380050cd03359564b95f.fabc897dd998cd3c78df5e8469be3194040e8a0f7dd4ee9278748dfcea803743\n",
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"_name_or_path\": \"xlm-mlm-100-1280\",\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/xlm-mlm-100-1280/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/5ba8c43e22aeb247eee7a4d27014eabe361cbfd2a9e00bd337946aaa0dece8ce.f11dc7ef5f30811d164556022e3174da0d6e8bb13676833dabdb1f50f61f39a5\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of XLMModel were initialized from the model checkpoint at xlm-mlm-100-1280.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Didn't find file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer.json. We won't load it.\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/spiece.model\n",
      "loading file None\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/added_tokens.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/special_tokens_map.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer_config.json\n",
      "Adding <pad> to the vocabulary\n",
      "loading configuration file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2\",\n",
      "  \"architectures\": [\n",
      "    \"AlbertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing AlbertModel.\n",
      "\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/spiece.model from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/97e976f62c951292c6fdb2bb5bf1f34f5450585dda98be8dedea2b97e4f25b86.5c8e83e7afe2b2faae1dc1a6b0fcdb911480df6af7079e9df53aa83ed0763de2\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.dense.weight', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at ai4bharat/indic-bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b97fc49fcc6c4b696e73d117cd105e9896633d546afdaa10fbdc2e3964b7ccce.6238bf3b1b7ad31c55bb4415faa9477a5f8e50723e8d1d70df19a65433db277f\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/special_tokens_map.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/290471f6a01c9af0dd0bcf02112dc77b9b0aee820ebb1fb023c96ac2dda9d8ef.750293617705dd39d21eef1e163d80ca5b23e1a0ec507fff24a087c44632142c\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/677de489a9460181a44c530abce89d7d341485a3d49dacc89a9b5a1fed34c328.94e1730f1b81d6fdf365e5e59d01a4e387286e650a02ed6512f3dba8668dd876\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/muril-base-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b4704f25323c21eafa8f1b6196e294d7252e11aa35d082c49d6ae62f3ca168dd.767d38e2461040f361197f7fc27e1968320609d399f194178c3adb49eeeb8ca9\n",
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at google/muril-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get cosine sims for ben_ass_train\n",
    "\n",
    "\n",
    "mbert_cos, all_vec = get_mbert_cos_sims(list(ben_ass_train['loan_word']),list(ben_ass_train['original_word']))\n",
    "xlm_cos,all_vec = get_xlm_cos_sims(list(ben_ass_train['loan_word']),list(ben_ass_train['original_word']))\n",
    "ass_bert_cos, all_vec = get_ass_albert_cos_sims(list(ben_ass_train['original_word']),list(ben_ass_train['loan_word']), lin_transform =True)\n",
    "indic_bert_cos, all_vec = Indic_bert_cos_sims(list(ben_ass_train['loan_word']),list(ben_ass_train['original_word']))\n",
    "muril_cos, all_vec = Muril_cos_sims(list(ben_ass_train['loan_word']),list(ben_ass_train['original_word']))\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea62c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert (1648, 768) (1648, 768) <class 'numpy.ndarray'>\n",
      "xlm (1648, 1280) (1648, 1280) <class 'numpy.ndarray'>\n",
      "ass_bert (1648, 768) (1648, 768) <class 'numpy.ndarray'>\n",
      "indic_bert (1648, 768) (1648, 768) <class 'numpy.ndarray'>\n",
      "muril (1648, 768) (1648, 768) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i, j in all_vec.items():\n",
    "    print(i,j['loan'].shape, j['original'].shape, type(j['original']))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a1d1289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1648, 768), (1648, 768))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vec['ass_bert']['original'].shape,all_vec['mbert']['loan'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7b87751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768)\n"
     ]
    }
   ],
   "source": [
    "# get the linear transformation from mbert space to ass_bert space using the precalculated transformation matrix i.e beng_m_bertvec, ass_bertvec\n",
    "\n",
    "m = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec, ass_bertvec) \n",
    "m = m.coef_ \n",
    "print(m.shape) #this is the 768 by 768 transformation matrix between mbert and assbert \n",
    "mapped_= all_vec['mbert']['loan'] @ m.transpose()\n",
    "beng_ass_cos_mapped = get_cosine_similarities(mapped_, all_vec['ass_bert']['original'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7090fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train production set and add the new cosim column\n",
    "ben_ass_train = pd.read_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Bengali-Assamese-train_production_alldata.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "623e20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_ass_train['mbert_src_assbert_trg'] = beng_ass_cos_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "400eaa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1</th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>loan_word_epitran</th>\n",
       "      <th>original_word_epitran</th>\n",
       "      <th>...</th>\n",
       "      <th>ass_bertmuril</th>\n",
       "      <th>indic_bertmbert</th>\n",
       "      <th>indic_bertxlm</th>\n",
       "      <th>indic_bertass_bert</th>\n",
       "      <th>indic_bertmuril</th>\n",
       "      <th>murilmbert</th>\n",
       "      <th>murilxlm</th>\n",
       "      <th>murilass_bert</th>\n",
       "      <th>murilindic_bert</th>\n",
       "      <th>mbert_src_assbert_trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>পিন্ধা</td>\n",
       "      <td>আঠ</td>\n",
       "      <td>pin̪d̪ʱa</td>\n",
       "      <td>atʰ</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.995502</td>\n",
       "      <td>0.987439</td>\n",
       "      <td>-0.036634</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>0.997388</td>\n",
       "      <td>-0.037025</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.063041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>615</td>\n",
       "      <td>615</td>\n",
       "      <td>পুষ্প</td>\n",
       "      <td>দোস্ত</td>\n",
       "      <td>puʃpɔ</td>\n",
       "      <td>dʊxtɔ</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.993861</td>\n",
       "      <td>-0.037131</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.998016</td>\n",
       "      <td>-0.036950</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>-0.003760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>336</td>\n",
       "      <td>336</td>\n",
       "      <td>জ্ঞান</td>\n",
       "      <td>শেঙুন</td>\n",
       "      <td>d͡ʑnan̪</td>\n",
       "      <td>xɛŋun</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.996036</td>\n",
       "      <td>0.997111</td>\n",
       "      <td>-0.037456</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.997383</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>-0.036918</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.129613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>কালি</td>\n",
       "      <td>কালি</td>\n",
       "      <td>kali</td>\n",
       "      <td>kali</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.997840</td>\n",
       "      <td>0.997473</td>\n",
       "      <td>-0.036673</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.998332</td>\n",
       "      <td>-0.037079</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.032470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>ছবি</td>\n",
       "      <td>ঠেং</td>\n",
       "      <td>t͡ɕʰɔbi</td>\n",
       "      <td>tʰɛŋ</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.993710</td>\n",
       "      <td>0.992030</td>\n",
       "      <td>-0.037115</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.998208</td>\n",
       "      <td>0.998024</td>\n",
       "      <td>-0.037072</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.012763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>1643</td>\n",
       "      <td>1643</td>\n",
       "      <td>1643</td>\n",
       "      <td>1643</td>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "      <td>হার্ট</td>\n",
       "      <td>হিয়া</td>\n",
       "      <td>ɦarʈɔ</td>\n",
       "      <td>ɦija</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.992731</td>\n",
       "      <td>0.987405</td>\n",
       "      <td>-0.037828</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.997372</td>\n",
       "      <td>0.998031</td>\n",
       "      <td>-0.037065</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>-0.060017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>1644</td>\n",
       "      <td>1644</td>\n",
       "      <td>1644</td>\n",
       "      <td>1644</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>পুষ্প</td>\n",
       "      <td>পাউণ্ড</td>\n",
       "      <td>puʃpɔ</td>\n",
       "      <td>paundɔ</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.997582</td>\n",
       "      <td>0.998046</td>\n",
       "      <td>-0.036369</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.998415</td>\n",
       "      <td>0.998395</td>\n",
       "      <td>-0.037102</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>-0.003760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>1645</td>\n",
       "      <td>1645</td>\n",
       "      <td>1645</td>\n",
       "      <td>1645</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>কলা</td>\n",
       "      <td>ককা</td>\n",
       "      <td>kɔla</td>\n",
       "      <td>kɔka</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.992143</td>\n",
       "      <td>0.981005</td>\n",
       "      <td>-0.037294</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.997453</td>\n",
       "      <td>0.997853</td>\n",
       "      <td>-0.037073</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.049187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>1646</td>\n",
       "      <td>1646</td>\n",
       "      <td>1646</td>\n",
       "      <td>1646</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>দিন</td>\n",
       "      <td>ডিম</td>\n",
       "      <td>d̪in̪</td>\n",
       "      <td>dim</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.997719</td>\n",
       "      <td>0.994965</td>\n",
       "      <td>-0.037080</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.998300</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>-0.037104</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.051215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>1647</td>\n",
       "      <td>1647</td>\n",
       "      <td>1647</td>\n",
       "      <td>1647</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>কিতাব</td>\n",
       "      <td>পুথি</td>\n",
       "      <td>kit̪ab</td>\n",
       "      <td>putʰi</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.996928</td>\n",
       "      <td>0.996682</td>\n",
       "      <td>-0.036917</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.998358</td>\n",
       "      <td>0.998365</td>\n",
       "      <td>-0.037068</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.015616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1648 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0              0             0               0                 0   \n",
       "1              1             1               1                 1   \n",
       "2              2             2               2                 2   \n",
       "3              3             3               3                 3   \n",
       "4              4             4               4                 4   \n",
       "...          ...           ...             ...               ...   \n",
       "1643        1643          1643            1643              1643   \n",
       "1644        1644          1644            1644              1644   \n",
       "1645        1645          1645            1645              1645   \n",
       "1646        1646          1646            1646              1646   \n",
       "1647        1647          1647            1647              1647   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1 loan_word original_word  \\\n",
       "0                    180                   180    পিন্ধা            আঠ   \n",
       "1                    615                   615     পুষ্প         দোস্ত   \n",
       "2                    336                   336     জ্ঞান         শেঙুন   \n",
       "3                     47                    47      কালি          কালি   \n",
       "4                    105                   105       ছবি           ঠেং   \n",
       "...                  ...                   ...       ...           ...   \n",
       "1643                 348                   348     হার্ট         হিয়া   \n",
       "1644                 136                   136     পুষ্প        পাউণ্ড   \n",
       "1645                  37                    37       কলা           ককা   \n",
       "1646                 589                   589       দিন           ডিম   \n",
       "1647                 195                   195     কিতাব          পুথি   \n",
       "\n",
       "     loan_word_epitran original_word_epitran  ... ass_bertmuril  \\\n",
       "0             pin̪d̪ʱa                   atʰ  ...      0.999895   \n",
       "1                puʃpɔ                 dʊxtɔ  ...      0.999765   \n",
       "2              d͡ʑnan̪                 xɛŋun  ...      0.999856   \n",
       "3                 kali                  kali  ...      0.999915   \n",
       "4              t͡ɕʰɔbi                  tʰɛŋ  ...      0.999907   \n",
       "...                ...                   ...  ...           ...   \n",
       "1643             ɦarʈɔ                  ɦija  ...      0.999483   \n",
       "1644             puʃpɔ                paundɔ  ...      0.999741   \n",
       "1645              kɔla                  kɔka  ...      0.999899   \n",
       "1646             d̪in̪                   dim  ...      0.999900   \n",
       "1647            kit̪ab                 putʰi  ...      0.999924   \n",
       "\n",
       "     indic_bertmbert  indic_bertxlm  indic_bertass_bert  indic_bertmuril  \\\n",
       "0           0.995502       0.987439           -0.036634         0.999794   \n",
       "1           0.995714       0.993861           -0.037131         0.999983   \n",
       "2           0.996036       0.997111           -0.037456         0.999987   \n",
       "3           0.997840       0.997473           -0.036673         0.999995   \n",
       "4           0.993710       0.992030           -0.037115         0.999976   \n",
       "...              ...            ...                 ...              ...   \n",
       "1643        0.992731       0.987405           -0.037828         0.999939   \n",
       "1644        0.997582       0.998046           -0.036369         0.999993   \n",
       "1645        0.992143       0.981005           -0.037294         0.999865   \n",
       "1646        0.997719       0.994965           -0.037080         0.999971   \n",
       "1647        0.996928       0.996682           -0.036917         0.999988   \n",
       "\n",
       "      murilmbert  murilxlm  murilass_bert  murilindic_bert  \\\n",
       "0       0.998521  0.997388      -0.037025         0.999968   \n",
       "1       0.997182  0.998016      -0.036950         0.999891   \n",
       "2       0.997383  0.997570      -0.036918         0.999913   \n",
       "3       0.998325  0.998332      -0.037079         0.999947   \n",
       "4       0.998208  0.998024      -0.037072         0.999954   \n",
       "...          ...       ...            ...              ...   \n",
       "1643    0.997372  0.998031      -0.037065         0.999911   \n",
       "1644    0.998415  0.998395      -0.037102         0.999950   \n",
       "1645    0.997453  0.997853      -0.037073         0.999909   \n",
       "1646    0.998300  0.998274      -0.037104         0.999951   \n",
       "1647    0.998358  0.998365      -0.037068         0.999950   \n",
       "\n",
       "     mbert_src_assbert_trg  \n",
       "0                 0.063041  \n",
       "1                -0.003760  \n",
       "2                 0.129613  \n",
       "3                 0.032470  \n",
       "4                 0.012763  \n",
       "...                    ...  \n",
       "1643             -0.060017  \n",
       "1644             -0.003760  \n",
       "1645              0.049187  \n",
       "1646              0.051215  \n",
       "1647              0.015616  \n",
       "\n",
       "[1648 rows x 50 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_ass_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5780dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lt_maps(all_vec):\n",
    "    #this function is for getting linear maps without using the transformation matrix from 339 sentences \n",
    "    \n",
    "  \n",
    "    \n",
    "    for i, j in all_vec.items():\n",
    "        #print(i,len(j['loan']) )\n",
    "\n",
    "\n",
    "        for m,n in all_vec.items():\n",
    "            if i ==m:\n",
    "                continue\n",
    "\n",
    "\n",
    "            print(i,m)\n",
    "          \n",
    "\n",
    "           #get linear maps for loans and originals separately    \n",
    "\n",
    "            mapper_loan = sklearn.linear_model.Ridge(fit_intercept=False).fit(j['loan'],n['loan']) \n",
    "            #mapper_loan = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec,ass_bertvec) \n",
    "            mapper_loan = mapper_loan.coef_\n",
    "            mapped_loan= j['loan'] @ mapper_loan.transpose()\n",
    "            all_mapped[i+m]['loan']  = mapped_loan\n",
    "\n",
    "            mapper_orig = sklearn.linear_model.Ridge(fit_intercept=False).fit(j['original'],n['original']) \n",
    "            #mapper_orig = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec,ass_bertvec) \n",
    "            mapper_orig = mapper_orig.coef_\n",
    "            mapped_orig= j['original'] @ mapper_orig.transpose()\n",
    "            all_mapped[i+m]['original']  = mapped_orig\n",
    "\n",
    "            cos_mapped[i+m] = get_cosine_similarities(mapped_loan, mapped_orig ) #get the cosine sims for mapped embeddings\n",
    "    return cos_mapped\n",
    "\n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc2428a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbertxlm [0.6520988  0.88991714 0.71950054 ... 0.5739207  0.68108535 0.84755015]\n",
      "mbertass_bert [-0.04072228 -0.03144859 -0.03459077 ... -0.03657508 -0.040287\n",
      " -0.03287696]\n",
      "mbertindic_bert [0.9978991  0.99957275 0.9991308  ... 0.9979694  0.9989909  0.99966216]\n",
      "mbertmuril [0.99839866 0.9986011  0.99890715 ... 0.9994731  0.999819   0.99949217]\n",
      "xlmmbert [0.85940564 0.8999516  0.80412424 ... 0.90755445 0.8564594  0.9402543 ]\n",
      "xlmass_bert [-0.04139591 -0.01836748 -0.03869876 ... -0.04617794 -0.04134841\n",
      " -0.03475533]\n",
      "xlmindic_bert [0.99683017 0.99924695 0.9993081  ... 0.9966495  0.9988537  0.9997119 ]\n",
      "xlmmuril [0.9977406  0.9966437  0.99824786 ... 0.99884045 0.99976546 0.9997694 ]\n",
      "ass_bertmbert [0.9877634  0.9778743  0.9747802  ... 0.982127   0.98322934 0.9801762 ]\n",
      "ass_bertxlm [0.95709693 0.95912945 0.95943815 ... 0.969867   0.9682539  0.96623474]\n",
      "ass_bertindic_bert [0.99980676 0.9999196  0.99984217 ... 0.99959093 0.999913   0.9999382 ]\n",
      "ass_bertmuril [0.9998949  0.9997655  0.9998558  ... 0.99989915 0.99990046 0.9999244 ]\n",
      "indic_bertmbert [0.9955022  0.99571407 0.99603605 ... 0.99214256 0.9977193  0.9969278 ]\n",
      "indic_bertxlm [0.987439   0.9938611  0.99711144 ... 0.9810046  0.99496514 0.9966817 ]\n",
      "indic_bertass_bert [-0.03663442 -0.03713082 -0.03745616 ... -0.03729449 -0.03708001\n",
      " -0.03691736]\n",
      "indic_bertmuril [0.9997935  0.9999833  0.9999873  ... 0.9998646  0.99997056 0.9999877 ]\n",
      "murilmbert [0.9985212  0.99718237 0.99738324 ... 0.99745274 0.9982999  0.9983579 ]\n",
      "murilxlm [0.99738777 0.9980155  0.99757016 ... 0.9978533  0.99827445 0.9983646 ]\n",
      "murilass_bert [-0.03702481 -0.0369499  -0.03691846 ... -0.03707321 -0.03710388\n",
      " -0.03706779]\n",
      "murilindic_bert [0.9999684  0.99989086 0.99991256 ... 0.99990946 0.99995065 0.9999495 ]\n"
     ]
    }
   ],
   "source": [
    "cos_mapped = get_lt_maps(all_vec)\n",
    "for i, j  in cos_mapped.items():\n",
    "    print(i,j)\n",
    "    \n",
    "    ben_ass_train[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5eae6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1',\n",
       "       'Unnamed: 0.1.1.1.1', 'Unnamed: 0.1.1.1.1.1', 'loan_word',\n",
       "       'original_word', 'loan_word_epitran', 'original_word_epitran',\n",
       "       'loan_english', 'original_english',\n",
       "       'Fast Levenshtein Distance Div Maxlen',\n",
       "       'Dolgo Prime Distance Div Maxlen', 'Feature Edit Distance Div Maxlen',\n",
       "       'Hamming Feature Distance Div Maxlen',\n",
       "       'Weighted Feature Distance Div Maxlen',\n",
       "       'Partial Hamming Feature Distance Div Maxlen', 'plain Levenshtein',\n",
       "       'loan_unicode', 'original_unicode', 'label', 'label_bin', 'DNN_logits',\n",
       "       'mbert_cos', 'xlm_cos', 'ass_bert_mbert_cos', 'indic_bert_cos',\n",
       "       'muril_cos', 'mbertxlm', 'mbertass_bert', 'mbertindic_bert',\n",
       "       'mbertmuril', 'xlmmbert', 'xlmass_bert', 'xlmindic_bert', 'xlmmuril',\n",
       "       'ass_bertmbert', 'ass_bertxlm', 'ass_bertindic_bert', 'ass_bertmuril',\n",
       "       'indic_bertmbert', 'indic_bertxlm', 'indic_bertass_bert',\n",
       "       'indic_bertmuril', 'murilmbert', 'murilxlm', 'murilass_bert',\n",
       "       'murilindic_bert', 'mbert_src_assbert_trg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_ass_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60a96845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mbertass_bert</th>\n",
       "      <th>xlmass_bert</th>\n",
       "      <th>ass_bertxlm</th>\n",
       "      <th>ass_bertmbert</th>\n",
       "      <th>ass_bertindic_bert</th>\n",
       "      <th>ass_bertmuril</th>\n",
       "      <th>indic_bert_cos</th>\n",
       "      <th>ass_bert_mbert_cos</th>\n",
       "      <th>mbert_cos</th>\n",
       "      <th>xlm_cos</th>\n",
       "      <th>muril_cos</th>\n",
       "      <th>indic_bert_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.040722</td>\n",
       "      <td>-0.041396</td>\n",
       "      <td>0.957097</td>\n",
       "      <td>0.987763</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.996818</td>\n",
       "      <td>0.437369</td>\n",
       "      <td>0.859162</td>\n",
       "      <td>0.619778</td>\n",
       "      <td>0.997738</td>\n",
       "      <td>0.996818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.031449</td>\n",
       "      <td>-0.018367</td>\n",
       "      <td>0.959129</td>\n",
       "      <td>0.977874</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>0.999240</td>\n",
       "      <td>0.399135</td>\n",
       "      <td>0.899460</td>\n",
       "      <td>0.880066</td>\n",
       "      <td>0.996626</td>\n",
       "      <td>0.999240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.034591</td>\n",
       "      <td>-0.038699</td>\n",
       "      <td>0.959438</td>\n",
       "      <td>0.974780</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.999310</td>\n",
       "      <td>0.527592</td>\n",
       "      <td>0.803146</td>\n",
       "      <td>0.689375</td>\n",
       "      <td>0.998220</td>\n",
       "      <td>0.999310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040505</td>\n",
       "      <td>-0.039202</td>\n",
       "      <td>0.976788</td>\n",
       "      <td>0.986098</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.456332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.036145</td>\n",
       "      <td>-0.035271</td>\n",
       "      <td>0.962915</td>\n",
       "      <td>0.976585</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.320201</td>\n",
       "      <td>0.787768</td>\n",
       "      <td>0.661757</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>0.999882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>-0.041362</td>\n",
       "      <td>-0.040279</td>\n",
       "      <td>0.907283</td>\n",
       "      <td>0.969478</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.998596</td>\n",
       "      <td>0.636795</td>\n",
       "      <td>0.835814</td>\n",
       "      <td>0.682145</td>\n",
       "      <td>0.998156</td>\n",
       "      <td>0.998596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>-0.032763</td>\n",
       "      <td>-0.011251</td>\n",
       "      <td>0.961271</td>\n",
       "      <td>0.980109</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.999694</td>\n",
       "      <td>0.399142</td>\n",
       "      <td>0.945338</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>0.999694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>-0.036575</td>\n",
       "      <td>-0.046178</td>\n",
       "      <td>0.969867</td>\n",
       "      <td>0.982127</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.996649</td>\n",
       "      <td>0.494424</td>\n",
       "      <td>0.907485</td>\n",
       "      <td>0.485389</td>\n",
       "      <td>0.998837</td>\n",
       "      <td>0.996649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>-0.040287</td>\n",
       "      <td>-0.041348</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.983229</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.998854</td>\n",
       "      <td>0.551089</td>\n",
       "      <td>0.856364</td>\n",
       "      <td>0.629492</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.998854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>-0.032877</td>\n",
       "      <td>-0.034755</td>\n",
       "      <td>0.966235</td>\n",
       "      <td>0.980176</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>0.471480</td>\n",
       "      <td>0.940100</td>\n",
       "      <td>0.769101</td>\n",
       "      <td>0.999769</td>\n",
       "      <td>0.999709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1648 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mbertass_bert  xlmass_bert  ass_bertxlm  ass_bertmbert  \\\n",
       "0         -0.040722    -0.041396     0.957097       0.987763   \n",
       "1         -0.031449    -0.018367     0.959129       0.977874   \n",
       "2         -0.034591    -0.038699     0.959438       0.974780   \n",
       "3         -0.040505    -0.039202     0.976788       0.986098   \n",
       "4         -0.036145    -0.035271     0.962915       0.976585   \n",
       "...             ...          ...          ...            ...   \n",
       "1643      -0.041362    -0.040279     0.907283       0.969478   \n",
       "1644      -0.032763    -0.011251     0.961271       0.980109   \n",
       "1645      -0.036575    -0.046178     0.969867       0.982127   \n",
       "1646      -0.040287    -0.041348     0.968254       0.983229   \n",
       "1647      -0.032877    -0.034755     0.966235       0.980176   \n",
       "\n",
       "      ass_bertindic_bert  ass_bertmuril  indic_bert_cos  ass_bert_mbert_cos  \\\n",
       "0               0.999807       0.999895        0.996818            0.437369   \n",
       "1               0.999920       0.999766        0.999240            0.399135   \n",
       "2               0.999842       0.999856        0.999310            0.527592   \n",
       "3               0.999668       0.999915        0.999681            0.456332   \n",
       "4               0.999851       0.999907        0.999882            0.320201   \n",
       "...                  ...            ...             ...                 ...   \n",
       "1643            0.998929       0.999483        0.998596            0.636795   \n",
       "1644            0.999886       0.999741        0.999694            0.399142   \n",
       "1645            0.999591       0.999899        0.996649            0.494424   \n",
       "1646            0.999913       0.999900        0.998854            0.551089   \n",
       "1647            0.999938       0.999924        0.999709            0.471480   \n",
       "\n",
       "      mbert_cos   xlm_cos  muril_cos  indic_bert_cos  \n",
       "0      0.859162  0.619778   0.997738        0.996818  \n",
       "1      0.899460  0.880066   0.996626        0.999240  \n",
       "2      0.803146  0.689375   0.998220        0.999310  \n",
       "3      1.000000  1.000000   1.000000        0.999681  \n",
       "4      0.787768  0.661757   0.999328        0.999882  \n",
       "...         ...       ...        ...             ...  \n",
       "1643   0.835814  0.682145   0.998156        0.998596  \n",
       "1644   0.945338  0.737297   0.999730        0.999694  \n",
       "1645   0.907485  0.485389   0.998837        0.996649  \n",
       "1646   0.856364  0.629492   0.999765        0.998854  \n",
       "1647   0.940100  0.769101   0.999769        0.999709  \n",
       "\n",
       "[1648 rows x 12 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_ass_train.loc[:,['mbertass_bert', 'xlmass_bert', 'ass_bertxlm', 'ass_bertmbert', 'ass_bertindic_bert','ass_bertmuril' ,'indic_bert_cos', 'ass_bert_mbert_cos','mbert_cos', 'xlm_cos', 'muril_cos', 'indic_bert_cos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cb9d993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1648, 1648, 1648, 1648, 1648)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mbert_cos ), len(xlm_cos), len(ass_bert_cos), len(indic_bert_cos), len(muril_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2274589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_ass_train['mbert_cos'] = mbert_cos\n",
    "ben_ass_train['xlm_cos'] = xlm_cos\n",
    "ben_ass_train['ass_bert_mbert_cos'] = ass_bert_cos\n",
    "ben_ass_train['indic_bert_cos'] = indic_bert_cos\n",
    "ben_ass_train['muril_cos'] = muril_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d408044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2280: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/vocab.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/fcfbd016a54060fb3e7290d39ac4fd04b0c7ca2c683e5fdd87928b0feaa2c367.bd20142f530c7b681cef79e2153e77f8d9e8c9fdb3f6db29f37298198166236d\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/merges.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0693c49aba9ba31f442ba9a6c368bc400d2a81e5931d983d63d8648a043bf551.a1730275bc49c3d660f1d9bf50222d8cb849f3ae93e75e5865a3037650459b27\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/91dad0f1b901ee17a1ca86293a46619408e812441cfa380050cd03359564b95f.fabc897dd998cd3c78df5e8469be3194040e8a0f7dd4ee9278748dfcea803743\n",
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"_name_or_path\": \"xlm-mlm-100-1280\",\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/xlm-mlm-100-1280/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/5ba8c43e22aeb247eee7a4d27014eabe361cbfd2a9e00bd337946aaa0dece8ce.f11dc7ef5f30811d164556022e3174da0d6e8bb13676833dabdb1f50f61f39a5\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of XLMModel were initialized from the model checkpoint at xlm-mlm-100-1280.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Didn't find file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer.json. We won't load it.\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/spiece.model\n",
      "loading file None\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/added_tokens.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/special_tokens_map.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer_config.json\n",
      "Adding <pad> to the vocabulary\n",
      "loading configuration file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2\",\n",
      "  \"architectures\": [\n",
      "    \"AlbertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing AlbertModel.\n",
      "\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/spiece.model from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/97e976f62c951292c6fdb2bb5bf1f34f5450585dda98be8dedea2b97e4f25b86.5c8e83e7afe2b2faae1dc1a6b0fcdb911480df6af7079e9df53aa83ed0763de2\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.dense.weight', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at ai4bharat/indic-bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b97fc49fcc6c4b696e73d117cd105e9896633d546afdaa10fbdc2e3964b7ccce.6238bf3b1b7ad31c55bb4415faa9477a5f8e50723e8d1d70df19a65433db277f\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/special_tokens_map.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/290471f6a01c9af0dd0bcf02112dc77b9b0aee820ebb1fb023c96ac2dda9d8ef.750293617705dd39d21eef1e163d80ca5b23e1a0ec507fff24a087c44632142c\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/677de489a9460181a44c530abce89d7d341485a3d49dacc89a9b5a1fed34c328.94e1730f1b81d6fdf365e5e59d01a4e387286e650a02ed6512f3dba8668dd876\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/muril-base-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b4704f25323c21eafa8f1b6196e294d7252e11aa35d082c49d6ae62f3ca168dd.767d38e2461040f361197f7fc27e1968320609d399f194178c3adb49eeeb8ca9\n",
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at google/muril-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "Got 1712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now get the cosin sims and embeddings for ass_ben_train\n",
    "\n",
    "mbert_cos, all_vec = get_mbert_cos_sims(list(ass_ben_train['loan_word']),list(ass_ben_train['original_word']))\n",
    "xlm_cos, all_vec = get_xlm_cos_sims(list(ass_ben_train['loan_word']),list(ass_ben_train['original_word']))\n",
    "ass_bert_cos, all_vec = get_ass_albert_cos_sims(list(ass_ben_train['loan_word']),list(ass_ben_train['original_word']), lin_transform =True)\n",
    "indic_bert_cos, all_vec = Indic_bert_cos_sims(list(ass_ben_train['loan_word']),list(ass_ben_train['original_word']))\n",
    "muril_cos, all_vec = Muril_cos_sims(list(ass_ben_train['loan_word']),list(ass_ben_train['original_word']))\n",
    " \n",
    "# ass_ben_train['mbert_cos'] = mbert_cos\n",
    "# ass_ben_train['xlm_cos'] = xlm_cos\n",
    "# ass_ben_train['ass_bert_mbert_cos'] = ass_bert_cos\n",
    "# ass_ben_train['indic_bert_cos'] = indic_bert_cos\n",
    "# ass_ben_train['muril_cos'] = muril_cos   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf18ddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert (1715, 768) (1715, 768) <class 'numpy.ndarray'>\n",
      "xlm (1715, 1280) (1715, 1280) <class 'numpy.ndarray'>\n",
      "ass_bert (1715, 768) (1715, 768) <class 'numpy.ndarray'>\n",
      "indic_bert (1715, 768) (1715, 768) <class 'numpy.ndarray'>\n",
      "muril (1715, 768) (1715, 768) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i, j in all_vec.items():\n",
    "    print(i,j['loan'].shape, j['original'].shape, type(j['original']))\n",
    "# all_vec['mbert']['loan'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1acade4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ce514f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768)\n"
     ]
    }
   ],
   "source": [
    "# get the linear transformation from mbert space to ass_bert space using the precalculated transformation matrix i.e beng_m_bertvec, ass_bertvec\n",
    "#for ass_ben_train\n",
    "m = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec, ass_bertvec) \n",
    "m = m.coef_ \n",
    "print(m.shape) #this is the 768 by 768 transformation matrix between mbert and assbert \n",
    "mapped_= all_vec['mbert']['loan'] @ m.transpose()\n",
    "ass_beng_cos_mapped = get_cosine_similarities(mapped_, all_vec['ass_bert']['original'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc5b6c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>loan_word_epitran</th>\n",
       "      <th>original_word_epitran</th>\n",
       "      <th>loan_english</th>\n",
       "      <th>...</th>\n",
       "      <th>ass_bertmuril</th>\n",
       "      <th>indic_bertmbert</th>\n",
       "      <th>indic_bertxlm</th>\n",
       "      <th>indic_bertass_bert</th>\n",
       "      <th>indic_bertmuril</th>\n",
       "      <th>murilmbert</th>\n",
       "      <th>murilxlm</th>\n",
       "      <th>murilass_bert</th>\n",
       "      <th>murilindic_bert</th>\n",
       "      <th>mbert_src_assbert_trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>568</td>\n",
       "      <td>568</td>\n",
       "      <td>ক্ৰিয়া</td>\n",
       "      <td>গাঁইয়া</td>\n",
       "      <td>kɹija</td>\n",
       "      <td>ɡãie̯a</td>\n",
       "      <td>Action</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999289</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>0.995359</td>\n",
       "      <td>-0.036194</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.998514</td>\n",
       "      <td>0.997798</td>\n",
       "      <td>-0.037001</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>-0.010115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>চান্দ</td>\n",
       "      <td>চন্দ্র</td>\n",
       "      <td>sandɔ</td>\n",
       "      <td>t͡ɕɔn̪d̪rɔ</td>\n",
       "      <td>Chand</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999310</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>-0.036599</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.997993</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>-0.037443</td>\n",
       "      <td>0.999867</td>\n",
       "      <td>0.080588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>818</td>\n",
       "      <td>818</td>\n",
       "      <td>পখিলা</td>\n",
       "      <td>বকুল</td>\n",
       "      <td>pɔkʰila</td>\n",
       "      <td>bɔkulɔ</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999154</td>\n",
       "      <td>0.994700</td>\n",
       "      <td>0.990668</td>\n",
       "      <td>-0.037378</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>0.998522</td>\n",
       "      <td>-0.037572</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>0.003350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "      <td>ৰঙা</td>\n",
       "      <td>বাঘ</td>\n",
       "      <td>ɹɔŋa</td>\n",
       "      <td>bagʱɔ</td>\n",
       "      <td>red</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>0.997704</td>\n",
       "      <td>0.995973</td>\n",
       "      <td>-0.037347</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.998912</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>-0.037650</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.066199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>665</td>\n",
       "      <td>665</td>\n",
       "      <td>বিলৈ</td>\n",
       "      <td>পালং</td>\n",
       "      <td>bilɔɪ</td>\n",
       "      <td>palɔŋ</td>\n",
       "      <td>to the b</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.997192</td>\n",
       "      <td>0.992324</td>\n",
       "      <td>-0.037832</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.998419</td>\n",
       "      <td>0.998129</td>\n",
       "      <td>-0.037200</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.054813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>1710</td>\n",
       "      <td>1710</td>\n",
       "      <td>1710</td>\n",
       "      <td>269</td>\n",
       "      <td>269</td>\n",
       "      <td>অগ্নি</td>\n",
       "      <td>আনা</td>\n",
       "      <td>ɔgni</td>\n",
       "      <td>an̪a</td>\n",
       "      <td>Fire</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999530</td>\n",
       "      <td>0.997056</td>\n",
       "      <td>0.995438</td>\n",
       "      <td>-0.037099</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.998927</td>\n",
       "      <td>0.998485</td>\n",
       "      <td>-0.037632</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.020783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>1711</td>\n",
       "      <td>1711</td>\n",
       "      <td>1711</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>ঠেং</td>\n",
       "      <td>পয়সা</td>\n",
       "      <td>tʰɛŋ</td>\n",
       "      <td>pe̯ɔʃa</td>\n",
       "      <td>The tail</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998865</td>\n",
       "      <td>0.996444</td>\n",
       "      <td>0.995111</td>\n",
       "      <td>-0.037162</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>-0.037122</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.032935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>1712</td>\n",
       "      <td>1712</td>\n",
       "      <td>1712</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>কেন্দ্ৰ</td>\n",
       "      <td>আখন্দ</td>\n",
       "      <td>kɛndɹɔ</td>\n",
       "      <td>akʰɔn̪d̪ɔ</td>\n",
       "      <td>hub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.998104</td>\n",
       "      <td>0.995225</td>\n",
       "      <td>-0.036582</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>0.997997</td>\n",
       "      <td>-0.037136</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>-0.064774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>1713</td>\n",
       "      <td>1713</td>\n",
       "      <td>1713</td>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "      <td>কাণ</td>\n",
       "      <td>খান</td>\n",
       "      <td>kan</td>\n",
       "      <td>kʰan̪</td>\n",
       "      <td>ear</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.997004</td>\n",
       "      <td>0.992971</td>\n",
       "      <td>-0.037427</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.998260</td>\n",
       "      <td>-0.037465</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.020544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>1714</td>\n",
       "      <td>1714</td>\n",
       "      <td>1714</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>গেলা</td>\n",
       "      <td>বায়ু</td>\n",
       "      <td>gɛla</td>\n",
       "      <td>bae̯u</td>\n",
       "      <td>Swallow</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.990788</td>\n",
       "      <td>0.982646</td>\n",
       "      <td>-0.036785</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.998217</td>\n",
       "      <td>0.998046</td>\n",
       "      <td>-0.037464</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.077583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1715 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0              0             0               0               568   \n",
       "1              1             1               1               119   \n",
       "2              2             2               2               818   \n",
       "3              3             3               3               277   \n",
       "4              4             4               4               665   \n",
       "...          ...           ...             ...               ...   \n",
       "1710        1710          1710            1710               269   \n",
       "1711        1711          1711            1711               153   \n",
       "1712        1712          1712            1712                48   \n",
       "1713        1713          1713            1713               790   \n",
       "1714        1714          1714            1714                76   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1 loan_word original_word loan_word_epitran  \\\n",
       "0                    568   ক্ৰিয়া       গাঁইয়া             kɹija   \n",
       "1                    119     চান্দ        চন্দ্র             sandɔ   \n",
       "2                    818     পখিলা          বকুল           pɔkʰila   \n",
       "3                    277       ৰঙা           বাঘ              ɹɔŋa   \n",
       "4                    665      বিলৈ          পালং             bilɔɪ   \n",
       "...                  ...       ...           ...               ...   \n",
       "1710                 269     অগ্নি           আনা              ɔgni   \n",
       "1711                 153       ঠেং         পয়সা              tʰɛŋ   \n",
       "1712                  48   কেন্দ্ৰ         আখন্দ            kɛndɹɔ   \n",
       "1713                 790       কাণ           খান               kan   \n",
       "1714                  76      গেলা         বায়ু              gɛla   \n",
       "\n",
       "     original_word_epitran loan_english  ... ass_bertmuril  indic_bertmbert  \\\n",
       "0                   ɡãie̯a       Action  ...      0.999289         0.997465   \n",
       "1               t͡ɕɔn̪d̪rɔ        Chand  ...      0.999310         0.998168   \n",
       "2                   bɔkulɔ    butterfly  ...      0.999154         0.994700   \n",
       "3                    bagʱɔ          red  ...      0.999649         0.997704   \n",
       "4                    palɔŋ     to the b  ...      0.999687         0.997192   \n",
       "...                    ...          ...  ...           ...              ...   \n",
       "1710                  an̪a         Fire  ...      0.999530         0.997056   \n",
       "1711                pe̯ɔʃa     The tail  ...      0.998865         0.996444   \n",
       "1712             akʰɔn̪d̪ɔ          hub  ...      0.999608         0.998104   \n",
       "1713                 kʰan̪          ear  ...      0.999526         0.997004   \n",
       "1714                 bae̯u      Swallow  ...      0.999689         0.990788   \n",
       "\n",
       "      indic_bertxlm  indic_bertass_bert  indic_bertmuril  murilmbert  \\\n",
       "0          0.995359           -0.036194         0.999959    0.998514   \n",
       "1          0.997567           -0.036599         0.999959    0.997993   \n",
       "2          0.990668           -0.037378         0.999927    0.998900   \n",
       "3          0.995973           -0.037347         0.999954    0.998912   \n",
       "4          0.992324           -0.037832         0.999953    0.998419   \n",
       "...             ...                 ...              ...         ...   \n",
       "1710       0.995438           -0.037099         0.999946    0.998927   \n",
       "1711       0.995111           -0.037162         0.999935    0.998588   \n",
       "1712       0.995225           -0.036582         0.999951    0.998639   \n",
       "1713       0.992971           -0.037427         0.999954    0.998824   \n",
       "1714       0.982646           -0.036785         0.999650    0.998217   \n",
       "\n",
       "      murilxlm  murilass_bert murilindic_bert mbert_src_assbert_trg  \n",
       "0     0.997798      -0.037001        0.999945             -0.010115  \n",
       "1     0.997674      -0.037443        0.999867              0.080588  \n",
       "2     0.998522      -0.037572        0.999914              0.003350  \n",
       "3     0.998547      -0.037650        0.999915              0.066199  \n",
       "4     0.998129      -0.037200        0.999898              0.054813  \n",
       "...        ...            ...             ...                   ...  \n",
       "1710  0.998485      -0.037632        0.999912              0.020783  \n",
       "1711  0.997881      -0.037122        0.999946              0.032935  \n",
       "1712  0.997997      -0.037136        0.999943             -0.064774  \n",
       "1713  0.998260      -0.037465        0.999940              0.020544  \n",
       "1714  0.998046      -0.037464        0.999873              0.077583  \n",
       "\n",
       "[1715 rows x 49 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ass_ben_train['mbert_src_assbert_trg'] = ass_beng_cos_mapped\n",
    "ass_ben_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef854a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert xlm\n",
      "mbert ass_bert\n",
      "mbert indic_bert\n",
      "mbert muril\n",
      "xlm mbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.17004e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.37965e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.17004e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm ass_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.37965e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.17004e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.37965e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm indic_bert\n",
      "xlm muril\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.17004e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.37965e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.21621e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert mbert\n",
      "ass_bert xlm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.21621e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.21621e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert indic_bert\n",
      "ass_bert muril\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.21621e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indic_bert mbert\n",
      "indic_bert xlm\n",
      "indic_bert ass_bert\n",
      "indic_bert muril\n",
      "muril mbert\n",
      "muril xlm\n",
      "muril ass_bert\n",
      "muril indic_bert\n",
      "mbertxlm [0.81422913 0.9049548  0.8283074  ... 0.8414111  0.72653395 0.8292563 ]\n",
      "mbertass_bert [-0.02195851 -0.01808187 -0.04044119 ... -0.03736622 -0.06029329\n",
      " -0.04182959]\n",
      "mbertindic_bert [0.999145   0.99959475 0.9984933  ... 0.9996923  0.9992353  0.9958416 ]\n",
      "mbertmuril [0.99905944 0.9985286  0.99879175 ... 0.9997323  0.99941474 0.99884534]\n",
      "xlmmbert [0.7086066  0.89907426 0.91591007 ... 0.87726027 0.84559566 0.8776003 ]\n",
      "xlmass_bert [-0.0197074  -0.01707486 -0.0403541  ... -0.0462508  -0.05708092\n",
      " -0.03930154]\n",
      "xlmindic_bert [0.9993415  0.99957055 0.998573   ... 0.9992578  0.99840796 0.9955033 ]\n",
      "xlmmuril [0.998371   0.9983493  0.9987029  ... 0.9984844  0.99921745 0.99828595]\n",
      "ass_bertmbert [0.7582203  0.92474973 0.92758924 ... 0.89519167 0.91026926 0.91854024]\n",
      "ass_bertxlm [0.82852423 0.9215591  0.87545663 ... 0.84163153 0.865111   0.8806467 ]\n",
      "ass_bertindic_bert [0.99961257 0.99969643 0.9988258  ... 0.99964744 0.99954474 0.9987945 ]\n",
      "ass_bertmuril [0.9992885  0.99930966 0.9991535  ... 0.99960846 0.999526   0.9996892 ]\n",
      "indic_bertmbert [0.99746525 0.99816793 0.9946995  ... 0.9981043  0.9970039  0.9907875 ]\n",
      "indic_bertxlm [0.995359   0.99756676 0.9906676  ... 0.99522483 0.99297124 0.98264635]\n",
      "indic_bertass_bert [-0.03619361 -0.0365987  -0.03737849 ... -0.03658162 -0.03742659\n",
      " -0.03678454]\n",
      "indic_bertmuril [0.99995905 0.9999588  0.9999267  ... 0.9999514  0.9999545  0.99964994]\n",
      "murilmbert [0.9985142  0.99799347 0.99890006 ... 0.9986393  0.998824   0.99821675]\n",
      "murilxlm [0.9977978  0.99767375 0.9985216  ... 0.9979966  0.9982602  0.9980457 ]\n",
      "murilass_bert [-0.03700086 -0.03744312 -0.03757237 ... -0.0371356  -0.03746517\n",
      " -0.03746393]\n",
      "murilindic_bert [0.9999454  0.99986714 0.99991405 ... 0.999943   0.99993956 0.99987304]\n"
     ]
    }
   ],
   "source": [
    "cos_mapped = get_lt_maps(all_vec) # get the mapped embeddings and transformed cosine sims for ass_ben_train\n",
    "for i, j  in cos_mapped.items():\n",
    "    print(i,j)\n",
    "    \n",
    "    ass_ben_train[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c21c753a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mbertxlm',\n",
       " 'mbertass_bert',\n",
       " 'mbertindic_bert',\n",
       " 'mbertmuril',\n",
       " 'xlmmbert',\n",
       " 'xlmass_bert',\n",
       " 'xlmindic_bert',\n",
       " 'xlmmuril',\n",
       " 'ass_bertmbert',\n",
       " 'ass_bertxlm',\n",
       " 'ass_bertindic_bert',\n",
       " 'ass_bertmuril',\n",
       " 'indic_bertmbert',\n",
       " 'indic_bertxlm',\n",
       " 'indic_bertass_bert',\n",
       " 'indic_bertmuril',\n",
       " 'murilmbert',\n",
       " 'murilxlm',\n",
       " 'murilass_bert',\n",
       " 'murilindic_bert']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cos_mapped.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77450910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2280: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/vocab.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/fcfbd016a54060fb3e7290d39ac4fd04b0c7ca2c683e5fdd87928b0feaa2c367.bd20142f530c7b681cef79e2153e77f8d9e8c9fdb3f6db29f37298198166236d\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/merges.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0693c49aba9ba31f442ba9a6c368bc400d2a81e5931d983d63d8648a043bf551.a1730275bc49c3d660f1d9bf50222d8cb849f3ae93e75e5865a3037650459b27\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/91dad0f1b901ee17a1ca86293a46619408e812441cfa380050cd03359564b95f.fabc897dd998cd3c78df5e8469be3194040e8a0f7dd4ee9278748dfcea803743\n",
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"_name_or_path\": \"xlm-mlm-100-1280\",\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/xlm-mlm-100-1280/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/5ba8c43e22aeb247eee7a4d27014eabe361cbfd2a9e00bd337946aaa0dece8ce.f11dc7ef5f30811d164556022e3174da0d6e8bb13676833dabdb1f50f61f39a5\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of XLMModel were initialized from the model checkpoint at xlm-mlm-100-1280.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Didn't find file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer.json. We won't load it.\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/spiece.model\n",
      "loading file None\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/added_tokens.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/special_tokens_map.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer_config.json\n",
      "Adding <pad> to the vocabulary\n",
      "loading configuration file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2\",\n",
      "  \"architectures\": [\n",
      "    \"AlbertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing AlbertModel.\n",
      "\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/spiece.model from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/97e976f62c951292c6fdb2bb5bf1f34f5450585dda98be8dedea2b97e4f25b86.5c8e83e7afe2b2faae1dc1a6b0fcdb911480df6af7079e9df53aa83ed0763de2\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.dense.weight', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at ai4bharat/indic-bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b97fc49fcc6c4b696e73d117cd105e9896633d546afdaa10fbdc2e3964b7ccce.6238bf3b1b7ad31c55bb4415faa9477a5f8e50723e8d1d70df19a65433db277f\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/special_tokens_map.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/290471f6a01c9af0dd0bcf02112dc77b9b0aee820ebb1fb023c96ac2dda9d8ef.750293617705dd39d21eef1e163d80ca5b23e1a0ec507fff24a087c44632142c\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/677de489a9460181a44c530abce89d7d341485a3d49dacc89a9b5a1fed34c328.94e1730f1b81d6fdf365e5e59d01a4e387286e650a02ed6512f3dba8668dd876\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/muril-base-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b4704f25323c21eafa8f1b6196e294d7252e11aa35d082c49d6ae62f3ca168dd.767d38e2461040f361197f7fc27e1968320609d399f194178c3adb49eeeb8ca9\n",
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at google/muril-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get all the mapped embeddings and cosine sims for ben_ass_test\n",
    "mbert_cos, all_vec = get_mbert_cos_sims(list(ben_ass_test['loan_word']),list(ben_ass_test['original_word']))\n",
    "xlm_cos, all_vec = get_xlm_cos_sims(list(ben_ass_test['loan_word']),list(ben_ass_test['original_word']))\n",
    "ass_bert_cos, all_vec = get_ass_albert_cos_sims(list(ben_ass_test['original_word']),list(ben_ass_test['loan_word']), lin_transform =True)\n",
    "indic_bert_cos, all_vec = Indic_bert_cos_sims(list(ben_ass_test['loan_word']),list(ben_ass_test['original_word']))\n",
    "muril_cos, all_vec = Muril_cos_sims(list(ben_ass_test['loan_word']),list(ben_ass_test['original_word']))\n",
    "\n",
    "# ben_ass_test['mbert_cos'] = mbert_cos\n",
    "# ben_ass_test['xlm_cos'] = xlm_cos\n",
    "# ben_ass_test['ass_bert_mbert_cos'] = ass_bert_cos\n",
    "# ben_ass_test['indic_bert_cos'] = indic_bert_cos\n",
    "# ben_ass_test['muril_cos'] = muril_cos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73c90348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert (1631, 768) (1631, 768) <class 'numpy.ndarray'>\n",
      "xlm (1631, 1280) (1631, 1280) <class 'numpy.ndarray'>\n",
      "ass_bert (1631, 768) (1631, 768) <class 'numpy.ndarray'>\n",
      "indic_bert (1631, 768) (1631, 768) <class 'numpy.ndarray'>\n",
      "muril (1631, 768) (1631, 768) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i, j in all_vec.items():\n",
    "    print(i,j['loan'].shape, j['original'].shape, type(j['original']))\n",
    "# all_vec['mbert']['loan'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed718ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768)\n"
     ]
    }
   ],
   "source": [
    "# get the linear transformation from mbert space to ass_bert space using the precalculated transformation matrix i.e beng_m_bertvec, ass_bertvec\n",
    "#for ben_ass_test\n",
    "m = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec, ass_bertvec) \n",
    "m = m.coef_ \n",
    "print(m.shape) #this is the 768 by 768 transformation matrix between mbert and assbert \n",
    "mapped_= all_vec['mbert']['loan'] @ m.transpose()\n",
    "beng_ass_test_cos_mapped = get_cosine_similarities(mapped_, all_vec['ass_bert']['original'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33ca8d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>loan_word_epitran</th>\n",
       "      <th>original_word_epitran</th>\n",
       "      <th>loan_english</th>\n",
       "      <th>...</th>\n",
       "      <th>ass_bertmuril</th>\n",
       "      <th>indic_bertmbert</th>\n",
       "      <th>indic_bertxlm</th>\n",
       "      <th>indic_bertass_bert</th>\n",
       "      <th>indic_bertmuril</th>\n",
       "      <th>murilmbert</th>\n",
       "      <th>murilxlm</th>\n",
       "      <th>murilass_bert</th>\n",
       "      <th>murilindic_bert</th>\n",
       "      <th>mbert_src_assbert_trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>হাট</td>\n",
       "      <td>পুথি</td>\n",
       "      <td>ɦaʈɔ</td>\n",
       "      <td>putʰi</td>\n",
       "      <td>Hat</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.995602</td>\n",
       "      <td>0.995207</td>\n",
       "      <td>-0.037043</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.998250</td>\n",
       "      <td>0.998064</td>\n",
       "      <td>-0.037110</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.053788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>গলদেশ</td>\n",
       "      <td>গেলা</td>\n",
       "      <td>ɡɔlɔd̪eʃ</td>\n",
       "      <td>gɛla</td>\n",
       "      <td>Neck</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.993731</td>\n",
       "      <td>0.990757</td>\n",
       "      <td>-0.036650</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.997744</td>\n",
       "      <td>0.997690</td>\n",
       "      <td>-0.036971</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.003743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>আঁকা</td>\n",
       "      <td>আঁক</td>\n",
       "      <td>ãka</td>\n",
       "      <td>ãkɔ</td>\n",
       "      <td>Draw</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.996707</td>\n",
       "      <td>0.996931</td>\n",
       "      <td>-0.036699</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.997577</td>\n",
       "      <td>0.998135</td>\n",
       "      <td>-0.037100</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.069326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>মিডা</td>\n",
       "      <td>নদী</td>\n",
       "      <td>miɖa</td>\n",
       "      <td>nɔdi</td>\n",
       "      <td>Mida</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.993703</td>\n",
       "      <td>0.982903</td>\n",
       "      <td>-0.037739</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>0.998603</td>\n",
       "      <td>0.997843</td>\n",
       "      <td>-0.037069</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.022493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>অনুমতি</td>\n",
       "      <td>পানী</td>\n",
       "      <td>on̪umt̪i</td>\n",
       "      <td>pani</td>\n",
       "      <td>Permission</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.998033</td>\n",
       "      <td>0.997661</td>\n",
       "      <td>-0.037113</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.998184</td>\n",
       "      <td>0.998295</td>\n",
       "      <td>-0.037151</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.066781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>1626</td>\n",
       "      <td>1626</td>\n",
       "      <td>1626</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>ভাজা</td>\n",
       "      <td>টাকা</td>\n",
       "      <td>bʱad͡ʑa</td>\n",
       "      <td>taka</td>\n",
       "      <td>Fried</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.996144</td>\n",
       "      <td>0.994600</td>\n",
       "      <td>-0.037110</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.998329</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>-0.037136</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.063769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>1627</td>\n",
       "      <td>1627</td>\n",
       "      <td>1627</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>ডাঁশ</td>\n",
       "      <td>আঁক</td>\n",
       "      <td>ɖãʃɔ</td>\n",
       "      <td>ãkɔ</td>\n",
       "      <td>Bite</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.996940</td>\n",
       "      <td>0.987930</td>\n",
       "      <td>-0.036750</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998310</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>-0.036979</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.121835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "      <td>মঙ্গল্য</td>\n",
       "      <td>শ্রী</td>\n",
       "      <td>mɔŋɡɔld͡zɔ</td>\n",
       "      <td>xɹi</td>\n",
       "      <td>Good luck</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999517</td>\n",
       "      <td>0.995814</td>\n",
       "      <td>0.989882</td>\n",
       "      <td>-0.036404</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.998445</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>-0.037016</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.003480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>1629</td>\n",
       "      <td>1629</td>\n",
       "      <td>1629</td>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "      <td>সন্ধ্যা</td>\n",
       "      <td>সন্ধিয়া</td>\n",
       "      <td>ʃɔn̪d̪ʱæ</td>\n",
       "      <td>xɔndʰija</td>\n",
       "      <td>Evening</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.996680</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>-0.037186</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.998191</td>\n",
       "      <td>0.998367</td>\n",
       "      <td>-0.037138</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.010274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>1630</td>\n",
       "      <td>1630</td>\n",
       "      <td>1630</td>\n",
       "      <td>272</td>\n",
       "      <td>272</td>\n",
       "      <td>মেয়ে</td>\n",
       "      <td>আকাশ</td>\n",
       "      <td>mee̯e</td>\n",
       "      <td>akax</td>\n",
       "      <td>Girl</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.998088</td>\n",
       "      <td>0.993749</td>\n",
       "      <td>-0.037103</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.998008</td>\n",
       "      <td>0.998292</td>\n",
       "      <td>-0.037172</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.013591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0              0             0               0               328   \n",
       "1              1             1               1                60   \n",
       "2              2             2               2                15   \n",
       "3              3             3               3               255   \n",
       "4              4             4               4                 9   \n",
       "...          ...           ...             ...               ...   \n",
       "1626        1626          1626            1626               232   \n",
       "1627        1627          1627            1627                84   \n",
       "1628        1628          1628            1628               311   \n",
       "1629        1629          1629            1629               311   \n",
       "1630        1630          1630            1630               272   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1 loan_word original_word loan_word_epitran  \\\n",
       "0                    328       হাট          পুথি              ɦaʈɔ   \n",
       "1                     60     গলদেশ          গেলা          ɡɔlɔd̪eʃ   \n",
       "2                     15      আঁকা           আঁক               ãka   \n",
       "3                    255      মিডা           নদী              miɖa   \n",
       "4                      9    অনুমতি          পানী          on̪umt̪i   \n",
       "...                  ...       ...           ...               ...   \n",
       "1626                 232      ভাজা          টাকা           bʱad͡ʑa   \n",
       "1627                  84      ডাঁশ           আঁক              ɖãʃɔ   \n",
       "1628                 311   মঙ্গল্য          শ্রী        mɔŋɡɔld͡zɔ   \n",
       "1629                 311   সন্ধ্যা      সন্ধিয়া          ʃɔn̪d̪ʱæ   \n",
       "1630                 272     মেয়ে          আকাশ             mee̯e   \n",
       "\n",
       "     original_word_epitran loan_english  ... ass_bertmuril  indic_bertmbert  \\\n",
       "0                    putʰi          Hat  ...      0.999896         0.995602   \n",
       "1                     gɛla         Neck  ...      0.999892         0.993731   \n",
       "2                      ãkɔ         Draw  ...      0.999945         0.996707   \n",
       "3                     nɔdi         Mida  ...      0.999900         0.993703   \n",
       "4                     pani   Permission  ...      0.999640         0.998033   \n",
       "...                    ...          ...  ...           ...              ...   \n",
       "1626                  taka        Fried  ...      0.999945         0.996144   \n",
       "1627                   ãkɔ         Bite  ...      0.999847         0.996940   \n",
       "1628                   xɹi    Good luck  ...      0.999517         0.995814   \n",
       "1629              xɔndʰija      Evening  ...      0.999760         0.996680   \n",
       "1630                  akax         Girl  ...      0.999922         0.998088   \n",
       "\n",
       "      indic_bertxlm  indic_bertass_bert  indic_bertmuril  murilmbert  \\\n",
       "0          0.995207           -0.037043         0.999959    0.998250   \n",
       "1          0.990757           -0.036650         0.999945    0.997744   \n",
       "2          0.996931           -0.036699         0.999989    0.997577   \n",
       "3          0.982903           -0.037739         0.999721    0.998603   \n",
       "4          0.997661           -0.037113         0.999993    0.998184   \n",
       "...             ...                 ...              ...         ...   \n",
       "1626       0.994600           -0.037110         0.999983    0.998329   \n",
       "1627       0.987930           -0.036750         0.999786    0.998310   \n",
       "1628       0.989882           -0.036404         0.999950    0.998445   \n",
       "1629       0.993957           -0.037186         0.999987    0.998191   \n",
       "1630       0.993749           -0.037103         0.999986    0.998008   \n",
       "\n",
       "      murilxlm  murilass_bert murilindic_bert mbert_src_assbert_trg  \n",
       "0     0.998064      -0.037110        0.999959              0.053788  \n",
       "1     0.997690      -0.036971        0.999936              0.003743  \n",
       "2     0.998135      -0.037100        0.999910              0.069326  \n",
       "3     0.997843      -0.037069        0.999968              0.022493  \n",
       "4     0.998295      -0.037151        0.999949              0.066781  \n",
       "...        ...            ...             ...                   ...  \n",
       "1626  0.998383      -0.037136        0.999948              0.063769  \n",
       "1627  0.997333      -0.036979        0.999958              0.121835  \n",
       "1628  0.997835      -0.037016        0.999963              0.003480  \n",
       "1629  0.998367      -0.037138        0.999944              0.010274  \n",
       "1630  0.998292      -0.037172        0.999939              0.013591  \n",
       "\n",
       "[1631 rows x 49 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_ass_test['mbert_src_assbert_trg'] = beng_ass_test_cos_mapped \n",
    "ben_ass_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "108d7cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert xlm\n",
      "mbert ass_bert\n",
      "mbert indic_bert\n",
      "mbert muril\n",
      "xlm mbert\n",
      "xlm ass_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.02671e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.25199e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.02671e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.25199e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.02671e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm indic_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.25199e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.02671e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.25199e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm muril\n",
      "ass_bert mbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.34718e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.34718e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert xlm\n",
      "ass_bert indic_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.34718e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.34718e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert muril\n",
      "indic_bert mbert\n",
      "indic_bert xlm\n",
      "indic_bert ass_bert\n",
      "indic_bert muril\n",
      "muril mbert\n",
      "muril xlm\n",
      "muril ass_bert\n",
      "muril indic_bert\n",
      "mbertxlm [0.68755674 0.6841567  0.8534988  ... 0.82382274 0.84723943 0.6884533 ]\n",
      "mbertass_bert [-0.03226281 -0.03727898 -0.03546291 ... -0.02263128 -0.02630463\n",
      " -0.03139025]\n",
      "mbertindic_bert [0.9993046  0.99761856 0.99946994 ... 0.9992995  0.9992915  0.99969566]\n",
      "mbertmuril [0.99955285 0.99912673 0.9995197  ... 0.99956286 0.9997964  0.99970603]\n",
      "xlmmbert [0.752661   0.896068   0.97391474 ... 0.8989773  0.9174396  0.83722556]\n",
      "xlmass_bert [-0.03177009 -0.03839995 -0.03367117 ... -0.01886591 -0.02574864\n",
      " -0.03231563]\n",
      "xlmindic_bert [0.9992496  0.9971322  0.99961483 ... 0.99843436 0.9987686  0.99955803]\n",
      "xlmmuril [0.99931383 0.9988723  0.9991207  ... 0.9991207  0.9997629  0.9996088 ]\n",
      "ass_bertmbert [0.97233784 0.96923876 0.98733175 ... 0.9767873  0.9857687  0.9736726 ]\n",
      "ass_bertxlm [0.9623678  0.94629645 0.9579295  ... 0.9473304  0.95603776 0.93384033]\n",
      "ass_bertindic_bert [0.9999118 0.9993599 0.9999355 ... 0.9998403 0.9998528 0.9998953]\n",
      "ass_bertmuril [0.9998965  0.99989223 0.999945   ... 0.9995174  0.9997602  0.99992216]\n",
      "indic_bertmbert [0.9956024  0.9937305  0.9967067  ... 0.99581367 0.99667984 0.99808836]\n",
      "indic_bertxlm [0.9952071  0.99075735 0.99693054 ... 0.9898816  0.99395657 0.99374884]\n",
      "indic_bertass_bert [-0.03704281 -0.03664971 -0.03669919 ... -0.03640383 -0.03718582\n",
      " -0.0371028 ]\n",
      "indic_bertmuril [0.9999594  0.9999454  0.99998945 ... 0.99994993 0.9999865  0.9999864 ]\n",
      "murilmbert [0.99825   0.9977438 0.9975773 ... 0.9984449 0.9981906 0.9980075]\n",
      "murilxlm [0.99806446 0.9976903  0.9981352  ... 0.99783504 0.9983667  0.9982916 ]\n",
      "murilass_bert [-0.0371102  -0.03697082 -0.03710019 ... -0.03701585 -0.037138\n",
      " -0.03717186]\n",
      "murilindic_bert [0.9999589  0.9999357  0.99991035 ... 0.9999628  0.99994385 0.9999386 ]\n"
     ]
    }
   ],
   "source": [
    "cos_mapped = get_lt_maps(all_vec) # get the mapped embeddings and cosine sims for ass_ben_train\n",
    "for i, j  in cos_mapped.items():\n",
    "    print(i,j)\n",
    "    \n",
    "    ben_ass_test[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5edff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2280: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/vocab.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/fcfbd016a54060fb3e7290d39ac4fd04b0c7ca2c683e5fdd87928b0feaa2c367.bd20142f530c7b681cef79e2153e77f8d9e8c9fdb3f6db29f37298198166236d\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/merges.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0693c49aba9ba31f442ba9a6c368bc400d2a81e5931d983d63d8648a043bf551.a1730275bc49c3d660f1d9bf50222d8cb849f3ae93e75e5865a3037650459b27\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-mlm-100-1280/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/91dad0f1b901ee17a1ca86293a46619408e812441cfa380050cd03359564b95f.fabc897dd998cd3c78df5e8469be3194040e8a0f7dd4ee9278748dfcea803743\n",
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"_name_or_path\": \"xlm-mlm-100-1280\",\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/xlm-mlm-100-1280/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/db80884313abeddd782425fe61c0846a43c007b0f403d13181e368ad7dd52f62.394eed9fa7b8205161e0b47bf552ae933e7e29234009f217a03b87bfe054ed52\n",
      "Model config XLMConfig {\n",
      "  \"accumulate_gradients\": 4,\n",
      "  \"ae_steps\": [],\n",
      "  \"amp\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"batch_size\": 16,\n",
      "  \"beam_size\": 1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 256,\n",
      "  \"bt_src_langs\": [],\n",
      "  \"bt_steps\": [],\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 1.0,\n",
      "  \"clm_steps\": [],\n",
      "  \"command\": \"python /private/home/aconneau/workdir/xlm_17_100_big.3/2019_08_10_19_23_42/train.py --n_heads 16 --bt_steps '' --max_vocab 200000 --word_mask_keep_rand '0.8,0.1,0.1' --use_lang_emb false --data_path '/private/home/aconneau/projects/XLM/data/wiki/100/175k' --save_periodic 0 --max_len 200 --bptt 256 --ae_steps '' --fp16 true --share_inout_emb true --sinusoidal_embeddings false --word_shuffle 0 --tokens_per_batch '-1' --accumulate_gradients 4 --validation_metrics '_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl' --attention_dropout '0.1' --split_data true --max_epoch 100000 --stopping_criterion '_valid_zh_mlm_ppl,25' --dump_path '/checkpoint/aconneau/dumped' --epoch_size 200000 --word_blank 0 --gelu_activation true --n_layers 16 --optimizer 'adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001' --mlm_steps 'en,es,fr,de,zh,ru,pt,it,ar,ja,id,tr,nl,pl,simple,fa,vi,sv,ko,he,ro,no,hi,uk,cs,fi,hu,th,da,ca,el,bg,sr,ms,bn,hr,sl,zh_yue,az,sk,eo,ta,sh,lt,et,ml,la,bs,sq,arz,af,ka,mr,eu,tl,ang,gl,nn,ur,kk,be,hy,te,lv,mk,zh_classical,als,is,wuu,my,sco,mn,ceb,ast,cy,kn,br,an,gu,bar,uz,lb,ne,si,war,jv,ga,zh_min_nan,oc,ku,sw,nds,ckb,ia,yi,fy,scn,gan,tt,am' --eval_bleu false --dropout '0.1' --mt_steps '' --batch_size 16 --word_dropout 0 --reload_model '/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth' --min_count 0 --amp 2 --group_by_size true --asm false --sample_alpha '0.5' --word_pred '0.15' --clip_grad_norm 1 --emb_dim 1280 --encoder_only true --lgs 'en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am' --clm_steps '' --exp_name 'xlm_17_100_big.3' --lg_sampling_factor '0.7' --eval_only false --exp_id 16656234 --master_port 11363 --exp_id \\\"16656234\\\"\",\n",
      "  \"context_size\": 0,\n",
      "  \"data_path\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k\",\n",
      "  \"debug\": false,\n",
      "  \"debug_slurm\": false,\n",
      "  \"debug_train\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dump_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234\",\n",
      "  \"emb_dim\": 1280,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"epoch_size\": 200000,\n",
      "  \"eval_bleu\": false,\n",
      "  \"eval_only\": false,\n",
      "  \"exp_id\": \"16656234\",\n",
      "  \"exp_name\": \"xlm_17_100_big.3\",\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"global_rank\": 0,\n",
      "  \"group_by_size\": true,\n",
      "  \"hyp_path\": \"/checkpoint/aconneau/dumped/xlm_17_100_big.3/16656234/hypotheses\",\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"af\",\n",
      "    \"1\": \"als\",\n",
      "    \"10\": \"be\",\n",
      "    \"11\": \"bg\",\n",
      "    \"12\": \"bn\",\n",
      "    \"13\": \"br\",\n",
      "    \"14\": \"bs\",\n",
      "    \"15\": \"ca\",\n",
      "    \"16\": \"ceb\",\n",
      "    \"17\": \"ckb\",\n",
      "    \"18\": \"cs\",\n",
      "    \"19\": \"cy\",\n",
      "    \"2\": \"am\",\n",
      "    \"20\": \"da\",\n",
      "    \"21\": \"de\",\n",
      "    \"22\": \"el\",\n",
      "    \"23\": \"en\",\n",
      "    \"24\": \"eo\",\n",
      "    \"25\": \"es\",\n",
      "    \"26\": \"et\",\n",
      "    \"27\": \"eu\",\n",
      "    \"28\": \"fa\",\n",
      "    \"29\": \"fi\",\n",
      "    \"3\": \"an\",\n",
      "    \"30\": \"fr\",\n",
      "    \"31\": \"fy\",\n",
      "    \"32\": \"ga\",\n",
      "    \"33\": \"gan\",\n",
      "    \"34\": \"gl\",\n",
      "    \"35\": \"gu\",\n",
      "    \"36\": \"he\",\n",
      "    \"37\": \"hi\",\n",
      "    \"38\": \"hr\",\n",
      "    \"39\": \"hu\",\n",
      "    \"4\": \"ang\",\n",
      "    \"40\": \"hy\",\n",
      "    \"41\": \"ia\",\n",
      "    \"42\": \"id\",\n",
      "    \"43\": \"is\",\n",
      "    \"44\": \"it\",\n",
      "    \"45\": \"ja\",\n",
      "    \"46\": \"jv\",\n",
      "    \"47\": \"ka\",\n",
      "    \"48\": \"kk\",\n",
      "    \"49\": \"kn\",\n",
      "    \"5\": \"ar\",\n",
      "    \"50\": \"ko\",\n",
      "    \"51\": \"ku\",\n",
      "    \"52\": \"la\",\n",
      "    \"53\": \"lb\",\n",
      "    \"54\": \"lt\",\n",
      "    \"55\": \"lv\",\n",
      "    \"56\": \"mk\",\n",
      "    \"57\": \"ml\",\n",
      "    \"58\": \"mn\",\n",
      "    \"59\": \"mr\",\n",
      "    \"6\": \"arz\",\n",
      "    \"60\": \"ms\",\n",
      "    \"61\": \"my\",\n",
      "    \"62\": \"nds\",\n",
      "    \"63\": \"ne\",\n",
      "    \"64\": \"nl\",\n",
      "    \"65\": \"nn\",\n",
      "    \"66\": \"no\",\n",
      "    \"67\": \"oc\",\n",
      "    \"68\": \"pl\",\n",
      "    \"69\": \"pt\",\n",
      "    \"7\": \"ast\",\n",
      "    \"70\": \"ro\",\n",
      "    \"71\": \"ru\",\n",
      "    \"72\": \"scn\",\n",
      "    \"73\": \"sco\",\n",
      "    \"74\": \"sh\",\n",
      "    \"75\": \"si\",\n",
      "    \"76\": \"simple\",\n",
      "    \"77\": \"sk\",\n",
      "    \"78\": \"sl\",\n",
      "    \"79\": \"sq\",\n",
      "    \"8\": \"az\",\n",
      "    \"80\": \"sr\",\n",
      "    \"81\": \"sv\",\n",
      "    \"82\": \"sw\",\n",
      "    \"83\": \"ta\",\n",
      "    \"84\": \"te\",\n",
      "    \"85\": \"th\",\n",
      "    \"86\": \"tl\",\n",
      "    \"87\": \"tr\",\n",
      "    \"88\": \"tt\",\n",
      "    \"89\": \"uk\",\n",
      "    \"9\": \"bar\",\n",
      "    \"90\": \"ur\",\n",
      "    \"91\": \"uz\",\n",
      "    \"92\": \"vi\",\n",
      "    \"93\": \"war\",\n",
      "    \"94\": \"wuu\",\n",
      "    \"95\": \"yi\",\n",
      "    \"96\": \"zh\",\n",
      "    \"97\": \"zh_classical\",\n",
      "    \"98\": \"zh_min_nan\",\n",
      "    \"99\": \"zh_yue\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"is_master\": true,\n",
      "  \"is_slurm_job\": true,\n",
      "  \"lambda_ae\": 1.0,\n",
      "  \"lambda_ae_config\": null,\n",
      "  \"lambda_bt\": 1.0,\n",
      "  \"lambda_bt_config\": null,\n",
      "  \"lambda_clm\": 1.0,\n",
      "  \"lambda_clm_config\": null,\n",
      "  \"lambda_mlm\": 1.0,\n",
      "  \"lambda_mlm_config\": null,\n",
      "  \"lambda_mt\": 1.0,\n",
      "  \"lambda_mt_config\": null,\n",
      "  \"lambda_pc\": 1.0,\n",
      "  \"lambda_pc_config\": null,\n",
      "  \"lang2id\": {\n",
      "    \"af\": 0,\n",
      "    \"als\": 1,\n",
      "    \"am\": 2,\n",
      "    \"an\": 3,\n",
      "    \"ang\": 4,\n",
      "    \"ar\": 5,\n",
      "    \"arz\": 6,\n",
      "    \"ast\": 7,\n",
      "    \"az\": 8,\n",
      "    \"bar\": 9,\n",
      "    \"be\": 10,\n",
      "    \"bg\": 11,\n",
      "    \"bn\": 12,\n",
      "    \"br\": 13,\n",
      "    \"bs\": 14,\n",
      "    \"ca\": 15,\n",
      "    \"ceb\": 16,\n",
      "    \"ckb\": 17,\n",
      "    \"cs\": 18,\n",
      "    \"cy\": 19,\n",
      "    \"da\": 20,\n",
      "    \"de\": 21,\n",
      "    \"el\": 22,\n",
      "    \"en\": 23,\n",
      "    \"eo\": 24,\n",
      "    \"es\": 25,\n",
      "    \"et\": 26,\n",
      "    \"eu\": 27,\n",
      "    \"fa\": 28,\n",
      "    \"fi\": 29,\n",
      "    \"fr\": 30,\n",
      "    \"fy\": 31,\n",
      "    \"ga\": 32,\n",
      "    \"gan\": 33,\n",
      "    \"gl\": 34,\n",
      "    \"gu\": 35,\n",
      "    \"he\": 36,\n",
      "    \"hi\": 37,\n",
      "    \"hr\": 38,\n",
      "    \"hu\": 39,\n",
      "    \"hy\": 40,\n",
      "    \"ia\": 41,\n",
      "    \"id\": 42,\n",
      "    \"is\": 43,\n",
      "    \"it\": 44,\n",
      "    \"ja\": 45,\n",
      "    \"jv\": 46,\n",
      "    \"ka\": 47,\n",
      "    \"kk\": 48,\n",
      "    \"kn\": 49,\n",
      "    \"ko\": 50,\n",
      "    \"ku\": 51,\n",
      "    \"la\": 52,\n",
      "    \"lb\": 53,\n",
      "    \"lt\": 54,\n",
      "    \"lv\": 55,\n",
      "    \"mk\": 56,\n",
      "    \"ml\": 57,\n",
      "    \"mn\": 58,\n",
      "    \"mr\": 59,\n",
      "    \"ms\": 60,\n",
      "    \"my\": 61,\n",
      "    \"nds\": 62,\n",
      "    \"ne\": 63,\n",
      "    \"nl\": 64,\n",
      "    \"nn\": 65,\n",
      "    \"no\": 66,\n",
      "    \"oc\": 67,\n",
      "    \"pl\": 68,\n",
      "    \"pt\": 69,\n",
      "    \"ro\": 70,\n",
      "    \"ru\": 71,\n",
      "    \"scn\": 72,\n",
      "    \"sco\": 73,\n",
      "    \"sh\": 74,\n",
      "    \"si\": 75,\n",
      "    \"simple\": 76,\n",
      "    \"sk\": 77,\n",
      "    \"sl\": 78,\n",
      "    \"sq\": 79,\n",
      "    \"sr\": 80,\n",
      "    \"sv\": 81,\n",
      "    \"sw\": 82,\n",
      "    \"ta\": 83,\n",
      "    \"te\": 84,\n",
      "    \"th\": 85,\n",
      "    \"tl\": 86,\n",
      "    \"tr\": 87,\n",
      "    \"tt\": 88,\n",
      "    \"uk\": 89,\n",
      "    \"ur\": 90,\n",
      "    \"uz\": 91,\n",
      "    \"vi\": 92,\n",
      "    \"war\": 93,\n",
      "    \"wuu\": 94,\n",
      "    \"yi\": 95,\n",
      "    \"zh\": 96,\n",
      "    \"zh_classical\": 97,\n",
      "    \"zh_min_nan\": 98,\n",
      "    \"zh_yue\": 99\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"lg_sampling_factor\": 0.7,\n",
      "  \"lgs\": \"en-es-fr-de-zh-ru-pt-it-ar-ja-id-tr-nl-pl-simple-fa-vi-sv-ko-he-ro-no-hi-uk-cs-fi-hu-th-da-ca-el-bg-sr-ms-bn-hr-sl-zh_yue-az-sk-eo-ta-sh-lt-et-ml-la-bs-sq-arz-af-ka-mr-eu-tl-ang-gl-nn-ur-kk-be-hy-te-lv-mk-zh_classical-als-is-wuu-my-sco-mn-ceb-ast-cy-kn-br-an-gu-bar-uz-lb-ne-si-war-jv-ga-zh_min_nan-oc-ku-sw-nds-ckb-ia-yi-fy-scn-gan-tt-am\",\n",
      "  \"local_rank\": 0,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"master_addr\": \"learnfair0332\",\n",
      "  \"master_port\": 11363,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_epoch\": 100000,\n",
      "  \"max_len\": 200,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": 200000,\n",
      "  \"min_count\": 0,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"en\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"es\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"de\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ru\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"it\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ja\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"id\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"pl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"simple\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fa\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"vi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ko\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"he\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ro\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"no\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"th\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"da\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ca\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"el\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bg\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ms\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_yue\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"az\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eo\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ta\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sh\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"et\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ml\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"la\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bs\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sq\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"arz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"af\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ka\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mr\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"eu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ang\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gl\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ur\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"be\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"hy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"te\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mk\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_classical\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"als\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"is\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"wuu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"my\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sco\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"mn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ceb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ast\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"cy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"kn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"br\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"an\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gu\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"bar\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"uz\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"lb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ne\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"si\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"war\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"jv\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ga\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"zh_min_nan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"oc\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ku\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"sw\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"nds\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ckb\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"ia\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"yi\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"fy\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"scn\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"gan\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"tt\",\n",
      "      null\n",
      "    ],\n",
      "    [\n",
      "      \"am\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"mono_dataset\": {\n",
      "    \"af\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.af.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.af.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.af.pth\"\n",
      "    },\n",
      "    \"als\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.als.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.als.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.als.pth\"\n",
      "    },\n",
      "    \"am\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.am.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.am.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.am.pth\"\n",
      "    },\n",
      "    \"an\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.an.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.an.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.an.pth\"\n",
      "    },\n",
      "    \"ang\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ang.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ang.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ang.pth\"\n",
      "    },\n",
      "    \"ar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ar.pth\"\n",
      "    },\n",
      "    \"arz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.arz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.arz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.arz.pth\"\n",
      "    },\n",
      "    \"ast\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ast.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ast.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ast.pth\"\n",
      "    },\n",
      "    \"az\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.az.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.az.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.az.pth\"\n",
      "    },\n",
      "    \"bar\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bar.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bar.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bar.pth\"\n",
      "    },\n",
      "    \"be\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.be.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.be.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.be.pth\"\n",
      "    },\n",
      "    \"bg\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bg.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bg.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bg.pth\"\n",
      "    },\n",
      "    \"bn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bn.pth\"\n",
      "    },\n",
      "    \"br\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.br.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.br.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.br.pth\"\n",
      "    },\n",
      "    \"bs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.bs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.bs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.bs.pth\"\n",
      "    },\n",
      "    \"ca\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ca.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ca.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ca.pth\"\n",
      "    },\n",
      "    \"ceb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ceb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ceb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ceb.pth\"\n",
      "    },\n",
      "    \"ckb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ckb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ckb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ckb.pth\"\n",
      "    },\n",
      "    \"cs\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cs.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cs.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cs.pth\"\n",
      "    },\n",
      "    \"cy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.cy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.cy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.cy.pth\"\n",
      "    },\n",
      "    \"da\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.da.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.da.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.da.pth\"\n",
      "    },\n",
      "    \"de\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.de.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.de.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.de.pth\"\n",
      "    },\n",
      "    \"el\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.el.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.el.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.el.pth\"\n",
      "    },\n",
      "    \"en\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.en.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.en.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.en.pth\"\n",
      "    },\n",
      "    \"eo\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eo.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eo.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eo.pth\"\n",
      "    },\n",
      "    \"es\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.es.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.es.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.es.pth\"\n",
      "    },\n",
      "    \"et\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.et.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.et.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.et.pth\"\n",
      "    },\n",
      "    \"eu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.eu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.eu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.eu.pth\"\n",
      "    },\n",
      "    \"fa\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fa.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fa.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fa.pth\"\n",
      "    },\n",
      "    \"fi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fi.pth\"\n",
      "    },\n",
      "    \"fr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fr.pth\"\n",
      "    },\n",
      "    \"fy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.fy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.fy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.fy.pth\"\n",
      "    },\n",
      "    \"ga\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ga.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ga.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ga.pth\"\n",
      "    },\n",
      "    \"gan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gan.pth\"\n",
      "    },\n",
      "    \"gl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gl.pth\"\n",
      "    },\n",
      "    \"gu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.gu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.gu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.gu.pth\"\n",
      "    },\n",
      "    \"he\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.he.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.he.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.he.pth\"\n",
      "    },\n",
      "    \"hi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hi.pth\"\n",
      "    },\n",
      "    \"hr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hr.pth\"\n",
      "    },\n",
      "    \"hu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hu.pth\"\n",
      "    },\n",
      "    \"hy\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.hy.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.hy.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.hy.pth\"\n",
      "    },\n",
      "    \"ia\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ia.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ia.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ia.pth\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.id.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.id.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.id.pth\"\n",
      "    },\n",
      "    \"is\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.is.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.is.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.is.pth\"\n",
      "    },\n",
      "    \"it\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.it.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.it.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.it.pth\"\n",
      "    },\n",
      "    \"ja\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ja.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ja.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ja.pth\"\n",
      "    },\n",
      "    \"jv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.jv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.jv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.jv.pth\"\n",
      "    },\n",
      "    \"ka\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ka.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ka.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ka.pth\"\n",
      "    },\n",
      "    \"kk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kk.pth\"\n",
      "    },\n",
      "    \"kn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.kn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.kn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.kn.pth\"\n",
      "    },\n",
      "    \"ko\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ko.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ko.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ko.pth\"\n",
      "    },\n",
      "    \"ku\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ku.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ku.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ku.pth\"\n",
      "    },\n",
      "    \"la\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.la.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.la.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.la.pth\"\n",
      "    },\n",
      "    \"lb\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lb.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lb.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lb.pth\"\n",
      "    },\n",
      "    \"lt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lt.pth\"\n",
      "    },\n",
      "    \"lv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.lv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.lv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.lv.pth\"\n",
      "    },\n",
      "    \"mk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mk.pth\"\n",
      "    },\n",
      "    \"ml\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ml.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ml.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ml.pth\"\n",
      "    },\n",
      "    \"mn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mn.pth\"\n",
      "    },\n",
      "    \"mr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.mr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.mr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.mr.pth\"\n",
      "    },\n",
      "    \"ms\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ms.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ms.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ms.pth\"\n",
      "    },\n",
      "    \"my\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.my.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.my.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.my.pth\"\n",
      "    },\n",
      "    \"nds\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nds.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nds.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nds.pth\"\n",
      "    },\n",
      "    \"ne\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ne.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ne.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ne.pth\"\n",
      "    },\n",
      "    \"nl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nl.pth\"\n",
      "    },\n",
      "    \"nn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.nn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.nn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.nn.pth\"\n",
      "    },\n",
      "    \"no\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.no.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.no.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.no.pth\"\n",
      "    },\n",
      "    \"oc\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.oc.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.oc.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.oc.pth\"\n",
      "    },\n",
      "    \"pl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pl.pth\"\n",
      "    },\n",
      "    \"pt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.pt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.pt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.pt.pth\"\n",
      "    },\n",
      "    \"ro\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ro.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ro.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ro.pth\"\n",
      "    },\n",
      "    \"ru\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ru.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ru.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ru.pth\"\n",
      "    },\n",
      "    \"scn\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.scn.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.scn.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.scn.pth\"\n",
      "    },\n",
      "    \"sco\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sco.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sco.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sco.pth\"\n",
      "    },\n",
      "    \"sh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sh.pth\"\n",
      "    },\n",
      "    \"si\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.si.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.si.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.si.pth\"\n",
      "    },\n",
      "    \"simple\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.simple.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.simple.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.simple.pth\"\n",
      "    },\n",
      "    \"sk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sk.pth\"\n",
      "    },\n",
      "    \"sl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sl.pth\"\n",
      "    },\n",
      "    \"sq\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sq.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sq.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sq.pth\"\n",
      "    },\n",
      "    \"sr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sr.pth\"\n",
      "    },\n",
      "    \"sv\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sv.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sv.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sv.pth\"\n",
      "    },\n",
      "    \"sw\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.sw.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.sw.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.sw.pth\"\n",
      "    },\n",
      "    \"ta\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ta.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ta.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ta.pth\"\n",
      "    },\n",
      "    \"te\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.te.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.te.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.te.pth\"\n",
      "    },\n",
      "    \"th\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.th.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.th.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.th.pth\"\n",
      "    },\n",
      "    \"tl\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tl.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tl.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tl.pth\"\n",
      "    },\n",
      "    \"tr\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tr.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tr.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tr.pth\"\n",
      "    },\n",
      "    \"tt\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.tt.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.tt.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.tt.pth\"\n",
      "    },\n",
      "    \"uk\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uk.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uk.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uk.pth\"\n",
      "    },\n",
      "    \"ur\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.ur.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.ur.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.ur.pth\"\n",
      "    },\n",
      "    \"uz\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.uz.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.uz.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.uz.pth\"\n",
      "    },\n",
      "    \"vi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.vi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.vi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.vi.pth\"\n",
      "    },\n",
      "    \"war\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.war.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.war.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.war.pth\"\n",
      "    },\n",
      "    \"wuu\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.wuu.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.wuu.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.wuu.pth\"\n",
      "    },\n",
      "    \"yi\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.yi.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.yi.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.yi.pth\"\n",
      "    },\n",
      "    \"zh\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh.pth\"\n",
      "    },\n",
      "    \"zh_classical\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_classical.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_classical.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_classical.pth\"\n",
      "    },\n",
      "    \"zh_min_nan\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_min_nan.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_min_nan.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_min_nan.pth\"\n",
      "    },\n",
      "    \"zh_yue\": {\n",
      "      \"test\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/test.zh_yue.pth\",\n",
      "      \"train\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/train.zh_yue.pth\",\n",
      "      \"valid\": \"/private/home/aconneau/projects/XLM/data/wiki/100/175k/valid.zh_yue.pth\"\n",
      "    }\n",
      "  },\n",
      "  \"mono_list\": [\n",
      "    \"en\",\n",
      "    \"es\",\n",
      "    \"fr\",\n",
      "    \"de\",\n",
      "    \"zh\",\n",
      "    \"ru\",\n",
      "    \"pt\",\n",
      "    \"it\",\n",
      "    \"ar\",\n",
      "    \"ja\",\n",
      "    \"id\",\n",
      "    \"tr\",\n",
      "    \"nl\",\n",
      "    \"pl\",\n",
      "    \"simple\",\n",
      "    \"fa\",\n",
      "    \"vi\",\n",
      "    \"sv\",\n",
      "    \"ko\",\n",
      "    \"he\",\n",
      "    \"ro\",\n",
      "    \"no\",\n",
      "    \"hi\",\n",
      "    \"uk\",\n",
      "    \"cs\",\n",
      "    \"fi\",\n",
      "    \"hu\",\n",
      "    \"th\",\n",
      "    \"da\",\n",
      "    \"ca\",\n",
      "    \"el\",\n",
      "    \"bg\",\n",
      "    \"sr\",\n",
      "    \"ms\",\n",
      "    \"bn\",\n",
      "    \"hr\",\n",
      "    \"sl\",\n",
      "    \"zh_yue\",\n",
      "    \"az\",\n",
      "    \"sk\",\n",
      "    \"eo\",\n",
      "    \"ta\",\n",
      "    \"sh\",\n",
      "    \"lt\",\n",
      "    \"et\",\n",
      "    \"ml\",\n",
      "    \"la\",\n",
      "    \"bs\",\n",
      "    \"sq\",\n",
      "    \"arz\",\n",
      "    \"af\",\n",
      "    \"ka\",\n",
      "    \"mr\",\n",
      "    \"eu\",\n",
      "    \"tl\",\n",
      "    \"ang\",\n",
      "    \"gl\",\n",
      "    \"nn\",\n",
      "    \"ur\",\n",
      "    \"kk\",\n",
      "    \"be\",\n",
      "    \"hy\",\n",
      "    \"te\",\n",
      "    \"lv\",\n",
      "    \"mk\",\n",
      "    \"zh_classical\",\n",
      "    \"als\",\n",
      "    \"is\",\n",
      "    \"wuu\",\n",
      "    \"my\",\n",
      "    \"sco\",\n",
      "    \"mn\",\n",
      "    \"ceb\",\n",
      "    \"ast\",\n",
      "    \"cy\",\n",
      "    \"kn\",\n",
      "    \"br\",\n",
      "    \"an\",\n",
      "    \"gu\",\n",
      "    \"bar\",\n",
      "    \"uz\",\n",
      "    \"lb\",\n",
      "    \"ne\",\n",
      "    \"si\",\n",
      "    \"war\",\n",
      "    \"jv\",\n",
      "    \"ga\",\n",
      "    \"zh_min_nan\",\n",
      "    \"oc\",\n",
      "    \"ku\",\n",
      "    \"sw\",\n",
      "    \"nds\",\n",
      "    \"ckb\",\n",
      "    \"ia\",\n",
      "    \"yi\",\n",
      "    \"fy\",\n",
      "    \"scn\",\n",
      "    \"gan\",\n",
      "    \"tt\",\n",
      "    \"am\"\n",
      "  ],\n",
      "  \"mt_steps\": [],\n",
      "  \"multi_gpu\": true,\n",
      "  \"multi_node\": true,\n",
      "  \"n_gpu_per_node\": 8,\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 100,\n",
      "  \"n_layers\": 16,\n",
      "  \"n_nodes\": 4,\n",
      "  \"node_id\": 0,\n",
      "  \"optimizer\": \"adam_inverse_sqrt,lr=0.00005,warmup_updates=30000,beta1=0.9,beta2=0.999,weight_decay=0.01,eps=0.000001\",\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"para_dataset\": {},\n",
      "  \"para_list\": [],\n",
      "  \"pc_steps\": [],\n",
      "  \"ref_paths\": {},\n",
      "  \"reload_checkpoint\": \"\",\n",
      "  \"reload_emb\": \"\",\n",
      "  \"reload_model\": \"/checkpoint/aconneau/dumped/xlm_17_100_240_big_model_upper.2/14884511/best-valid_zh_mlm_ppl.pth\",\n",
      "  \"sample_alpha\": 0.5,\n",
      "  \"save_periodic\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"split_data\": true,\n",
      "  \"start_n_top\": 5,\n",
      "  \"stopping_criterion\": \"_valid_zh_mlm_ppl,25\",\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": false,\n",
      "  \"use_memory\": false,\n",
      "  \"validation_metrics\": \"_valid_en_mlm_ppl,_valid_mlm_ppl,_valid_zh_mlm_ppl\",\n",
      "  \"vocab_size\": 200000,\n",
      "  \"word_blank\": 0.0,\n",
      "  \"word_dropout\": 0.0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0.0,\n",
      "  \"world_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/xlm-mlm-100-1280/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/5ba8c43e22aeb247eee7a4d27014eabe361cbfd2a9e00bd337946aaa0dece8ce.f11dc7ef5f30811d164556022e3174da0d6e8bb13676833dabdb1f50f61f39a5\n",
      "Some weights of the model checkpoint at xlm-mlm-100-1280 were not used when initializing XLMModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of XLMModel were initialized from the model checkpoint at xlm-mlm-100-1280.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Didn't find file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer.json. We won't load it.\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/spiece.model\n",
      "loading file None\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/added_tokens.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/special_tokens_map.json\n",
      "loading file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/tokenizer_config.json\n",
      "Adding <pad> to the vocabulary\n",
      "loading configuration file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/config.json\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2\",\n",
      "  \"architectures\": [\n",
      "    \"AlbertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing AlbertModel.\n",
      "\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at /s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/data_dir/ass_bert_new_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/spiece.model from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/97e976f62c951292c6fdb2bb5bf1f34f5450585dda98be8dedea2b97e4f25b86.5c8e83e7afe2b2faae1dc1a6b0fcdb911480df6af7079e9df53aa83ed0763de2\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/ai4bharat/indic-bert/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
      "Model config AlbertConfig {\n",
      "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 200000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.dense.weight', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of AlbertModel were initialized from the model checkpoint at ai4bharat/indic-bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/vocab.txt from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b97fc49fcc6c4b696e73d117cd105e9896633d546afdaa10fbdc2e3964b7ccce.6238bf3b1b7ad31c55bb4415faa9477a5f8e50723e8d1d70df19a65433db277f\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/special_tokens_map.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/290471f6a01c9af0dd0bcf02112dc77b9b0aee820ebb1fb023c96ac2dda9d8ef.750293617705dd39d21eef1e163d80ca5b23e1a0ec507fff24a087c44632142c\n",
      "loading file https://huggingface.co/google/muril-base-cased/resolve/main/tokenizer_config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/677de489a9460181a44c530abce89d7d341485a3d49dacc89a9b5a1fed34c328.94e1730f1b81d6fdf365e5e59d01a4e387286e650a02ed6512f3dba8668dd876\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/muril-base-cased/resolve/main/config.json from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/d8ca6ce642f067ecf3d1163f4d2903b471287613933f2857ca8307e500bc7645.aff1657f5771205f5a0c6cb4816f125ee5f2f2d62dbf27e6b9fee30b0ebbf0f5\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/muril-base-cased/resolve/main/pytorch_model.bin from cache at /s/chopin/b/grad/abhijnan/.cache/huggingface/transformers/b4704f25323c21eafa8f1b6196e294d7252e11aa35d082c49d6ae62f3ca168dd.767d38e2461040f361197f7fc27e1968320609d399f194178c3adb49eeeb8ca9\n",
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at google/muril-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8\n",
      "Got 112\n",
      "Got 208\n",
      "Got 312\n",
      "Got 408\n",
      "Got 512\n",
      "Got 608\n",
      "Got 712\n",
      "Got 808\n",
      "Got 912\n",
      "Got 1008\n",
      "Got 1112\n",
      "Got 1208\n",
      "Got 1312\n",
      "Got 1408\n",
      "Got 1512\n",
      "Got 1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mbert_cos = get_mbert_cos_sims(list(ass_ben_test['loan_word']),list(ass_ben_test['original_word']))\n",
    "xlm_cos = get_xlm_cos_sims(list(ass_ben_test['loan_word']),list(ass_ben_test['original_word']))\n",
    "ass_bert_cos = get_ass_albert_cos_sims(list(ass_ben_test['loan_word']),list(ass_ben_test['original_word']), lin_transform =True)\n",
    "indic_bert_cos = Indic_bert_cos_sims(list(ass_ben_test['loan_word']),list(ass_ben_test['original_word']))\n",
    "muril_cos = Muril_cos_sims(list(ass_ben_test['loan_word']),list(ass_ben_test['original_word']))\n",
    " \n",
    "# ass_ben_test['mbert_cos'] = mbert_cos\n",
    "# ass_ben_test['xlm_cos'] = xlm_cos\n",
    "# ass_ben_test['ass_bert_mbert_cos'] = ass_bert_cos\n",
    "# ass_ben_test['indic_bert_cos'] = indic_bert_cos\n",
    "# ass_ben_test['muril_cos'] = muril_cos   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da7af5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert (1700, 768) (1700, 768) <class 'numpy.ndarray'>\n",
      "xlm (1700, 1280) (1700, 1280) <class 'numpy.ndarray'>\n",
      "ass_bert (1700, 768) (1700, 768) <class 'numpy.ndarray'>\n",
      "indic_bert (1700, 768) (1700, 768) <class 'numpy.ndarray'>\n",
      "muril (1700, 768) (1700, 768) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i, j in all_vec.items():\n",
    "    print(i,j['loan'].shape, j['original'].shape, type(j['original']))\n",
    "# all_vec['mbert']['loan'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3df06606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768)\n"
     ]
    }
   ],
   "source": [
    "# get the linear transformation from mbert space to ass_bert space using the precalculated transformation matrix i.e beng_m_bertvec, ass_bertvec\n",
    "#for ass_ben_test\n",
    "m = sklearn.linear_model.Ridge(fit_intercept=False).fit(beng_m_bertvec, ass_bertvec) \n",
    "m = m.coef_ \n",
    "print(m.shape) #this is the 768 by 768 transformation matrix between mbert and assbert \n",
    "mapped_= all_vec['mbert']['loan'] @ m.transpose()\n",
    "ass_beng_test_cos_mapped = get_cosine_similarities(mapped_, all_vec['ass_bert']['original'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12eae1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>loan_word_epitran</th>\n",
       "      <th>original_word_epitran</th>\n",
       "      <th>loan_english</th>\n",
       "      <th>...</th>\n",
       "      <th>ass_bertmuril</th>\n",
       "      <th>indic_bertmbert</th>\n",
       "      <th>indic_bertxlm</th>\n",
       "      <th>indic_bertass_bert</th>\n",
       "      <th>indic_bertmuril</th>\n",
       "      <th>murilmbert</th>\n",
       "      <th>murilxlm</th>\n",
       "      <th>murilass_bert</th>\n",
       "      <th>murilindic_bert</th>\n",
       "      <th>mbert_src_assbert_trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>আজি</td>\n",
       "      <td>দাঁত</td>\n",
       "      <td>azi</td>\n",
       "      <td>d̪ãt̪ɔ</td>\n",
       "      <td>today</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999816</td>\n",
       "      <td>0.995245</td>\n",
       "      <td>0.984364</td>\n",
       "      <td>-0.037255</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.998842</td>\n",
       "      <td>0.998491</td>\n",
       "      <td>-0.037662</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.003580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>424</td>\n",
       "      <td>424</td>\n",
       "      <td>বস্তু</td>\n",
       "      <td>ভক্তি</td>\n",
       "      <td>bɔxtu</td>\n",
       "      <td>bʱɔkt̪i</td>\n",
       "      <td>Objects</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.998458</td>\n",
       "      <td>0.995757</td>\n",
       "      <td>-0.037769</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.998917</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>-0.037490</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.134114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>গোসাঁই</td>\n",
       "      <td>কলা</td>\n",
       "      <td>gʊxãi</td>\n",
       "      <td>kɔla</td>\n",
       "      <td>Gosain</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997764</td>\n",
       "      <td>0.995150</td>\n",
       "      <td>0.983945</td>\n",
       "      <td>-0.036948</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.996424</td>\n",
       "      <td>-0.037293</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.081233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "      <td>শ্রী</td>\n",
       "      <td>অশোত</td>\n",
       "      <td>xɹi</td>\n",
       "      <td>oʃot̪</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.997368</td>\n",
       "      <td>0.994264</td>\n",
       "      <td>-0.035945</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.998593</td>\n",
       "      <td>0.997663</td>\n",
       "      <td>-0.036670</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.063111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>ডাঁহ</td>\n",
       "      <td>ডাঁশ</td>\n",
       "      <td>dãɦɔ</td>\n",
       "      <td>ɖãʃɔ</td>\n",
       "      <td>Duck</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>0.995704</td>\n",
       "      <td>0.991231</td>\n",
       "      <td>-0.036069</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.998209</td>\n",
       "      <td>0.997781</td>\n",
       "      <td>-0.036462</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.116244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1695</td>\n",
       "      <td>1695</td>\n",
       "      <td>1695</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>লাজ</td>\n",
       "      <td>লজ্জা</td>\n",
       "      <td>laz</td>\n",
       "      <td>lɔd͡ʑd͡ʑa</td>\n",
       "      <td>Shame</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.993459</td>\n",
       "      <td>-0.037235</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>-0.037537</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.099490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>1696</td>\n",
       "      <td>1696</td>\n",
       "      <td>1696</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>অক্ষ</td>\n",
       "      <td>অক্ষি</td>\n",
       "      <td>ɔkʰjɔ</td>\n",
       "      <td>okkʰi</td>\n",
       "      <td>Axis</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999457</td>\n",
       "      <td>0.994719</td>\n",
       "      <td>0.988365</td>\n",
       "      <td>-0.036510</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.998698</td>\n",
       "      <td>0.997802</td>\n",
       "      <td>-0.037324</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.043864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>1697</td>\n",
       "      <td>1697</td>\n",
       "      <td>1697</td>\n",
       "      <td>586</td>\n",
       "      <td>586</td>\n",
       "      <td>চাঁদ</td>\n",
       "      <td>দাঁত</td>\n",
       "      <td>sãdɔ</td>\n",
       "      <td>d̪ãt̪ɔ</td>\n",
       "      <td>The moon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.997607</td>\n",
       "      <td>0.996476</td>\n",
       "      <td>-0.036991</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.998912</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>-0.037662</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.170446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>1698</td>\n",
       "      <td>1698</td>\n",
       "      <td>1698</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>সঁচা</td>\n",
       "      <td>বাজ</td>\n",
       "      <td>xɔ̃sa</td>\n",
       "      <td>bad͡ʑ</td>\n",
       "      <td>true</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.997836</td>\n",
       "      <td>0.996538</td>\n",
       "      <td>-0.037763</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.998426</td>\n",
       "      <td>0.998303</td>\n",
       "      <td>-0.037575</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.083471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1699</td>\n",
       "      <td>1699</td>\n",
       "      <td>1699</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>ঘমা</td>\n",
       "      <td>ঘামা</td>\n",
       "      <td>gʱɔma</td>\n",
       "      <td>gʱama</td>\n",
       "      <td>Sweat</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>0.995235</td>\n",
       "      <td>0.989131</td>\n",
       "      <td>-0.036336</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.998407</td>\n",
       "      <td>0.998010</td>\n",
       "      <td>-0.036879</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.019352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0              0             0               0                20   \n",
       "1              1             1               1               424   \n",
       "2              2             2               2                83   \n",
       "3              3             3               3               318   \n",
       "4              4             4               4               129   \n",
       "...          ...           ...             ...               ...   \n",
       "1695        1695          1695            1695               296   \n",
       "1696        1696          1696            1696                 7   \n",
       "1697        1697          1697            1697               586   \n",
       "1698        1698          1698            1698               327   \n",
       "1699        1699          1699            1699                88   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1 loan_word original_word loan_word_epitran  \\\n",
       "0                     20       আজি          দাঁত               azi   \n",
       "1                    424     বস্তু         ভক্তি             bɔxtu   \n",
       "2                     83    গোসাঁই           কলা             gʊxãi   \n",
       "3                    318      শ্রী          অশোত               xɹi   \n",
       "4                    129      ডাঁহ          ডাঁশ              dãɦɔ   \n",
       "...                  ...       ...           ...               ...   \n",
       "1695                 296       লাজ         লজ্জা               laz   \n",
       "1696                   7      অক্ষ         অক্ষি             ɔkʰjɔ   \n",
       "1697                 586      চাঁদ          দাঁত              sãdɔ   \n",
       "1698                 327      সঁচা           বাজ             xɔ̃sa   \n",
       "1699                  88       ঘমা          ঘামা             gʱɔma   \n",
       "\n",
       "     original_word_epitran loan_english  ... ass_bertmuril  indic_bertmbert  \\\n",
       "0                   d̪ãt̪ɔ        today  ...      0.999816         0.995245   \n",
       "1                  bʱɔkt̪i      Objects  ...      0.999737         0.998458   \n",
       "2                     kɔla       Gosain  ...      0.997764         0.995150   \n",
       "3                    oʃot̪          Mr.  ...      0.999268         0.997368   \n",
       "4                     ɖãʃɔ         Duck  ...      0.999721         0.995704   \n",
       "...                    ...          ...  ...           ...              ...   \n",
       "1695             lɔd͡ʑd͡ʑa        Shame  ...      0.999359         0.997234   \n",
       "1696                 okkʰi         Axis  ...      0.999457         0.994719   \n",
       "1697                d̪ãt̪ɔ     The moon  ...      0.999868         0.997607   \n",
       "1698                 bad͡ʑ         true  ...      0.998944         0.997836   \n",
       "1699                 gʱama        Sweat  ...      0.999729         0.995235   \n",
       "\n",
       "      indic_bertxlm  indic_bertass_bert  indic_bertmuril  murilmbert  \\\n",
       "0          0.984364           -0.037255         0.999860    0.998842   \n",
       "1          0.995757           -0.037769         0.999962    0.998917   \n",
       "2          0.983945           -0.036948         0.999825    0.997333   \n",
       "3          0.994264           -0.035945         0.999937    0.998593   \n",
       "4          0.991231           -0.036069         0.999895    0.998209   \n",
       "...             ...                 ...              ...         ...   \n",
       "1695       0.993459           -0.037235         0.999956    0.998167   \n",
       "1696       0.988365           -0.036510         0.999899    0.998698   \n",
       "1697       0.996476           -0.036991         0.999951    0.998912   \n",
       "1698       0.996538           -0.037763         0.999941    0.998426   \n",
       "1699       0.989131           -0.036336         0.999837    0.998407   \n",
       "\n",
       "      murilxlm  murilass_bert murilindic_bert mbert_src_assbert_trg  \n",
       "0     0.998491      -0.037662        0.999918              0.003580  \n",
       "1     0.998437      -0.037490        0.999925              0.134114  \n",
       "2     0.996424      -0.037293        0.999829              0.081233  \n",
       "3     0.997663      -0.036670        0.999940              0.063111  \n",
       "4     0.997781      -0.036462        0.999917              0.116244  \n",
       "...        ...            ...             ...                   ...  \n",
       "1695  0.997904      -0.037537        0.999868              0.099490  \n",
       "1696  0.997802      -0.037324        0.999946              0.043864  \n",
       "1697  0.998486      -0.037662        0.999921              0.170446  \n",
       "1698  0.998303      -0.037575        0.999887              0.083471  \n",
       "1699  0.998010      -0.036879        0.999918              0.019352  \n",
       "\n",
       "[1700 rows x 49 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ass_ben_test['mbert_src_assbert_trg'] = ass_beng_test_cos_mapped\n",
    "ass_ben_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c0f5a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbert xlm\n",
      "mbert ass_bert\n",
      "mbert indic_bert\n",
      "mbert muril\n",
      "xlm mbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.23923e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.4278e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm ass_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.23923e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.4278e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.23923e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm indic_bert\n",
      "xlm muril\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.4278e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.23923e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.4278e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert mbert\n",
      "ass_bert xlm\n",
      "ass_bert indic_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.23287e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.23287e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.23287e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ass_bert muril\n",
      "indic_bert mbert\n",
      "indic_bert xlm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/d/proj/ramfis-aida/venv/lib64/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.23287e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indic_bert ass_bert\n",
      "indic_bert muril\n",
      "muril mbert\n",
      "muril xlm\n",
      "muril ass_bert\n",
      "muril indic_bert\n",
      "mbertxlm [0.7835372  0.8324632  0.7524152  ... 0.83098465 0.8068333  0.8784781 ]\n",
      "mbertass_bert [-0.02294929 -0.02864049 -0.04234096 ... -0.02772318 -0.035661\n",
      " -0.03385013]\n",
      "mbertindic_bert [0.99575704 0.99916756 0.996084   ... 0.9997469  0.99915326 0.998631  ]\n",
      "mbertmuril [0.99969953 0.99971086 0.997231   ... 0.9998252  0.9987678  0.9994286 ]\n",
      "xlmmbert [0.8258198  0.8333431  0.76705796 ... 0.7853576  0.9124824  0.95633495]\n",
      "xlmass_bert [-0.02109283 -0.02265036 -0.04356567 ... -0.02540999 -0.03646286\n",
      " -0.02866849]\n",
      "xlmindic_bert [0.9954077  0.9984507  0.99488956 ... 0.99955475 0.9991399  0.99553984]\n",
      "xlmmuril [0.9996149  0.9997564  0.99652153 ... 0.9997771  0.99840975 0.99922234]\n",
      "ass_bertmbert [0.87931776 0.942175   0.82123417 ... 0.8644617  0.9282237  0.9772395 ]\n",
      "ass_bertxlm [0.8653891  0.88182724 0.7863366  ... 0.8756689  0.8359395  0.96302044]\n",
      "ass_bertindic_bert [0.998331   0.99960446 0.9974607  ... 0.9995295  0.9993796  0.99899477]\n",
      "ass_bertmuril [0.99981576 0.99973726 0.99776447 ... 0.999868   0.99894446 0.99972934]\n",
      "indic_bertmbert [0.99524486 0.9984577  0.9951499  ... 0.9976066  0.99783623 0.9952351 ]\n",
      "indic_bertxlm [0.9843641  0.9957572  0.9839449  ... 0.9964763  0.9965382  0.98913074]\n",
      "indic_bertass_bert [-0.03725499 -0.0377688  -0.0369476  ... -0.03699121 -0.03776292\n",
      " -0.0363365 ]\n",
      "indic_bertmuril [0.9998599  0.9999622  0.9998254  ... 0.9999508  0.99994123 0.99983716]\n",
      "murilmbert [0.99884164 0.99891746 0.9973332  ... 0.99891174 0.9984257  0.99840724]\n",
      "murilxlm [0.9984909  0.99843657 0.9964235  ... 0.9984859  0.9983027  0.9980104 ]\n",
      "murilass_bert [-0.03766162 -0.03748998 -0.03729313 ... -0.03766231 -0.03757496\n",
      " -0.03687856]\n",
      "murilindic_bert [0.999918  0.9999249 0.9998285 ... 0.9999214 0.9998865 0.9999177]\n"
     ]
    }
   ],
   "source": [
    "cos_mapped = get_lt_maps(all_vec) # get the mapped embeddings and cosine sims for ass_ben_test\n",
    "for i, j  in cos_mapped.items():\n",
    "    print(i,j)\n",
    "    \n",
    "    ass_ben_test[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d5f0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "ben_ass_train.to_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Bengali-Assamese-train_production_alldata.csv')\n",
    "ass_ben_train.to_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Assamese-Bengali-train_production_alldata.csv')\n",
    "ben_ass_test.to_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Bengali-Assamese-test_production_alldata.csv')\n",
    "ass_ben_test.to_csv('/s/chopin/d/proj/ramfis-aida/loan_exp_results/loan-word-detection/Datasets/Assamese_Bert_dataset/Assamese-Bengali-test_production_alldata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcffe48",
   "metadata": {},
   "source": [
    "# Load `language-pairs.json` list and run pipeline for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44a4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9700120",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f: # for getting logits from all languages\n",
    " \n",
    "    \n",
    "    pairs = json.loads(f.read())\n",
    "for pair in pairs:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs-holdout.json', 'r') as f: # for getting logits from all languages\n",
    " \n",
    "    \n",
    "    pairs = json.loads(f.read())\n",
    "for pair in pairs:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231fcdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f:\n",
    "    pairs = json.loads(f.read())\n",
    "\n",
    "for pair in pairs:\n",
    "    print(pair)\n",
    "    L1 = pairs[pair]['target']['name']\n",
    "    L2 = pairs[pair]['source']['name']\n",
    "    \n",
    "    # load datasets\n",
    "    prefix = f'../Datasets/production_train_test/{L1}-{L2}'\n",
    "    \n",
    "    train_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata.csv')\n",
    "    test_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata.csv')\n",
    "\n",
    "    train_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    test_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')\n",
    "\n",
    "    # get and pad PanPhon features for alldata split\n",
    "    get_panphon_features(train_alldata, test_alldata)\n",
    "    alldata_maxlen = (max(np.max(train_alldata['features_loan'].str.len()),\\\n",
    "                          np.max(test_alldata['features_loan'].str.len())),\\\n",
    "                      max(np.max(train_alldata['features_orig'].str.len()),\\\n",
    "                          np.max(test_alldata['features_orig'].str.len())))\n",
    "    pad_panphon_features(train_alldata, test_alldata, alldata_maxlen)\n",
    "\n",
    "    # add target labels\n",
    "    Y_train, Y_test = add_target_labels(train_alldata, test_alldata)\n",
    "\n",
    "    # make train and val splits\n",
    "    X_train, X_val, X_test, Y_train, Y_val = make_train_val_set(train_alldata, test_alldata, Y_train)\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test)\n",
    "\n",
    "    # instantiate network\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\nUsing {device} device\\n\")\n",
    "    \n",
    "    # set random seeds for reproducibility\n",
    "    np.random.seed(666)\n",
    "\n",
    "    model = NeuralNetwork(X_train.shape[1]).to(device)\n",
    "    print(model,\"\\n\")\n",
    "\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "    # train and plot losses, accuracy\n",
    "    train_losses, val_losses, train_accur, val_accur = \\\n",
    "        model.fit(X_train, Y_train, X_val, Y_val, criterion, optimizer)\n",
    "    model.plot_losses(train_losses,val_losses,train_accur,val_accur)\n",
    "\n",
    "    # get and pad PanPhon features for realdist and balanced splits\n",
    "    get_panphon_features(train_realdist,test_realdist)\n",
    "    pad_panphon_features(train_realdist,test_realdist,alldata_maxlen)\n",
    "\n",
    "    get_panphon_features(train_balanced,test_balanced)\n",
    "    pad_panphon_features(train_balanced,test_balanced,alldata_maxlen)\n",
    "\n",
    "    # create data to get logits for\n",
    "    X_train_alldata = torch.tensor(np.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                         np.array([x for x in train_alldata['features_orig']])])).to(device)\n",
    "    X_test_alldata = torch.tensor(np.hstack([np.array([x for x in test_alldata['features_loan']]),\\\n",
    "                        np.array([x for x in test_alldata['features_orig']])])).to(device)\n",
    "\n",
    "    X_train_realdist = torch.tensor(np.hstack([np.array([x for x in train_realdist['features_loan']]),\\\n",
    "                         np.array([x for x in train_realdist['features_orig']])])).to(device)\n",
    "    X_test_realdist = torch.tensor(np.hstack([np.array([x for x in test_realdist['features_loan']]),\\\n",
    "                        np.array([x for x in test_realdist['features_orig']])])).to(device)\n",
    "\n",
    "    X_train_balanced = torch.tensor(np.hstack([np.array([x for x in train_balanced['features_loan']]),\\\n",
    "                         np.array([x for x in train_balanced['features_orig']])])).to(device)\n",
    "    X_test_balanced = torch.tensor(np.hstack([np.array([x for x in test_balanced['features_loan']]),\\\n",
    "                        np.array([x for x in test_balanced['features_orig']])])).to(device)\n",
    "\n",
    "    # place model in eval mode and get logits from DNN for all datasets/splits\n",
    "    print(\"Getting logits from DNN\")\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_logits_dnn_alldata = model(X_train_alldata.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_alldata = model(X_test_alldata.float())[1].detach().cpu().numpy()\n",
    "        train_logits_dnn_realdist = model(X_train_realdist.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_realdist = model(X_test_realdist.float())[1].detach().cpu().numpy()\n",
    "        train_logits_dnn_balanced = model(X_train_balanced.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_balanced = model(X_test_balanced.float())[1].detach().cpu().numpy()\n",
    "\n",
    "    # remove PanPhon features from dataframe and add logits column\n",
    "    train_alldata = train_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_alldata['DNN_logits'] = train_logits_dnn_alldata\n",
    "\n",
    "    test_alldata = test_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_alldata['DNN_logits'] = test_logits_dnn_alldata\n",
    "\n",
    "    train_realdist = train_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_realdist['DNN_logits'] = train_logits_dnn_realdist\n",
    "\n",
    "    test_realdist = test_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_realdist['DNN_logits'] = test_logits_dnn_realdist\n",
    "\n",
    "    train_balanced = train_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_balanced['DNN_logits'] = train_logits_dnn_balanced\n",
    "\n",
    "    test_balanced = test_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_balanced['DNN_logits'] = test_logits_dnn_balanced\n",
    "\n",
    "    #set the seeds for reproducibility even though we are not fine-tuning or training and the weights \n",
    "    #for both these models are effectively frozen for our purpose \n",
    "    torch.manual_seed(7)\n",
    "    random.seed(7)\n",
    "    np.random.seed(7)\n",
    "\n",
    "    # Setting PyTorch's required configuration variables for reproducibility.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "\n",
    "    PRE_TRAINED_bert_MODEL = 'bert-base-multilingual-cased'\n",
    "    PRE_TRAINED_xlm_MODEL = 'xlm-mlm-100-1280'\n",
    "\n",
    "    MAXTOKENS = 5\n",
    "    BS = 8  # batch size\n",
    "\n",
    "    #list of loan-original words for train sets\n",
    "    l1_train_alldata = list(train_alldata[\"loan_word\"])\n",
    "    l2_train_alldata = list(train_alldata[\"original_word\"])\n",
    "\n",
    "    l1_train_realdist = list(train_realdist[\"loan_word\"])\n",
    "    l2_train_realdist = list(train_realdist[\"original_word\"])\n",
    "\n",
    "    l1_train_balanced = list(train_balanced[\"loan_word\"])\n",
    "    l2_train_balanced = list(train_balanced[\"original_word\"])\n",
    "\n",
    "    #list of loan-original words for test sets\n",
    "    l1_test_alldata = list(test_alldata[\"loan_word\"])\n",
    "    l2_test_alldata = list(test_alldata[\"original_word\"])\n",
    "\n",
    "    l1_test_realdist = list(test_realdist[\"loan_word\"])\n",
    "    l2_test_realdist = list(test_realdist[\"original_word\"])\n",
    "\n",
    "    l1_test_balanced = list(test_balanced[\"loan_word\"])\n",
    "    l2_test_balanced = list(test_balanced[\"original_word\"])\n",
    "\n",
    "    print(\"Getting MBERT similarities\")\n",
    "    train_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    test_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    train_realdist['MBERT_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    train_balanced['MBERT_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    test_realdist['MBERT_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    test_balanced['MBERT_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    print()\n",
    "    print(\"Getting XLM similarities\")\n",
    "    train_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    test_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    train_realdist['XLM_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    train_balanced['XLM_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "\n",
    "    test_realdist['XLM_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    test_balanced['XLM_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "        \n",
    "    train_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata.csv')\n",
    "    test_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata.csv')\n",
    "\n",
    "    train_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    test_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_test_alldata,l2_test_alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25016d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced['MBERT_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3363a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "print(train_realdist.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b372a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = None\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f: # for getting logits from all languages\n",
    " \n",
    "    \n",
    "    pairs = json.loads(f.read())\n",
    "\n",
    "for pair in pairs:\n",
    "    print(pair)\n",
    "    L1 = pairs[pair]['target']['name']\n",
    "    L2 = pairs[pair]['source']['name']\n",
    "    \n",
    "    # load datasets\n",
    "    prefix = f'../Datasets/production_train_test/{L1}-{L2}'\n",
    "    \n",
    "    train_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata.csv')\n",
    "    test_alldata = pd.read_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata.csv')\n",
    "\n",
    "    train_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    test_realdist = pd.read_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced = pd.read_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')\n",
    "\n",
    "    # get and pad PanPhon features for alldata split\n",
    "    get_panphon_features(train_alldata, test_alldata)\n",
    "    alldata_maxlen = (max(np.max(train_alldata['features_loan'].str.len()),\\\n",
    "                          np.max(test_alldata['features_loan'].str.len())),\\\n",
    "                      max(np.max(train_alldata['features_orig'].str.len()),\\\n",
    "                          np.max(test_alldata['features_orig'].str.len())))\n",
    "    pad_panphon_features(train_alldata, test_alldata, alldata_maxlen)\n",
    "\n",
    "    # add target labels\n",
    "    Y_train, Y_test = add_target_labels(train_alldata, test_alldata)\n",
    "\n",
    "    # make train and val splits\n",
    "    X_train, X_val, X_test, Y_train, Y_val = make_train_val_set(train_alldata, test_alldata, Y_train)\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = make_tensors(X_train, Y_train, X_val, Y_val, X_test, Y_test)\n",
    "\n",
    "    # instantiate network\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\nUsing {device} device\\n\")\n",
    "    \n",
    "    # set random seeds for reproducibility\n",
    "    np.random.seed(666)\n",
    "\n",
    "    model = NeuralNetwork(X_train.shape[1]).to(device)\n",
    "    print(model,\"\\n\")\n",
    "\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "    # train and plot losses, accuracy\n",
    "    train_losses, val_losses, train_accur, val_accur = \\\n",
    "        model.fit(X_train, Y_train, X_val, Y_val, criterion, optimizer)\n",
    "    model.plot_losses(train_losses,val_losses,train_accur,val_accur)\n",
    "\n",
    "    # get and pad PanPhon features for realdist and balanced splits\n",
    "    get_panphon_features(train_realdist,test_realdist)\n",
    "    pad_panphon_features(train_realdist,test_realdist,alldata_maxlen)\n",
    "\n",
    "    get_panphon_features(train_balanced,test_balanced)\n",
    "    pad_panphon_features(train_balanced,test_balanced,alldata_maxlen)\n",
    "\n",
    "    # create data to get logits for\n",
    "    X_train_alldata = torch.tensor(np.hstack([np.array([x for x in train_alldata['features_loan']]),\\\n",
    "                         np.array([x for x in train_alldata['features_orig']])])).to(device)\n",
    "    X_test_alldata = torch.tensor(np.hstack([np.array([x for x in test_alldata['features_loan']]),\\\n",
    "                        np.array([x for x in test_alldata['features_orig']])])).to(device)\n",
    "\n",
    "    X_train_realdist = torch.tensor(np.hstack([np.array([x for x in train_realdist['features_loan']]),\\\n",
    "                         np.array([x for x in train_realdist['features_orig']])])).to(device)\n",
    "    X_test_realdist = torch.tensor(np.hstack([np.array([x for x in test_realdist['features_loan']]),\\\n",
    "                        np.array([x for x in test_realdist['features_orig']])])).to(device)\n",
    "\n",
    "    X_train_balanced = torch.tensor(np.hstack([np.array([x for x in train_balanced['features_loan']]),\\\n",
    "                         np.array([x for x in train_balanced['features_orig']])])).to(device)\n",
    "    X_test_balanced = torch.tensor(np.hstack([np.array([x for x in test_balanced['features_loan']]),\\\n",
    "                        np.array([x for x in test_balanced['features_orig']])])).to(device)\n",
    "\n",
    "    # place model in eval mode and get logits from DNN for all datasets/splits\n",
    "    print(\"Getting logits from DNN\")\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_logits_dnn_alldata = model(X_train_alldata.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_alldata = model(X_test_alldata.float())[1].detach().cpu().numpy()\n",
    "        train_logits_dnn_realdist = model(X_train_realdist.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_realdist = model(X_test_realdist.float())[1].detach().cpu().numpy()\n",
    "        train_logits_dnn_balanced = model(X_train_balanced.float())[1].detach().cpu().numpy()\n",
    "        test_logits_dnn_balanced = model(X_test_balanced.float())[1].detach().cpu().numpy()\n",
    "\n",
    "    # remove PanPhon features from dataframe and add logits column\n",
    "    train_alldata = train_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_alldata['DNN_logits'] = train_logits_dnn_alldata\n",
    "\n",
    "    test_alldata = test_alldata.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_alldata['DNN_logits'] = test_logits_dnn_alldata\n",
    "\n",
    "    train_realdist = train_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_realdist['DNN_logits'] = train_logits_dnn_realdist\n",
    "\n",
    "    test_realdist = test_realdist.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_realdist['DNN_logits'] = test_logits_dnn_realdist\n",
    "\n",
    "    train_balanced = train_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    train_balanced['DNN_logits'] = train_logits_dnn_balanced\n",
    "\n",
    "    test_balanced = test_balanced.drop(['features_loan','features_orig'], axis=1)\n",
    "    test_balanced['DNN_logits'] = test_logits_dnn_balanced\n",
    "\n",
    "    #set the seeds for reproducibility even though we are not fine-tuning or training and the weights \n",
    "    #for both these models are effectively frozen for our purpose \n",
    "    torch.manual_seed(7)\n",
    "    random.seed(7)\n",
    "    np.random.seed(7)\n",
    "\n",
    "    # Setting PyTorch's required configuration variables for reproducibility.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "\n",
    "    PRE_TRAINED_bert_MODEL = 'bert-base-multilingual-cased'\n",
    "    PRE_TRAINED_xlm_MODEL = 'xlm-mlm-100-1280'\n",
    "\n",
    "    MAXTOKENS = 5\n",
    "    MAXTOKENS_XLM = 9\n",
    "    BS = 8  # batch size\n",
    "\n",
    "    #list of loan-original words for train sets\n",
    "    l1_train_alldata = list(train_alldata[\"loan_word\"])\n",
    "    l2_train_alldata = list(train_alldata[\"original_word\"])\n",
    "\n",
    "    l1_train_realdist = list(train_realdist[\"loan_word\"])\n",
    "    l2_train_realdist = list(train_realdist[\"original_word\"])\n",
    "\n",
    "    l1_train_balanced = list(train_balanced[\"loan_word\"])\n",
    "    l2_train_balanced = list(train_balanced[\"original_word\"])\n",
    "\n",
    "    #list of loan-original words for test sets\n",
    "    l1_test_alldata = list(test_alldata[\"loan_word\"])\n",
    "    l2_test_alldata = list(test_alldata[\"original_word\"])\n",
    "\n",
    "    l1_test_realdist = list(test_realdist[\"loan_word\"])\n",
    "    l2_test_realdist = list(test_realdist[\"original_word\"])\n",
    "\n",
    "    l1_test_balanced = list(test_balanced[\"loan_word\"])\n",
    "    l2_test_balanced = list(test_balanced[\"original_word\"])\n",
    "\n",
    "    print(\"Getting MBERT similarities\")\n",
    "    train_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    test_alldata['MBERT_cos_sim'] = get_mbert_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    train_realdist['MBERT_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    train_balanced['MBERT_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    test_realdist['MBERT_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "    test_balanced['MBERT_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['MBERT_cos_sim']\n",
    "\n",
    "    print()\n",
    "    print(\"Getting XLM similarities\")\n",
    "    train_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_train_alldata,l2_train_alldata)\n",
    "    test_alldata['XLM_cos_sim'] = get_xlm_cos_sims(l1_test_alldata,l2_test_alldata)\n",
    "\n",
    "    train_realdist['XLM_cos_sim'] = train_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    train_balanced['XLM_cos_sim'] = train_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                           on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "\n",
    "    test_realdist['XLM_cos_sim'] = test_realdist.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "    test_balanced['XLM_cos_sim'] = test_balanced.merge(pd.concat([train_alldata,test_alldata]),\\\n",
    "                                                         on=['loan_word','original_word'], how=\"left\")['XLM_cos_sim']\n",
    "        \n",
    "    train_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-train_production_alldata.csv')\n",
    "    test_alldata.to_csv(f'{prefix}/alldata/{L1}-{L2}-test_production_alldata.csv')\n",
    "\n",
    "    train_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-train_production_realdist.csv')\n",
    "    test_realdist.to_csv(f'{prefix}/realdist/{L1}-{L2}-test_production_realdist.csv')\n",
    "\n",
    "    train_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-train_production_balanced.csv')\n",
    "    test_balanced.to_csv(f'{prefix}/balanced/{L1}-{L2}-test_production_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c96c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
