{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hindi-Persian': 'https://en.m.wiktionary.org/wiki/Category:Hindi_terms_borrowed_from_Persian',\n",
       " 'English-French': 'https://en.m.wiktionary.org/wiki/Category:English_terms_borrowed_from_French'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = {}\n",
    "\n",
    "with open('../language-pairs.json', 'r') as f:\n",
    "    pairs = json.loads(f.read())\n",
    "    \n",
    "    for pair in pairs:\n",
    "        links[pair] = pairs[pair]['wiki']\n",
    "\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_link = \"https://en.m.wiktionary.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_ipas(dest_lang, src_lang, link, page_num, lst_invalid_words=['plural', 'not comparable']):\n",
    "    borrowed_words = []\n",
    "\n",
    "    try:\n",
    "        # get list of words\n",
    "        page = requests.get(link)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        res = soup.find_all(\"div\", class_=\"mw-category-group\")\n",
    "\n",
    "        for i, r in enumerate(res):\n",
    "            if i > 0:\n",
    "                list_words = r.find_all('a')\n",
    "                src_word = None\n",
    "\n",
    "                for borrowed_word in list_words:\n",
    "\n",
    "                    # for each loaned word get the wiki link and extract ipas for it.\n",
    "                    ipa_page = requests.get(base_link + borrowed_word['href'])\n",
    "                    ipa_soup = BeautifulSoup(ipa_page.content, 'html.parser')\n",
    "\n",
    "\n",
    "                    # get the src word and wiki link to extract ipas for the src word\n",
    "                    src_word_html_final = None\n",
    "                    for header in ipa_soup.find_all(\"span\", class_=\"mw-headline\"):\n",
    "                        if re.match(\"Etymology [1-9]\",header.text):\n",
    "                            try:\n",
    "                                if dest_lang == header.parent.parent.find_previous_siblings()[0].find_all(\"span\", class_=\"mw-headline\")[0].text:\n",
    "                                    if len(header.parent.find_next_siblings()) > 0:\n",
    "                                        if len(header.parent.find_next_siblings()[0].find_all(\"span\", class_=\"etyl\")) > 0:\n",
    "                                            etym = header.parent.find_next_siblings()[0].find_all(\"span\", class_=\"etyl\")[0]\n",
    "                                            for tag in etym.find(lambda tag: tag.name == 'a'):\n",
    "                                                if src_lang.lower() not in tag.text.lower():\n",
    "                                                    src_word_html_final = etym.find_next(\"i\")\n",
    "                                                    meaning = header.parent.find_next_siblings('ol')[0].text.split('\\n')[0]\n",
    "                                                    meaning = re.sub(r'\\(.+?\\)',r'',meaning)\n",
    "                                                    meaning = re.sub(r'\\[.+?\\]',r'',meaning)\n",
    "                                                    meaning = meaning.replace('  ', ' ')\n",
    "                                                    meaning = re.split('[.;:]',meaning)[0].strip()\n",
    "                                                    src_word = src_word_html_final.text if src_word_html_final != None else ''\n",
    "                                                    src_word = re.split('[,;:]',src_word)[0].strip()\n",
    "                                                    if src_word in lst_invalid_words:\n",
    "                                                        src_word_html_final = etym.find_next(\"strong\")\n",
    "                                                        src_word = src_word_html_final.text if src_word_html_final != None else ''\n",
    "                                                        src_word = re.split('[,;:]',src_word)[0].strip()\n",
    "\n",
    "\n",
    "                                                    #if len(borrowed_words) == 0 or \\\n",
    "                                                    #    borrowed_word.text != borrowed_words[-1][0]:\n",
    "                                                    print(borrowed_word.text,src_word,tag.text.lower(),meaning)\n",
    "                                                    borrowed_words.append([borrowed_word.text,src_word,tag.text.lower(),meaning]) \n",
    "                            except:\n",
    "                                pass\n",
    "                                            \n",
    "        print(dest_lang, src_lang, page_num, \"done\", len(borrowed_words), \"\\n\")\n",
    "        # return borrowed_words      \n",
    "        # find whether there is a next page containing more loan words if there is scrape that as well. \n",
    "        next_link = soup.find(\n",
    "            lambda tag: tag.name == 'a' and 'next page' in tag.text.lower()\n",
    "        )\n",
    "\n",
    "        # return borrowed_words\n",
    "        if next_link != None:\n",
    "            more_words = get_words_ipas(dest_lang, src_lang, base_link + next_link['href'], page_num+1)\n",
    "            borrowed_words = borrowed_words + more_words\n",
    "\n",
    "    except Exception as e:\n",
    "        # errors can be due to timeouts/connections refused due to rate limiting. can be fixed via proxies/vpns/timeouts\n",
    "        print(pair, page_num, \"got error\", e, len(borrowed_words))\n",
    "        return borrowed_words\n",
    "        \n",
    "    return borrowed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-a- Jak middle english Connective interfix used in forming compounds, often no longer carrying a distinct meaning\n",
      "-a- Exmoor Scolding middle english And\n",
      "abandon abandounen middle english To give up or relinquish control of, to surrender or to give oneself over, or to yield to one's emotions\n",
      "Acre Acre portuguese A state of the North Region, Brazil\n",
      "Acre Aakre norwegian A surname​\n",
      "English French 1 done 5 \n",
      "\n",
      "anime アニメ japanese An artistic style originating in, and associated with, Japanese animation, and that has also been adopted by a comparatively low number of animated works from other countries\n",
      "Annam An Nam vietnamese A former colonial province of China, now part of Vietnam's present-day Tonkin\n",
      "annex annexen middle english To add something to another thing, especially territory\n",
      "arbor arbour middle english A shady sitting place or pergola usually in a park or garden, surrounded by climbing shrubs, vines or other vegetation\n",
      "Aries aries latin A constellation of the zodiac supposedly shaped like a ram\n",
      "aval avus latin Of, related to, or characteristic of a grandparent\n",
      "back bak middle english At or near the rear\n",
      "English French 2 done 7 \n",
      "\n",
      "bail baille middle english Security, usually a sum of money, exchanged for the release of an arrested person as a guarantee of that person's appearance for trial\n",
      "bail beyl middle english A hoop, ring or handle\n",
      "bandy bandy scots Bowlegged, or bending outward at the knees\n",
      "bandy bando welsh A winter sport played on ice, from which ice hockey developed\n",
      "bandy bandy telugu A carriage or cart used in India, especially one drawn by bullocks\n",
      "bat natt-batta swedish Any of the flying mammals of the order Chiroptera, usually small and nocturnal, insectivorous or frugivorous\n",
      "bat bat middle english A club made of wood or aluminium used for striking the ball in sports such as baseball, softball and cricket\n",
      "English French 3 done 7 \n",
      "\n",
      "bijou bijou sabir small, little\n",
      "Blon Блонь belarusian A settlement in Belarus\n",
      "bombard bombard middle english a medieval primitive cannon, used chiefly in sieges for throwing heavy stone balls\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000004?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000004?line=5'>6</a>\u001b[0m [dest, src] \u001b[39m=\u001b[39m pair\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000004?line=6'>7</a>\u001b[0m words \u001b[39m=\u001b[39m get_words_ipas(dest, src, links[pair], \u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000004?line=7'>8</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(words, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mloan_word\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moriginal_word\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mother_etymology\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mother_meaning\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000004?line=8'>9</a>\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mresults/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_false_friends.csv\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(pair), index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb Cell 4'\u001b[0m in \u001b[0;36mget_words_ipas\u001b[0;34m(dest_lang, src_lang, link, page_num, lst_invalid_words)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=60'>61</a>\u001b[0m     \u001b[39m# return borrowed_words\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=61'>62</a>\u001b[0m     \u001b[39mif\u001b[39;00m next_link \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=62'>63</a>\u001b[0m         more_words \u001b[39m=\u001b[39m get_words_ipas(dest_lang, src_lang, base_link \u001b[39m+\u001b[39;49m next_link[\u001b[39m'\u001b[39;49m\u001b[39mhref\u001b[39;49m\u001b[39m'\u001b[39;49m], page_num\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=63'>64</a>\u001b[0m         borrowed_words \u001b[39m=\u001b[39m borrowed_words \u001b[39m+\u001b[39m more_words\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=65'>66</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=66'>67</a>\u001b[0m     \u001b[39m# errors can be due to timeouts/connections refused due to rate limiting. can be fixed via proxies/vpns/timeouts\u001b[39;00m\n",
      "\u001b[1;32m/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb Cell 4'\u001b[0m in \u001b[0;36mget_words_ipas\u001b[0;34m(dest_lang, src_lang, link, page_num, lst_invalid_words)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=60'>61</a>\u001b[0m     \u001b[39m# return borrowed_words\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=61'>62</a>\u001b[0m     \u001b[39mif\u001b[39;00m next_link \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=62'>63</a>\u001b[0m         more_words \u001b[39m=\u001b[39m get_words_ipas(dest_lang, src_lang, base_link \u001b[39m+\u001b[39;49m next_link[\u001b[39m'\u001b[39;49m\u001b[39mhref\u001b[39;49m\u001b[39m'\u001b[39;49m], page_num\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=63'>64</a>\u001b[0m         borrowed_words \u001b[39m=\u001b[39m borrowed_words \u001b[39m+\u001b[39m more_words\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=65'>66</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=66'>67</a>\u001b[0m     \u001b[39m# errors can be due to timeouts/connections refused due to rate limiting. can be fixed via proxies/vpns/timeouts\u001b[39;00m\n",
      "\u001b[1;32m/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb Cell 4'\u001b[0m in \u001b[0;36mget_words_ipas\u001b[0;34m(dest_lang, src_lang, link, page_num, lst_invalid_words)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=60'>61</a>\u001b[0m     \u001b[39m# return borrowed_words\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=61'>62</a>\u001b[0m     \u001b[39mif\u001b[39;00m next_link \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=62'>63</a>\u001b[0m         more_words \u001b[39m=\u001b[39m get_words_ipas(dest_lang, src_lang, base_link \u001b[39m+\u001b[39;49m next_link[\u001b[39m'\u001b[39;49m\u001b[39mhref\u001b[39;49m\u001b[39m'\u001b[39;49m], page_num\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=63'>64</a>\u001b[0m         borrowed_words \u001b[39m=\u001b[39m borrowed_words \u001b[39m+\u001b[39m more_words\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=65'>66</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=66'>67</a>\u001b[0m     \u001b[39m# errors can be due to timeouts/connections refused due to rate limiting. can be fixed via proxies/vpns/timeouts\u001b[39;00m\n",
      "\u001b[1;32m/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb Cell 4'\u001b[0m in \u001b[0;36mget_words_ipas\u001b[0;34m(dest_lang, src_lang, link, page_num, lst_invalid_words)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m borrowed_word \u001b[39min\u001b[39;00m list_words:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=16'>17</a>\u001b[0m     \u001b[39m# for each loaned word get the wiki link and extract ipas for it.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=17'>18</a>\u001b[0m     ipa_page \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(base_link \u001b[39m+\u001b[39m borrowed_word[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=18'>19</a>\u001b[0m     ipa_soup \u001b[39m=\u001b[39m BeautifulSoup(ipa_page\u001b[39m.\u001b[39;49mcontent, \u001b[39m'\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=21'>22</a>\u001b[0m     \u001b[39m# get the src word and wiki link to extract ipas for the src word\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mannan/work/loan-word-detection/wiktionary-scraper-python/scraper_false_friends.ipynb#ch0000003?line=22'>23</a>\u001b[0m     src_word_html_final \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py:362\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py?line=359'>360</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py?line=360'>361</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py?line=361'>362</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed()\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py?line=362'>363</a>\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py?line=363'>364</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py:448\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py?line=444'>445</a>\u001b[0m \u001b[39m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py?line=445'>446</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py?line=447'>448</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mfeed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup)\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py?line=448'>449</a>\u001b[0m \u001b[39m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/__init__.py?line=449'>450</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendData()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/bs4/builder/_htmlparser.py:392\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/builder/_htmlparser.py?line=389'>390</a>\u001b[0m parser\u001b[39m.\u001b[39msoup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoup\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/builder/_htmlparser.py?line=390'>391</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/builder/_htmlparser.py?line=391'>392</a>\u001b[0m     parser\u001b[39m.\u001b[39;49mfeed(markup)\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/builder/_htmlparser.py?line=392'>393</a>\u001b[0m     parser\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    <a href='file:///Users/mannan/Library/Python/3.8/lib/python/site-packages/bs4/builder/_htmlparser.py?line=393'>394</a>\u001b[0m \u001b[39mexcept\u001b[39;00m HTMLParseError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py:111\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=104'>105</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=105'>106</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=106'>107</a>\u001b[0m \u001b[39mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=107'>108</a>\u001b[0m \u001b[39mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=108'>109</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=109'>110</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m+\u001b[39m data\n\u001b[0;32m--> <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=110'>111</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoahead(\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py:171\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=168'>169</a>\u001b[0m \u001b[39mif\u001b[39;00m startswith(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m, i):\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=169'>170</a>\u001b[0m     \u001b[39mif\u001b[39;00m starttagopen\u001b[39m.\u001b[39mmatch(rawdata, i): \u001b[39m# < + letter\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=170'>171</a>\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_starttag(i)\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=171'>172</a>\u001b[0m     \u001b[39melif\u001b[39;00m startswith(\u001b[39m\"\u001b[39m\u001b[39m</\u001b[39m\u001b[39m\"\u001b[39m, i):\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=172'>173</a>\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py:316\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=313'>314</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlasttag \u001b[39m=\u001b[39m tag \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mlower()\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=314'>315</a>\u001b[0m \u001b[39mwhile\u001b[39;00m k \u001b[39m<\u001b[39m endpos:\n\u001b[0;32m--> <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=315'>316</a>\u001b[0m     m \u001b[39m=\u001b[39m attrfind_tolerant\u001b[39m.\u001b[39;49mmatch(rawdata, k)\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=316'>317</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m m:\n\u001b[1;32m    <a href='file:///Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py?line=317'>318</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for pair in links:\n",
    "    if os.path.exists(\"results/{}_false_friends.csv\".format(pair)):\n",
    "        overwrite = input(\"{}_false_friends.csv exists. Overwrite existing file? (y/n) \".format(pair))\n",
    "    if not os.path.exists(\"results/{}.csv\".format(pair)) or overwrite == \"y\":\n",
    "        print()\n",
    "        [dest, src] = pair.split('-')\n",
    "        words = get_words_ipas(dest, src, links[pair], 1)\n",
    "        df = pd.DataFrame(words, columns=['loan_word', 'original_word', 'other_etymology', 'other_meaning'])\n",
    "        df.to_csv(\"results/{}_false_friends.csv\".format(pair), index=False)\n",
    "        print(pair, \"done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
